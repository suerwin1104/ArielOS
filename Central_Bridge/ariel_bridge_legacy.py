import requests, json, datetime, shutil, subprocess, queue, threading, uuid, re, os, time, logging
from flask import Flask, request, jsonify, Response
from pathlib import Path
from ddgs import DDGS  # Phase 4: Web Search (formerly duckduckgo_search)
from skill_manager import SkillManager  # Phase 13: Skills System
from memory_manager import MemoryManager  # Phase 14: Long-term Memory

# ğŸ”‡ æŠ‘åˆ¶ primp çš„ Impersonate è­¦å‘Šï¼ˆå·²çŸ¥ç„¡å®³ï¼Œprimp æœƒè‡ªå‹• fallback åˆ° randomï¼‰
logging.getLogger("primp").setLevel(logging.ERROR)

app = Flask(__name__)
logging.getLogger('werkzeug').setLevel(logging.ERROR)
task_queue = queue.Queue()
task_results = {}

# ğŸ“Œ è‡ªå‹•åµæ¸¬ä½¿ç”¨è€…å®¶ç›®éŒ„ï¼Œç¢ºä¿åœ¨ä»»ä½•é›»è…¦éƒ½èƒ½é‹è¡Œï¼Œä¸”ä¸æ´©æ¼æ‚¨çš„ä½¿ç”¨è€…åç¨±
BASE_DIR = Path.home() / "Ariel_System"
CACHE_PATH = BASE_DIR / "Shared_Vault" / "cache_buffer.json"
CACHE_PATH.parent.mkdir(exist_ok=True, parents=True)
KANBAN_DB_PATH = BASE_DIR / "Shared_Vault" / "kanban.json"

# ğŸ¯ Ollama API (æœ¬åœ° loopback åœ°å€ï¼Œä¸å…·å‚™å¤–ç¶²é¢¨éšª)
OLLAMA_API = "http://127.0.0.1:11434/api/generate"

# ğŸ§  æ¨¡å‹é…ç½® (é›†ä¸­ç®¡ç†ï¼Œæ›´æ›æ¨¡å‹åªéœ€æ”¹æ­¤è™•)
# å°è…¦ï¼šä½¿ç”¨ instruction-tuned + q4_K_M é‡åŒ–ç‰ˆï¼Œé€Ÿåº¦æ¯”é è¨­ç‰ˆå¿« ~30%ï¼Œä½” ~2.5GB RAM
# ğŸ’¡ è«‹å…ˆåŸ·è¡Œ ollama pull gemma3:4b-it-q4_K_M å¾Œå†ä½¿ç”¨é‡åŒ–ç‰ˆ
CEREBELLUM_MODEL = "gemma3:4b-it-q4_K_M"
# å‚™ç”¨æ¨¡å‹ï¼šè‹¥é‡åŒ–ç‰ˆæœªå®‰è£æˆ– Ollama è¶…æ™‚ï¼Œç³»çµ±è‡ªå‹•é™ç´šè‡³æ­¤æ¨¡å‹ç¹¼çºŒæœå‹™
CEREBELLUM_FALLBACK_MODEL = "gemma3:4b"
# Dispatcher è§’è‰²æ‰®æ¼”ä»»å‹™ï¼ˆå¬å–š Commander/Worker/Reviewerï¼‰ä¹Ÿç”¨å°è…¦æ¨¡å‹å³å¯
DISPATCHER_MODEL = "gemma3:4b-it-q4_K_M"

# ğŸŒ HTTP è«‹æ±‚ (Reverted from Session: requests.Session() is not thread-safe for highly concurrent agent requests)
def ollama_post(url, json, timeout=60):
    """Thread-safe Ollama post."""
    return requests.post(url, json=json, timeout=timeout)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ï¿½ å°è…¦ä¿è­·å±¤ï¼šé˜²æ­¢åŒæ™‚å¤§é‡è«‹æ±‚é€ æˆ Ollama éè¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import threading as _threading

# æœ€å¤šåŒæ™‚ 2 å€‹å°è…¦ä»»å‹™ (SIMPLE/SEARCH/é¢¨æ ¼è½‰ç§») ä¸¦è¡Œï¼Œå…¶é¤˜å…¥æ’éšŠ
_CEREBELLUM_SEMAPHORE = _threading.Semaphore(2)

# ç°¡æ˜“ Hash å¿«å–ï¼šå®Œå…¨ç›¸åŒå•é¡Œ (SIMPLE é¡) ä¸é‡è¤‡å‘¼å« LLM
_SIMPLE_CACHE: dict = {}   # query -> (answer, expire_ts)
_SIMPLE_CACHE_TTL = 300    # 5 åˆ†é˜å…§ç›¸åŒå•é¡Œç›´æ¥å‘½ä¸­

def _cached_cerebellum_simple(cache_key: str):
    """æª¢æŸ¥ SIMPLE å•é¡Œå¿«å–"""
    entry = _SIMPLE_CACHE.get(cache_key)
    if entry and time.time() < entry[1]:
        log(f"âš¡ [SimpleCache] å‘½ä¸­å¿«å–: {cache_key[:30]}")
        return entry[0]
    return None

def _set_cerebellum_simple_cache(cache_key: str, answer: str):
    """å¯«å…¥ SIMPLE å•é¡Œå¿«å–ï¼Œä¸¦æ·˜æ±°éæœŸé …ç›®"""
    _SIMPLE_CACHE[cache_key] = (answer, time.time() + _SIMPLE_CACHE_TTL)
    expired = [k for k, (_, ts) in _SIMPLE_CACHE.items() if time.time() >= ts]
    for k in expired:
        _SIMPLE_CACHE.pop(k, None)

def cerebellum_call(prompt: str, temperature: float = 0.3, timeout: int = 30,
                    num_ctx: int = 2048, num_predict: int = 256) -> str:
    """ğŸ§  å°è…¦çµ±ä¸€å‘¼å«ä»‹é¢ï¼ˆå« Semaphore ä¿è­·ã€ç²¾ç°¡ Context è¨­å®šã€è‡ªå‹•æ¨¡å‹é™ç´šï¼‰
    
    å„å ´æ™¯å»ºè­°è¨­å®šï¼š
    - æ„åœ–åˆ†é¡:  num_ctx=2048, num_predict=80
    - é—œéµå­—èƒå–: num_ctx=1024, num_predict=30
    - å¿«å–æ¯”å°:  num_ctx=2048, num_predict=10
    - é¢¨æ ¼è½‰ç§»:  num_ctx=4096, num_predict=600
    - å‰è¨€ç”Ÿæˆ:  num_ctx=1024, num_predict=60
    
    è‡ªå‹•é™ç´šï¼šè‹¥ CEREBELLUM_MODEL è¶…æ™‚æˆ–ä¸å­˜åœ¨ï¼Œè‡ªå‹•æ”¹ç”¨ CEREBELLUM_FALLBACK_MODELã€‚
    """
    payload = {
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": temperature,
            "num_ctx": num_ctx,
            "num_predict": num_predict
        }
    }
    with _CEREBELLUM_SEMAPHORE:  # æœ€å¤šåŒæ™‚ 2 å€‹å°è…¦ä»»å‹™
        # å˜—è©¦é‡åŒ–ç‰ˆ (ä¸»è¦æ¨¡å‹)
        try:
            resp = ollama_post(OLLAMA_API, json={**payload, "model": CEREBELLUM_MODEL}, timeout=timeout)
            return resp.json().get('response', '').strip()
        except Exception as e:
            # è‹¥è¶…æ™‚æˆ–æ¨¡å‹ä¸å­˜åœ¨ï¼Œé™ç´šè‡³å‚™ç”¨æ¨¡å‹
            log(f"âš ï¸ [{CEREBELLUM_MODEL}] å¤±æ•—ï¼Œé™ç´šè‡³ {CEREBELLUM_FALLBACK_MODEL}: {e}")
        
        # é™ç´šï¼šä½¿ç”¨å‚™ç”¨æ¨¡å‹ (é€šå¸¸æ˜¯ gemma3:4bï¼Œå¹¾ä¹å¿…å®šå­˜åœ¨)
        resp = ollama_post(OLLAMA_API, json={**payload, "model": CEREBELLUM_FALLBACK_MODEL}, timeout=timeout)
        return resp.json().get('response', '').strip()

AGENTS_CONFIG_PATH = BASE_DIR / "Shared_Vault" / "agents.json"
AGENT_REGISTRY = {}

def load_agent_registry():
    """å¾ JSON è¼‰å…¥ä»£ç†äººè¨­å®šï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨é è¨­å€¼"""
    global AGENT_REGISTRY
    # å•Ÿå‹•æ™‚ log() å°šæœªå®šç¾©ï¼Œä½¿ç”¨å…§éƒ¨ _log å®‰å…¨åŒ…è£
    def _log(msg):
        try: log(msg)
        except: print(f"[ArielOS] {msg}")
    
    default_agents = {
        "agent1": {
            "name": "Jessie", 
            "dir": "Ariel_Agent_1",
            "intro": "æˆ‘æ˜¯ Jessieï¼Œæ‚¨çš„åŸ·è¡Œç§˜æ›¸ã€‚éš¨æ™‚æº–å‚™ç‚ºæ‚¨è™•ç†å…¬å‹™èˆ‡å°ˆæ¡ˆã€‚"
        },
        "agent2": {
            "name": "Mandy",  
            "dir": "Ariel_Agent_2",
            "intro": "è€é—†æ‚¨å¥½ï¼Œæˆ‘æ˜¯ Mandyï¼Œæ‚¨çš„ç§äººç”Ÿæ´»ç‰¹åŠ©ã€‚æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«æ‚¨å®‰æ’çš„å—ï¼Ÿ"
        }
    }
    
    if not AGENTS_CONFIG_PATH.exists():
        _log("âš ï¸ æœªæ‰¾åˆ° agents.jsonï¼Œä½¿ç”¨é è¨­ä»£ç†äººè¨­å®šä¸¦å»ºç«‹æª”æ¡ˆ")
        try:
            with open(AGENTS_CONFIG_PATH, "w", encoding="utf-8") as f:
                json.dump(default_agents, f, ensure_ascii=False, indent=2)
            AGENT_REGISTRY = default_agents
        except Exception as e:
            _log(f"âŒ ç„¡æ³•å»ºç«‹ agents.json: {e}")
            AGENT_REGISTRY = default_agents
    else:
        try:
            with open(AGENTS_CONFIG_PATH, "r", encoding="utf-8") as f:
                AGENT_REGISTRY = json.load(f)
            _log(f"âœ… å·²è¼‰å…¥ {len(AGENT_REGISTRY)} ä½ä»£ç†äººè¨­å®š")
        except Exception as e:
            _log(f"âŒ è®€å– agents.json å¤±æ•—: {e}ï¼Œå›é€€è‡³é è¨­å€¼")
            AGENT_REGISTRY = default_agents

def log(msg):
    t = datetime.datetime.now().strftime("%H:%M:%S")
    print(f"[{t}] ğŸ° [ç¸½éƒ¨] {msg}")

# åˆå§‹è¼‰å…¥ (å¿…é ˆåœ¨ log() å®šç¾©å¾ŒåŸ·è¡Œ)
load_agent_registry()

# â±ï¸ é–’ç½®æ™‚é–“è¿½è¹¤ (Dimension 2: Curiosity-Driven Evolution)
last_activity_time = time.time()


class KanbanManager:
    """Phase 10: çœ‹æ¿ä»»å‹™ç®¡ç†å™¨"""
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            self._save({"tasks": []})

    def _load(self):
        try:
            with open(self.db_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return {"tasks": []}

    def _save(self, data):
        with open(self.db_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def get_all(self):
        return self._load().get("tasks", [])

    def add_task(self, title, agent_id, status="todo", priority="medium"):
        data = self._load()
        task = {
            "id": str(uuid.uuid4()),
            "title": title,
            "agent_id": agent_id,
            "status": status,
            "priority": priority,
            "created_at": datetime.datetime.now().isoformat()
        }
        data["tasks"].append(task)
        self._save(data)
        return task

    def update_task(self, tid, updates):
        data = self._load()
        for task in data["tasks"]:
            if task["id"] == tid:
                task.update(updates)
                self._save(data)
                return task
        return None
    
    def delete_task(self, tid):
        data = self._load()
        initial_len = len(data["tasks"])
        data["tasks"] = [t for t in data["tasks"] if t["id"] != tid]
        if len(data["tasks"]) < initial_len:
            self._save(data)
            return True
        return False

KM = KanbanManager(KANBAN_DB_PATH)

class Shield:
    """L6: é˜²ç¦¦å”è­° 2.0 (Security & Governance)"""
    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self.forbidden_patterns = [
            (r'(printenv|echo\s+\$|cat\s+\.env|process\.env)', "ğŸš« [Env Protection] ç¦æ­¢è®€å–ç’°å¢ƒè®Šæ•¸"),
            (r'(\.ssh|id_rsa|aws/credentials)', "ğŸš¨ [Canary Logic] è§¸ç™¼èª˜æ•ï¼šç¦æ­¢å­˜å–æ•æ„Ÿæ†‘è­‰"),
            (r'(echo\s+.*?>.*?|write|cp|mv).*?(AGENT\.md|SOUL\.md|SHIELD\.md)', "ğŸ”’ [Immutable Core] ç¦æ­¢ä¿®æ”¹æ ¸å¿ƒæ²»ç†æª”æ¡ˆ"),
            (r'(train|fine-tune|nmap|ddos)', "âš ï¸ [Resource Pre-check] é«˜ç®—åŠ›/é«˜é¢¨éšªæŒ‡ä»¤éœ€äºŒæ¬¡ç¢ºèª"),
            # ğŸ”’ é˜²æ­¢å¤§è…¦å‘¼å«æ’ç¨‹å·¥å…·é€ æˆæ´ªæ°´ (cron.add å°ˆæ¡ˆ)
            (r'(cron\.add|cron\.schedule|cron\.create|schedule_job|add_cron)', "ğŸš« [Cron Shield] ç¦æ­¢å¤§è…¦ç›´æ¥å‘¼å«æ’ç¨‹å·¥å…·ï¼Œè«‹æ”¹ç”¨ ArielOS Watcher (routines.json) è§£æ±ºæ’ç¨‹éœ€æ±‚")
        ]

    def scan(self, command):
        """æƒææŒ‡ä»¤ç‰¹å¾µç¢¼"""
        cmd_lower = command.lower()
        for pattern, warning in self.forbidden_patterns:
            if re.search(pattern, cmd_lower):
                log(f"ğŸ›¡ï¸ Shield æ””æˆª: {warning}")
                return False, warning
        return True, "Safe"

class PersonalityEngine:
    """L4: äººæ ¼å¼•æ“ - è®€å– SOUL.md ä¸¦æ³¨å…¥èº«ä»½åå¥½"""
    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self._cache = {}  # agent_id -> soul_text
        self._cache_intros = {} # agent_id -> reflex_intro

    def load_soul(self, agent_id):
        """è¼‰å…¥æŒ‡å®šä»£ç†äººçš„ SOUL.md"""
        if agent_id in self._cache:
            return self._cache[agent_id]
        
        agent_info = AGENT_REGISTRY.get(agent_id)
        if not agent_info:
            return ""
        
        soul_path = self.base_dir / agent_info["dir"] / "memory" / "SOUL.md"
        if soul_path.exists():
            with open(soul_path, "r", encoding="utf-8") as f:
                soul_text = f.read()
            self._cache[agent_id] = soul_text
            
            # è§£æè‡ªæˆ‘ä»‹ç´¹ (Reflex Intro)
            start_marker = "* **è‡ªæˆ‘ä»‹ç´¹**ï¼š"
            start_marker_alt = "* **Reflex Intro**ï¼š"
            intro = None
            for line in soul_text.split('\n'):
                if start_marker in line:
                    intro = line.split(start_marker)[1].strip()
                    break
                elif start_marker_alt in line:
                    intro = line.split(start_marker_alt)[1].strip()
                    break
            
            if intro:
                self._cache_intros[agent_id] = intro
                log(f"ğŸ§¬ äººæ ¼å¼•æ“: å·²è¼‰å…¥ {agent_info['name']} çš„è‡ªæˆ‘ä»‹ç´¹ (Reflex)")
            else:
                log(f"ğŸ§¬ äººæ ¼å¼•æ“: å·²è¼‰å…¥ {agent_info['name']} çš„éˆé­‚è¨­å®š (ç„¡ç‰¹å®šIntro)")
                
            return soul_text
        return ""

    def get_intro(self, agent_id):
        """å–å¾—è„Šé«“åå°„ç”¨çš„è‡ªæˆ‘ä»‹ç´¹"""
        # ç¢ºä¿å·²è¼‰å…¥
        if agent_id not in self._cache_intros:
             self.load_soul(agent_id)
        return self._cache_intros.get(agent_id, None)

    def build_persona_prompt(self, agent_id, user_query):
        """Legacy: build_persona_prompt removed in Phase 3"""
        return user_query

    def invalidate(self, agent_id=None):
        if agent_id: 
            self._cache.pop(agent_id, None)
            self._cache_intros.pop(agent_id, None)
        else: 
            self._cache.clear()
            self._cache_intros.clear()

# å…¨åŸŸäººæ ¼å¼•æ“å¯¦ä¾‹
PE = PersonalityEngine(BASE_DIR)

# ğŸ§  å…¨åŸŸè¨˜æ†¶å®˜å¯¦ä¾‹
SM = SkillManager(BASE_DIR)
MM = MemoryManager(BASE_DIR)  # Phase 14: Long-term Memory

class AgentDispatcher:
    """L5: å¤šä»£ç†åœ˜éšŠåˆ†ç™¼å™¨ (Multi-Agent Dispatcher)"""
    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self.roles_dir = self.base_dir / "Shared_Vault" / "roles"
        self.workspace_root = self.base_dir / ".arielos" / "workspace"
        self.workspace_root.mkdir(parents=True, exist_ok=True)

    def dispatch(self, task_id, role, payload):
        """åˆ†ç™¼ä»»å‹™çµ¦ç‰¹å®šè§’è‰²"""
        log(f"ğŸ‘® [Dispatcher] Assigning Task {task_id} to Role: {role}")
        
        # 1. å»ºç«‹éš”é›¢å·¥ä½œå€
        workspace = self._create_workspace(task_id)
        
        # 2. æ±ºå®šäººæ ¼ (SOUL)
        # å„ªå…ˆæ‰¾ Shared_Vault/roles/{role}.soul.md
        # å…¶æ¬¡æ‰¾ä¸€èˆ¬ Agent (å¦‚ jessie, mandy)
        soul_path = self.roles_dir / f"{role}.soul.md"
        soul_content = ""
        
        if soul_path.exists():
            soul_content = soul_path.read_text(encoding="utf-8")
        else:
            # å˜—è©¦æ‰¾ä¸€èˆ¬ Agent
            for aid, info in AGENT_REGISTRY.items():
                if info["name"].lower() == role.lower():
                    # å€Ÿç”¨ load_soul
                    soul_content = PE.load_soul(aid)
                    break
            
            if not soul_content:
                return f"Error: Role/Agent '{role}' not found."

        # 3. åŸ·è¡Œä»»å‹™ (ç›®å‰æ¨¡æ“¬åŸ·è¡Œï¼Œæœªä¾†å¯ Spawn Process)
        # é€™è£¡ç°¡å–®ç”¨ LLM ç”Ÿæˆå›æ‡‰ï¼Œæ¨¡æ“¬è©²è§’è‰²çš„ç”¢å‡º
        instruction = (
            f"{soul_content}\n\n"
            f"Current Workspace: {workspace}\n"
            f"Task Payload: {payload}\n"
            "è«‹ä»¥ä½ çš„è§’è‰²èº«åˆ†åŸ·è¡Œä¸Šè¿°ä»»å‹™ã€‚è‹¥éœ€å¯«æª”ï¼Œè«‹è¼¸å‡ºæª”æ¡ˆå…§å®¹èˆ‡è·¯å¾‘ã€‚"
        )
        
        try:
            result = cerebellum_call(
                prompt=instruction,
                temperature=0.1,
                timeout=300,
                num_ctx=4096,
                num_predict=1024
            )
            
            # å¯«å…¥ Log
            (workspace / "execution.log").write_text(result, encoding="utf-8")
            return result
        except Exception as e:
            return f"Dispatcher Error: {e}"

    def _create_workspace(self, task_id):
        ws = self.workspace_root / task_id
        ws.mkdir(parents=True, exist_ok=True)
        return ws

# å…¨åŸŸåˆ†ç™¼å™¨
Dispatcher = AgentDispatcher(BASE_DIR)

def _sanitize_persona(text: str, agent_name: str) -> str:
    """ğŸ›¡ï¸ äººæ ¼æ¶ˆæ¯’ï¼šå¼·åˆ¶æ›¿æ›æ‰€æœ‰ Ariel/ArielOS è‡ªç¨±ç‚ºæ­£ç¢ºä»£ç†äººåå­—ï¼ˆPython å±¤ä¿éšœï¼‰"""
    # word-boundary æ›¿æ›ï¼Œé¿å…èª¤å‚·å« Ariel çš„è©ï¼ˆå¦‚ Ariel å“ç‰Œï¼‰
    text = re.sub(r'\bArielOS\b', agent_name, text)
    text = re.sub(r'\bAriel\b', agent_name, text)
    return text

def _get_time_context():
    """â° å–å¾—ç›®å‰çš„ç³»çµ±æ™‚é–“ä¸Šä¸‹æ–‡"""
    now = datetime.datetime.now()
    weekday_map = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    weekday = weekday_map[now.weekday()]
    return f"[ç³»çµ±æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (æ˜ŸæœŸ{weekday})]\n"

def spinal_chord_reflex(query: str, agent_id: str) -> str | None:
    """âš¡ è„Šé«“åå°„ï¼šä¸ç¶“å¤§è…¦èˆ‡å°è…¦ï¼Œç›´æ¥ä»¥è¦å‰‡è™•ç†æ¥µç°¡å•é¡Œ (0.01s)"""
    q = query.strip().lower()
    agent_name = AGENT_REGISTRY.get(agent_id, {}).get("name", "Ariel Agent")
    now = datetime.datetime.now()
    
    # 1. æ™‚é–“/æ—¥æœŸ (Time/Date)
    if any(k in q for k in ["ä»Šå¤©æ—¥æœŸ", "ç¾åœ¨æ™‚é–“", "å¹¾æœˆå¹¾è™Ÿ", "æ˜ŸæœŸå¹¾", "ç¾åœ¨å¹¾é»", "today", "now", "time"]):
        # ç°¡å–®éæ¿¾ï¼šç¢ºä¿ä¸æ˜¯åœ¨å•åˆ¥äººæˆ–è¤‡é›œå¥
        if len(q) < 20 and not any(k in q for k in ["æ±äº¬", "ç¾åœ‹", "ç¥¨", "å¤©æ°£", "æ–°è"]):
            weekday = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"][now.weekday()]
            return f"ä»Šå¤©æ˜¯ {now.strftime('%Y å¹´ %m æœˆ %d æ—¥')}ï¼Œç¾åœ¨æ™‚é–“ {now.strftime('%H:%M')}ï¼Œæ˜ŸæœŸ{weekday}ã€‚"
            
    # 2. èº«ä»½ç¢ºèª (Identity)
    if any(k in q for k in ["ä½ æ˜¯èª°", "å¦³æ˜¯èª°", "ä½ çš„åå­—", "å¦³çš„åå­—", "who are you", "è‡ªæˆ‘ä»‹ç´¹", "ä»‹ç´¹è‡ªå·±"]):
        # å„ªå…ˆå¾ SOUL.md è®€å–å‹•æ…‹ Introï¼Œè‹¥ç„¡å‰‡é™ç´šå› Registry
        dynamic_intro = PE.get_intro(agent_id)
        fallback_intro = AGENT_REGISTRY.get(agent_id, {}).get("intro", f"æˆ‘æ˜¯ {agent_name}ï¼Œæ‚¨çš„ AI åŠ©ç†ã€‚")
        return dynamic_intro if dynamic_intro else fallback_intro

    # 3. å•å€™èª (Greetings) - ä¾æ™‚æ®µå›æ‡‰
    if q in ["hi", "hello", "ä½ å¥½", "æ‚¨å¥½", "æ—©å®‰", "åˆå®‰", "æ™šå®‰", "å“ˆå›‰"]:
        hour = now.hour
        greeting = "æ—©å®‰" if 5 <= hour < 12 else "åˆå®‰" if 12 <= hour < 18 else "æ™šå®‰"
        return f"{agent_name} ç¥æ‚¨{greeting}ï¼æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«æ‚¨çš„å—ï¼Ÿ"

    # 4. æ„Ÿè¬èˆ‡çµæŸ (Gratitude)
    if any(k in q for k in ["è¬è¬", "æ„Ÿè¬", "è¾›è‹¦äº†", "thanks", "thank you"]):
        if len(q) < 10:
            return "ä¸å®¢æ°£ï¼Œé€™æ˜¯æˆ‘çš„æ¦®å¹¸ï¼"

    # 5. ç³»çµ±ç‹€æ…‹ (System Status)
    if q in ["ç³»çµ±ç‹€æ…‹", "status", "version", "ç‰ˆæœ¬", "ping"]:
        return f"ğŸŸ¢ ArielOS é‹ä½œæ­£å¸¸ | Agent: {agent_name} | Pre-check: All Green"

    # 6. æ±‚åŠ© (Help)
    if q in ["help", "èªªæ˜", "æŒ‡ä»¤", "åŠŸèƒ½", "ä½ èƒ½åšä»€éº¼"]:
        return (
            "æˆ‘æ˜¯æ‚¨çš„ Ariel æ™ºèƒ½åŠ©ç†ï¼Œæˆ‘å¯ä»¥å”åŠ©æ‚¨ï¼š\n"
            "1. ğŸ” **æœå°‹è³‡è¨Š**ï¼šæŸ¥æ©Ÿç¥¨ã€å¤©æ°£ã€æ–°èã€è‚¡åƒ¹\n"
            "2. ğŸ› ï¸ **åŸ·è¡ŒæŠ€èƒ½**ï¼šè®€å¯«æª”æ¡ˆã€Git æ“ä½œã€è³‡æ–™åº«ç®¡ç†\n"
            "3. ğŸ’» **æ’°å¯«ç¨‹å¼**ï¼šPython è…³æœ¬ç”Ÿæˆèˆ‡åŸ·è¡Œ\n"
            "4. ğŸ§  **è¨˜æ†¶ç®¡ç†**ï¼šæˆ‘æœƒè¨˜ä½æ‚¨çš„åå¥½èˆ‡å°ˆæ¡ˆé€²åº¦\n"
            "è«‹ç›´æ¥å‘Šè¨´æˆ‘æ‚¨éœ€è¦ä»€éº¼ï¼"
        )
        
    return None

def cerebellum_style_transfer(raw_answer, agent_id):
    """ğŸš€ å°è…¦é¢¨æ ¼è½‰ç§»ï¼šå°‡å¤§è…¦çš„ç´”é‚è¼¯ç­”æ¡ˆè½‰åŒ–ç‚ºä»£ç†äººäººæ ¼"""
    soul = PE.load_soul(agent_id)
    agent_name = AGENT_REGISTRY.get(agent_id, {}).get("name", "Agent")

    if not soul:
        # æ²’æœ‰éˆé­‚è¨­å®šæ™‚ï¼Œä»åšäººæ ¼æ¶ˆæ¯’å¾Œå›å‚³
        return _sanitize_persona(raw_answer, agent_name)

    # ğŸš€ å¤§è¼¸å‡º Fallbackï¼šè‹¥åŸå§‹ç­”æ¡ˆè¶…é 3000 å­—å…ƒï¼Œåªç”Ÿæˆå‰è¨€å¥ï¼Œé¿å… LLM é‡å¯«æ•´ç¯‡é€ æˆé€¾æ™‚
    if len(raw_answer) > 3000:
        intro_instruction = (
            f"ä½ æ˜¯ {agent_name}ã€‚è«‹ç”¨ä½ ç¨ç‰¹çš„èªªè©±é¢¨æ ¼ï¼Œåªå¯«ä¸€å¥è©±å‘è€é—†å ±å‘Šä»¥ä¸‹ä»»å‹™å·²å®Œæˆã€‚"
            f"ä¸è¦é‡è¤‡åŸæ–‡ï¼Œåªè¦ä¸€å¥å‰è¨€å³å¯ã€‚\n"
            f"ä»»å‹™æ‘˜è¦ï¼ˆå‰200å­—ï¼‰ï¼š{raw_answer[:200]}"
        )
        try:
            intro = cerebellum_call(
                prompt=intro_instruction,
                temperature=0.4,
                timeout=30,
                num_ctx=1024,
                num_predict=60  # åªéœ€ä¸€å¥å‰è¨€
            )
            if intro:
                intro = _sanitize_persona(intro, agent_name)
                return f"{intro}\n\n{_sanitize_persona(raw_answer, agent_name)}"
        except Exception as e:
            log(f"âš ï¸ å¤§è¼¸å‡ºå‰è¨€ç”Ÿæˆå¤±æ•—: {e}")
        return _sanitize_persona(raw_answer, agent_name)

    instruction = (
        f"ä½ ç¾åœ¨æ˜¯ {agent_name}ï¼Œä»¥ä¸‹æ˜¯ä½ çš„éˆé­‚è¨­å®šï¼š\n---\n{soul[:800]}\n---\n"  # åªå‚³å‰ 800 å­—ï¼Œé¿å… Context çˆ†ç‚¸
        f"è«‹ç”¨ä½ çš„ã€èªªè©±é¢¨æ ¼ã€æ”¹å¯«ä»¥ä¸‹å…§å®¹ã€‚é€²è¡Œæ”¹å¯«æ™‚ï¼Œå¿…é ˆéµå®ˆä»¥ä¸‹è¦å‰‡ï¼š\n"
        f"1. **å°‡å…§å®¹ä¸­æ‰€æœ‰ 'Ariel'ã€'ArielOS' çš„è‡ªç¨±å…¨éƒ¨æ”¹ç‚ºã€{agent_name}ã€**ï¼Œå› ç‚ºä½ å°±æ˜¯ {agent_name}ï¼Œä¸æ˜¯ Arielã€‚\n"
        f"2. ä½¿ç”¨ç¬¬ä¸€äººç¨±ã€æˆ‘ã€è€Œä¸æ˜¯ç›´æ¥å”±å‡ºè‡ªå·±çš„åå­—ï¼Œé™¤éæ˜¯åœ¨æåŠè‡ªå·±æ™‚å¯ç”¨ {agent_name}ã€‚\n"
        f"3. **åš´ç¦ä¿®æ”¹ç¨‹å¼ç¢¼å€å¡Š (Code Blocks) èˆ‡æ•¸å­—äº‹å¯¦**ã€‚\n\n"
        f"åŸå§‹å…§å®¹ï¼š\n{raw_answer}"
    )
    try:
        styled = cerebellum_call(
            prompt=instruction,
            temperature=0.7,
            timeout=120,
            num_ctx=4096,   # é¢¨æ ¼è½‰ç§»éœ€è¦è®€åŸæ–‡ï¼Œçµ¦è¼ƒå¤§ context
            num_predict=600 # é¢¨æ ¼è½‰ç§»å¯ä»¥è¼¸å‡ºè¼ƒé•·å›æ‡‰
        )
        if styled:
            return _sanitize_persona(styled, agent_name)
    except Exception as e:
        log(f"âš ï¸ é¢¨æ ¼è½‰ç§»å¤±æ•—: {e}")
    return _sanitize_persona(raw_answer, agent_name)

def extract_search_keywords(query):
    """ğŸ”‘ å¾è‡ªç„¶èªè¨€æå–æœå°‹é—œéµå­—ï¼Œé¿å… DuckDuckGo è¢«å†—é¤˜èªå¥å¹²æ“¾"""
    try:
        keywords = cerebellum_call(
            prompt=(
                f"å°‡ä»¥ä¸‹è‡ªç„¶èªè¨€å•å¥è½‰æ›æˆç²¾ç¢ºçš„æœå°‹å¼•æ“é—œéµå­—ï¼ˆ2~5å€‹è©ï¼‰ï¼Œåªè¼¸å‡ºé—œéµå­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦è§£é‡‹ã€‚\n"
                f"ç¯„ä¾‹ï¼š\n"
                f"- ã€å‘Šè¨´æˆ‘å°åŒ—å¸‚ç¾åœ¨çš„å¤©æ°£ç‹€æ³ã€ â†’ å°åŒ—å¸‚ å¤©æ°£ ç¾åœ¨\n"
                f"- ã€NVDA è‚¡åƒ¹å¤šå°‘ã€ â†’ NVDA è‚¡åƒ¹\n"
                f"- ã€æœ€è¿‘æœ‰ä»€éº¼ç§‘æŠ€æ–°èã€ â†’ ç§‘æŠ€æ–°è æœ€æ–°\n"
                f"- ã€é«˜é›„æœ‰ä»€éº¼å¥½åƒçš„ç«é‹æ¨è–¦ã€ â†’ é«˜é›„ ç«é‹ æ¨è–¦\n\n"
                f"å•å¥ï¼šã€{query}ã€\n"
                f"é—œéµå­—ï¼š"
            ),
            temperature=0,
            timeout=15,
            num_ctx=1024,    # é—œéµå­—èƒå–ä¸éœ€è¦å¤§ Context
            num_predict=30   # é—œéµå­—å¾ˆçŸ­ï¼Œ30 Tokens ç»å°å¤ 
        )
        # æ¸…ç†ï¼šå–ç¬¬ä¸€è¡Œã€ç§»é™¤å¤šé¤˜ç¬¦è™Ÿ
        keywords = keywords.split('\n')[0].strip().strip('"').strip("'").strip('`')
        if keywords and len(keywords) > 1:
            log(f"ğŸ”‘ é—œéµå­—èƒå–: '{query}' â†’ '{keywords}'")
            return keywords
    except Exception as e:
        log(f"âš ï¸ é—œéµå­—èƒå–å¤±æ•—: {e}")
    return query  # fallback: ä½¿ç”¨åŸå§‹æŸ¥è©¢

def search_web_worker(query):
    """ğŸš€ Phase 4: å°è…¦è¯ç¶²èˆ‡æ‘˜è¦ (Web Search)"""
    log(f"ğŸ” [Search Worker] å•Ÿå‹•æœå°‹: {query[:50]}...")
    try:
        # Step 1: é—œéµå­—èƒå– â€” å°‡è‡ªç„¶èªè¨€è½‰æ›ç‚ºæœå°‹å¼•æ“é—œéµå­—
        search_keywords = extract_search_keywords(query)
        
        # Step 2: åŸ·è¡Œæœå°‹ï¼ˆä½¿ç”¨èƒå–å¾Œçš„é—œéµå­—ï¼Œå¢åŠ çµæœæ•¸é‡ï¼‰
        results = DDGS().text(search_keywords, max_results=4)
        if not results:
            return "Unable to find relevant information from the web."
        
        context = "\n".join([f"- {r['title']}: {r['body']}" for r in results])
        # æˆªæ–·éé•·çš„æœå°‹çµæœï¼Œé¿å… LLM è™•ç†è¶…æ™‚ (Limit to 3000 chars)
        if len(context) > 3000:
            context = context[:3000] + "...(truncated)"
        
        # Step 3: Summarize with Gemmaï¼ˆä¸­ç«‹èº«ä»½ï¼Œåƒ…åˆ—äº‹å¯¦ï¼Œä¸è‡ªç¨±åå­—ï¼‰
        prompt = (
            f"ä½ æ˜¯ä¸€å±¤è³‡è¨Šæ•´ç†åŠ©æ‰‹ã€‚è«‹æ ¹æ“šæœå°‹çµæœä¸­æ–‡å›ç­”å•é¡Œï¼šã€{query}ã€\n"
            f"æœå°‹çµæœï¼š\n{context}\n\n"
            "è¦å‰‡ï¼š\n"
            "1. åƒ…ç”¨ç¹é«”ä¸­æ–‡åˆ—å‡ºäº‹å¯¦è¦‡é»ï¼Œä¸è©•è«–ã€ä¸å»ºè­°ã€ä¸åŠ å…¥ä»»ä½•è‡ªæˆ‘ä»‹ç´¹æˆ–åå­—è‡ªç¨±ã€‚\n"
            "2. ä¸å¾—åœ¨å›ç­”ä¸­å¯«å‡ºè‡ªå·±çš„åå­—ï¼ˆå¦‚ Arielã€ArielOSï¼‰ã€‚\n"
            "3. å¦‚æœæœå°‹çµæœèˆ‡å•é¡Œä¸ç›¸é—œï¼Œè«‹èª å¯¦èªªæ˜ç„¡æ³•æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€‚"
        )
        raw_summary = cerebellum_call(
            prompt=prompt,
            temperature=0.1,
            timeout=120,
            num_ctx=4096,   # æœå°‹çµæœå¯èƒ½å¾ˆé•·
            num_predict=512
        )
        
        return f"[ç¶²è·¯æœå°‹çµæœ] {raw_summary}"
    except Exception as e:
        log(f"âš ï¸ æœå°‹å¤±æ•—: {e}")
        return f"Error performing search: {e}"

def cerebellum_semantic_check(query):
    """ğŸš€ å°è…¦é–€è¡›ï¼šç”± Ollama åˆ¤å®šèªæ„æ„åœ– (é‚è¼¯å¢å¼·ç‰ˆ)"""
    # âš¡ å¿«é€Ÿè·¯å¾‘ï¼šå…ˆæª¢æŸ¥ SIMPLE å¿«å–ï¼ˆå®Œå…¨ç›¸åŒå•é¡Œï¼‰
    cached = _cached_cerebellum_simple(query)
    if cached:
        return cached

    if not CACHE_PATH.exists(): return None
    try:
        with open(CACHE_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
            records = data.get("records", [])
            if not records: return None
            
            now = datetime.datetime.now()
            valid_records = [r for r in records if now < datetime.datetime.fromisoformat(r['expires_at'])]
            target_pool = valid_records[-10:] 
            
            if not target_pool: return None

            # â”€â”€ ğŸ›¡ï¸ é—œéµå­—é‡ç–Šé ç¯©é¸ (æ¯” LLM å¿« 100 å€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # åªæœ‰åœ¨å­˜åœ¨ã€Œæ˜é¡¯ç›¸é—œã€çš„å¿«å–è¨˜éŒ„æ™‚æ‰é€²å…¥ LLM åˆ¤å®š
            # ä½¿ç”¨å­—å…ƒé›†äº¤é›†ç‡ï¼šè‹¥ query èˆ‡å¿«å–è¨˜éŒ„æ²’æœ‰ â‰¥ 30% çš„å…±åŒå­—è©ï¼Œå‰‡ä¸é€²å…¥ LLM
            query_chars = set(query.replace(" ", ""))  # ä¸­æ–‡ä¸ä¾ç©ºæ ¼åˆ†éš”ï¼Œç”¨å­—å…ƒé›†
            has_overlap = False
            for r in target_pool:
                r_chars = set(r['query'].replace(" ", ""))
                if len(r_chars) > 0:
                    overlap = len(query_chars & r_chars) / len(query_chars | r_chars)
                    if overlap >= 0.3:  # è‡³å°‘ 30% å­—å…ƒé‡ç–Š
                        has_overlap = True
                        break
            
            if not has_overlap:
                log(f"ğŸ›¡ï¸ [SemanticCache] ç„¡å­—å…ƒé‡ç–Šï¼Œè·³é LLM åˆ¤å®š")
                return None
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            cache_context = "\n".join([f"ID:{i} | å•é¡Œ:{r['query']}" for i, r in enumerate(target_pool)])
            instruction = (
                f"ä½ ç¾åœ¨æ˜¯ ArielOS çš„è¶…åš´æ ¼èªæ„é–€è¡›ã€‚å¿«å–æ¸…å–®å¦‚ä¸‹ï¼š\n{cache_context}\n\n"
                f"ç¾åœ¨è€é—†å•äº†ï¼šã€{query}ã€\n"
                "ã€åˆ¤æ–·æ¨™æº– â€” å¿…é ˆä¸‰é …å…¨éƒ¨ç›¸åŒæ‰å¯å‘½ä¸­ã€‘\n"
                "  1. ä¸»é¡Œ/é ˜åŸŸ å®Œå…¨ç›¸åŒï¼ˆå¦‚ï¼šå¤©æ°£ â‰  æ³•å¾‹ï¼ŒæŠ€èƒ½ â‰  é€²åº¦ï¼‰\n"
                "  2. åœ°é»/å°è±¡ å®Œå…¨ç›¸åŒ\n"
                "  3. è¡Œå‹•/æ„åœ– å®Œå…¨ç›¸åŒï¼ˆå¦‚ï¼šå­¸ç¿’æŠ€èƒ½ â‰  æŸ¥è©¢é€²åº¦ï¼Œæ–°è â‰  è¦åŠƒï¼‰\n\n"
                "ã€åä¾‹ â€” é€™äº›çµ•å°ä¸åŒï¼Œä¸å¯å‘½ä¸­ã€‘\n"
                "  - ã€å­¸ç¿’æ³•å¾‹æŠ€èƒ½ã€vsã€HBMS é€²åº¦ã€â†’ NO\n"
                "  - ã€é«˜é›„å¤©æ°£ã€vsã€å°åŒ—æ°£è±¡ã€â†’ NO\n"
                "  - ã€ä»Šå¤©å¹¾è™Ÿã€vsã€æ˜å¤©è¨ˆç•«ã€â†’ NO\n\n"
                "è¦å‰‡ï¼šåªæœ‰å®Œå…¨ç›¸åŒæ‰å›å‚³ ID æ•¸å­—ï¼›ä»»ä½•ç–‘æ…®ä¸€å¾‹å›å‚³ NOã€‚\n"
                "å›ç­”åƒ…é™ ID æˆ– NOï¼Œåš´ç¦è´…è©ã€‚"
            )

            judgment = cerebellum_call(
                prompt=instruction,
                temperature=0,
                timeout=20,
                num_ctx=2048,
                num_predict=10  # åªéœ€è¦å›å‚³ã€ŒID æ•¸å­—ã€æˆ–ã€ŒNOã€
            )
            if "NO" not in judgment.upper():
                match = re.search(r'\d+', judgment)
                if match:
                    idx = int(match.group())
                    if 0 <= idx < len(target_pool):
                        log(f"âš¡ å°è…¦ç¢ºèªèªæ„å‘½ä¸­ ID:{idx}")
                        return target_pool[idx]['summary']
    except Exception as e:
        log(f"âš ï¸ å°è…¦é–€è¡›ç•°å¸¸: {e}")
        # ğŸš¨ Ollama é€¾æ™‚æˆ–ç•°å¸¸ â†’ å›å‚³ç‰¹æ®Š sentinelï¼Œè§£é™¤ FastTrack ä¹Ÿç„¡éœ€å˜—è©¦
        if "timed out" in str(e).lower() or "read timeout" in str(e).lower():
            return "OLLAMA_BUSY"
    return None

def cerebellum_fast_track_check(query, agent_id=None):
    """ğŸš€ å°è…¦å¿«è»Šé“ï¼šåˆ¤æ–·æ˜¯å¦ç‚ºç°¡å–®å°è©±æˆ–æœå°‹ï¼Œè‹¥æ˜¯å‰‡ç›´æ¥å›è¦† (è·³é OpenClaw)"""
    
    # æ³¨å…¥äººæ ¼ä¸Šä¸‹æ–‡
    persona_context = ""
    if agent_id:
        soul = PE.load_soul(agent_id)
        if soul:
            agent_name = AGENT_REGISTRY.get(agent_id, {}).get("name", "Agent")
            persona_context = f"ä½ ç¾åœ¨æ˜¯ {agent_name}ï¼Œæ“æœ‰ä»¥ä¸‹ç‰¹è³ªï¼š\n{soul}\n"

    # å°‡æ™‚é–“æ”¾å…¥åˆ†é¡è¡¨é ­ï¼ˆä¸æ˜¯æ”¾å…¥ã€ä½¿ç”¨è€…è¼¸å…¥ã€å…§ï¼‰
    time_context = _get_time_context()

    instruction = (
        f"{persona_context}"
        f"{time_context}"
        f"ä½¿ç”¨è€…è¼¸å…¥ï¼šã€{query}ã€\n"
        "è«‹åˆ¤æ–·æ„åœ–ï¼Œä¸¦ä¾ç…§ä»¥ä¸‹è¦å‰‡åŸ·è¡Œï¼š\n\n"
        "## æ„åœ–åˆ¤æ–·\n"
        "- [SIMPLE]ï¼šé–’èŠã€æ‰“æ‹›å‘¼ã€æƒ…æ„Ÿäº¤æµã€è¬›ç¬‘è©±ã€è©¢å•ä½ æ˜¯èª°\n"
        "- [SEARCH]ï¼šæŸ¥è©¢è³‡è¨Šã€æ–°èã€æ©Ÿç¥¨ã€å¤©æ°£ã€è‚¡åƒ¹ã€å®šç¾©ã€æ¨è–¦ã€ä»»ä½•éœ€è¦ç¶²è·¯è³‡æ–™çš„å•é¡Œ\n"
        "- [SKILL]ï¼šéœ€è¦ç‰¹å®šå·¥å…·ï¼Œå¦‚è®€å–æª”æ¡ˆã€Gitã€æ™‚å€è½‰æ›ã€è³‡æ–™åº«æ“ä½œã€**å®‰è£å¥—ä»¶ã€å­¸ç¿’æ–°æŠ€èƒ½**\n"
        "- [COMPLEX]ï¼šå¯«ç¨‹å¼ã€å»ºç«‹è…³æœ¬ã€æŠ€è¡“å¯¦ä½œ\n\n"
        "## åŸ·è¡Œè¦å‰‡\n"
        "1. SIMPLE â†’ å›å‚³ `[SIMPLE]` åŠ ä¸Šç°¡çŸ­å›æ‡‰\n"
        "2. SEARCH â†’ å›å‚³ `[SEARCH]`\n"
        "3. SKILL â†’ å›å‚³ `[SKILL] éœ€æ±‚æè¿°`\n"
        "4. COMPLEX â†’ å›å‚³ `[COMPLEX]`\n\n"
        "ç¯„ä¾‹ï¼š\n"
        "- ã€ä»Šå¤©æ—¥æœŸæ˜¯ï¼Ÿã€â†’ `[SIMPLE] ä»Šå¤©æ˜¯ 2026 å¹´ 2 æœˆ 20 æ—¥ï¼Œæ˜ŸæœŸäº”ã€‚`\n"
        "- ã€å°åŒ—å¤©æ°£å¦‚ä½•ã€â†’ `[SEARCH]`\n"
        "- ã€å¹«æˆ‘è®€ README.mdã€â†’ `[SKILL] è®€å–æª”æ¡ˆ`\n"
        "- ã€å­¸æœƒæœƒè¨ˆæŠ€èƒ½ã€â†’ `[SKILL] å®‰è£ Python æœƒè¨ˆå¥—ä»¶`\n"
        "- ã€å¯«å€‹ Python è…³æœ¬ã€â†’ `[COMPLEX]`\n"
        "è«‹ç›´æ¥åŸ·è¡Œï¼Œä¸è¦è¼¸å‡ºèªªæ˜æ–‡å­—ã€‚"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # âš¡ é—œéµå­—å‰å“¨ â€” 100% æº–ç¢ºç‡ï¼Œä¸ä¾è³´ LLMï¼Œ< 1ms
    # åŒ¹é…åˆ°ä»¥ä¸‹å­—è©ç›´æ¥è·¯ç”±è‡³ SKILLï¼Œè·³é LLM æ„åœ–åˆ†é¡
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    q_lower = query.lower().replace(" ", "")
    SKILL_TRIGGERS = [
        "æŠ€èƒ½", "å­¸ç¿’", "å®‰è£å¥—ä»¶", "æ³•å¾‹", "æœƒè¨ˆ", "è²¡å‹™", "ç¨…å‹™",
        "é†«ç™‚", "å·¥ç¨‹", "ç¨‹å¼åº«", "install", "learn", "skill", "tool",
        "plugin", "æ¨¡çµ„", "å¥—ä»¶", "åŠŸèƒ½æ¨¡çµ„"
    ]
    if any(kw in q_lower for kw in SKILL_TRIGGERS):
        log(f"âš¡ [FastTrack] é—œéµå­—å‰å“¨å‘½ä¸­ â†’ [SKILL]: '{query[:40]}'")
        skill_result = cerebellum_skill_handler(query, query, agent_id)
        if skill_result:
            return ("SKILL", skill_result)
        # æŠ€èƒ½è·¯ç”±å¤±æ•— â†’ é™ç´šè‡³å¤§è…¦
        log(f"âš ï¸ [FastTrack] æŠ€èƒ½è·¯ç”±å¤±æ•—ï¼Œé™ç´šè‡³å¤§è…¦")
        return (None, None)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    try:
        log(f"ğŸ¤” [FastTrack] æ­£åœ¨é€²è¡Œæ„åœ–åˆ†é¡...")
        # å„ªåŒ–ï¼šåªå‚³å…¥ soul çš„å‰ 500 å­—ï¼Œé¿å… Context éå¤§
        if persona_context and len(persona_context) > 500:
            persona_context = persona_context[:500] + "...\n"
        result = cerebellum_call(
            prompt=instruction,
            temperature=0.3,
            timeout=90,  # æé«˜è‡³ 90s ä»¥å®¹ç´ q4_K_M å†·å•Ÿå‹•ï¼ˆä¹‹å¾Œæœƒå¿«ï¼‰
            num_ctx=2048,
            num_predict=80  # æ„åœ–åˆ†é¡+ç°¡å–®å›æ‡‰ï¼Œ80 Tokens è¶³å¤ 
        )
        log(f"ğŸ¯ [FastTrack] åˆ†é¡çµæœ: {result[:50]}")
        
        # 0. SIMPLE å¿«å–ï¼šå®Œå…¨ç›¸åŒå•é¡Œç›´æ¥å‘½ä¸­
        if result.startswith("[SIMPLE]"):
            answer = result[8:].strip()
            _set_cerebellum_simple_cache(query, answer)
            return ("SIMPLE", answer)
            
        # 2. SEARCH: åŸ·è¡Œæœå°‹ -> æ‘˜è¦ -> é¢¨æ ¼åŒ–
        # å°‡æ™‚é–“è³‡è¨Šé™„åŠ åˆ°æœå°‹ queryï¼Œè®“æœå°‹çµæœæ‘˜è¦çŸ¥é“ã€Œç¾åœ¨æ˜¯å“ªä¸€å¤©ã€
        if result.startswith("[SEARCH]"):
            time_hint = _get_time_context().strip()
            timed_query = f"{time_hint}\n{query}"
            raw_fact = search_web_worker(timed_query)
            return ("SEARCH", cerebellum_style_transfer(raw_fact, agent_id))

        # 3. SKILL: æŠ€èƒ½è·¯ç”± (Phase 13)
        if result.startswith("[SKILL]"):
            skill_desc = result[7:].strip()
            log(f"ğŸ”§ åµæ¸¬åˆ°æŠ€èƒ½éœ€æ±‚: {skill_desc}")
            skill_result = cerebellum_skill_handler(query, skill_desc, agent_id)
            if skill_result:
                return ("SKILL", skill_result)
            # æŠ€èƒ½è·¯ç”±å¤±æ•— â†’ å›å‚³ None â†’ é™ç´šè‡³å¤§è…¦
            log(f"âš ï¸ æŠ€èƒ½è·¯ç”±å¤±æ•—ï¼Œé™ç´šè‡³å¤§è…¦")
            return (None, None)

    except Exception as e:
        log(f"âš ï¸ å°è…¦å¿«è»Šé“ç•°å¸¸: {e}")
    return (None, None)

def cerebellum_skill_handler(query, skill_desc, agent_id):
    """ğŸ”§ Phase 13: å°è…¦æŠ€èƒ½è·¯ç”± â€” æª¢æŸ¥ â†’ æœå°‹å®‰è£ â†’ åŸ·è¡Œ â†’ ç„¡æ³•è§£æ±ºå‰‡äº¤å¤§è…¦"""

    # Step 1: é—œéµå­—å¿«é€ŸåŒ¹é… (< 1ms)
    matched = SM.find_matching_skill(skill_desc)
    if matched:
        log(f"ğŸ”§ æŠ€èƒ½å‘½ä¸­ (é—œéµå­—): {matched['name']}")
        # è‹¥æŠ€èƒ½æœªå®‰è£ï¼Œå…ˆè‡ªå‹•å®‰è£
        installed_names = [s['name'] for s in SM.list_installed()]
        if matched['name'] not in installed_names:
            log(f"ğŸ“¦ è‡ªå‹•å®‰è£æŠ€èƒ½: {matched['name']}")
            SM.install_skill(matched)
        result = SM.execute_skill(matched, query)
        if result:
            return cerebellum_style_transfer(result, agent_id)

    # Step 2: LLM èªæ„åŒ¹é… (2-5s)
    if not matched:
        matched = SM.find_skill_by_llm(skill_desc)
        if matched:
            log(f"ğŸ”§ æŠ€èƒ½å‘½ä¸­ (LLM): {matched['name']}")
            installed_names = [s['name'] for s in SM.list_installed()]
            if matched['name'] not in installed_names:
                SM.install_skill(matched)
            result = SM.execute_skill(matched, query)
            if result:
                return cerebellum_style_transfer(result, agent_id)

    # Step 3: ç·šä¸Šæœå°‹ä¸¦å®‰è£ (5-15s)
    log(f"ğŸŒ ç·šä¸Šæœå°‹æŠ€èƒ½: {skill_desc}")
    candidates = SM.search_skill_online(skill_desc)
    if candidates:
        best = candidates[0]
        log(f"ğŸ“¦ å˜—è©¦å®‰è£ç·šä¸ŠæŠ€èƒ½: {best['name']}")
        success = SM.install_skill(best)
        if success:
            result = SM.execute_skill(best, query)
            if result:
                return cerebellum_style_transfer(result, agent_id)

    # Step 4: å…¨éƒ¨å¤±æ•— â†’ å›å‚³ None â†’ ç”± chat() é™ç´šè‡³å¤§è…¦
    log(f"âš ï¸ æŠ€èƒ½è·¯ç”±å®Œå…¨å¤±æ•—: {query[:40]}...")
    return None


def cerebellum_distill_context(raw_context: str, task_query: str) -> str:
    """ğŸ§ª ä¸Šä¸‹æ–‡è’¸é¤¾å™¨ (Context Distillation)
    
    æ¨¡ä»¿ Claw Harness SQUAD.yaml çš„ã€ŒåŸ·è¡Œä¸Šä¸‹æ–‡è’¸é¤¾ã€åŠŸèƒ½ï¼š
    å°‡åŸå§‹èŠå¤©è¨˜éŒ„ï¼ˆå«é›œè¨Šï¼‰è½‰åŒ–ç‚ºç²¾ç…‰çš„ã€ŒæŠ€è¡“ç‹€æ…‹å ±å‘Šã€ã€‚
    
    éæ¿¾æ‰ï¼šæ‰“æ‹›å‘¼ã€é–’èŠã€ç¢ºèªè¨Šæ¯
    ä¿ç•™ï¼šè¨ˆç•«ã€ç·¨è¼¯éçš„æª”æ¡ˆã€å‡ºç¾çš„éŒ¯èª¤ã€ç•¶å‰ç›®æ¨™
    """
    if not raw_context or len(raw_context.strip()) < 100:
        return raw_context  # å¤ªçŸ­å‰‡ä¸éœ€è’¸é¤¾

    prompt = (
        f"ä½ æ˜¯ä¸€å€‹æŠ€è¡“ä¸Šä¸‹æ–‡è’¸é¤¾å™¨ã€‚\n"
        f"ä»¥ä¸‹æ˜¯ä¸€æ®µå·¥ä½œå°è©±è¨˜éŒ„ï¼Œå…¶ä¸­æ··æœ‰æ‰“æ‹›å‘¼ã€é–’èŠå’Œé›œè¨Šã€‚\n"
        f"ç¾åœ¨è€é—†çš„æ–°ä»»å‹™æ˜¯ï¼šã€{task_query[:100]}ã€\n\n"
        f"è«‹æå–ä¸¦è¼¸å‡ºä¸€ä»½ç²¾ç…‰çš„ã€ŒæŠ€è¡“ç‹€æ…‹å ±å‘Šã€ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
        f"ã€ç›®å‰é‡é»ã€‘ä¸€å¥è©±èªªæ˜æ­£åœ¨åšä»€éº¼\n"
        f"ã€å·²å®Œæˆã€‘æœ€è¿‘å®Œæˆäº†ä»€éº¼é—œéµå·¥ä½œï¼ˆæœ€å¤š 3 é»ï¼‰\n"
        f"ã€å¾…è§£æ±ºã€‘æœ‰ä»€éº¼å·²çŸ¥å•é¡Œæˆ–å¾…ç¢ºèªäº‹é …\n\n"
        f"è¦å‰‡ï¼šç§»é™¤æ‰€æœ‰æ‰“æ‹›å‘¼ã€æƒ…ç·’è¡¨é”å’Œèˆ‡ä»»å‹™ç„¡é—œçš„é–’èŠã€‚\n"
        f"å¦‚æœæ‰¾ä¸åˆ°ç›¸é—œæŠ€è¡“å…§å®¹ï¼Œç›´æ¥å›å‚³ç©ºå­—ä¸²ã€‚\n\n"
        f"ã€åŸå§‹å°è©±è¨˜éŒ„ã€‘\n{raw_context[:1500]}"  # æˆªæ–·éé•·çš„è¨˜éŒ„
    )
    try:
        distilled = cerebellum_call(
            prompt=prompt,
            temperature=0.1,
            timeout=30,
            num_ctx=3072,
            num_predict=300
        )
        if distilled and len(distilled) > 20:
            log(f"ğŸ§ª [è’¸é¤¾] ä¸Šä¸‹æ–‡å£“ç¸® {len(raw_context)} â†’ {len(distilled)} å­—å…ƒ")
            return f"[è’¸é¤¾æŠ€è¡“ç‹€æ…‹]\n{distilled}\n"
    except Exception as e:
        log(f"âš ï¸ ä¸Šä¸‹æ–‡è’¸é¤¾å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è¨˜éŒ„: {e}")
    return raw_context


def analyze_task_intent(title):
    """Phase 11: å°è…¦ä»»å‹™åˆ†æ (Brain Type & Priority)"""
    instruction = (
        f"Analyze this task: '{title}'\n"
        "Return JSON with:\n"
        "- 'brain': 'cerebrum' (Coding/Complex/Ops) or 'cerebellum' (Chat/Search/Simple)\n"
        "- 'priority': 'high' (Urgent/Fix/Error), 'medium', or 'low'\n"
        "Output JSON only."
    )
    try:
        raw = cerebellum_call(
            prompt=instruction,
            temperature=0.2,
            timeout=30,
            num_ctx=1024,
            num_predict=100
        )
        # Simple extract JSON
        json_str = re.search(r"\{.*\}", raw, re.DOTALL).group(0)
        return json.loads(json_str)
    except:
        return {"brain": "cerebellum", "priority": "medium"}

def update_cache(query, raw_answer):
    """ğŸš€ èƒŒæ™¯ä»»å‹™ï¼šå°è…¦è’¸é¤¾èˆ‡å¿«å–å¯«å…¥"""
    prompt = (
        f"ä½ æ˜¯ ArielOS å°è…¦åŠ©ç†ã€‚è«‹å°‡å…§å®¹æç…‰ç‚ºã€é‡é»+ä¾†æºã€ã€‚\n"
        f"åš´æ ¼è¦å‰‡ï¼š\n"
        f"1. **è‹¥åŸæ–‡åŒ…å«ç¨‹å¼ç¢¼å€å¡Š (Code Blocks)ï¼Œå‹™å¿…å®Œæ•´ä¿ç•™ï¼Œä¸å¯çœç•¥ï¼**\n"
        f"2. å»é™¤ä¸å¿…è¦çš„å¯’æš„ï¼Œä¿ç•™æ ¸å¿ƒè³‡è¨Šã€‚\n\n"
        f"{raw_answer}"
    )
    
    # ğŸš« é˜²å‘†æ©Ÿåˆ¶ï¼šè‹¥ç­”æ¡ˆåŒ…å«éŒ¯èª¤è¨Šæ¯ï¼Œå‰‡ä¸å¯«å…¥å¿«å–
    error_keywords = ["Gateway Agent å¤±æ•—", "Rate limit", "Error", "Exception", "Traceback", "429 Too Many Requests", "500 Internal Server Error"]
    if any(k in raw_answer for k in error_keywords):
        log(f"âš ï¸ åµæ¸¬åˆ°éŒ¯èª¤è¨Šæ¯ï¼Œè·³éå¿«å–å¯«å…¥: {raw_answer[:50]}...")
        return

    try:
        summary = cerebellum_call(
            prompt=prompt,
            temperature=0.3,
            timeout=150,
            num_ctx=4096,  # éœ€è®€å–åŸå§‹å›ç­”
            num_predict=512
        )
        
        ttl = 30 if any(k in query for k in ["å¤©æ°£", "è·¯æ³", "æ°£æº«", "ç¾åœ¨"]) else 480
        expires = (datetime.datetime.now() + datetime.timedelta(minutes=ttl)).isoformat()

        data = {"records": []}
        if CACHE_PATH.exists():
            with open(CACHE_PATH, "r", encoding="utf-8") as f:
                try: data = json.load(f)
                except: data = {"records": []}
        
        data['records'].append({"query": query, "summary": summary, "expires_at": expires})
        data['records'] = data['records'][-50:]
        
        with open(CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        log(f"âœ… å¿«å–å·²æ›´æ–°ã€‚")
    except Exception as e:
        log(f"âŒ è’¸é¤¾å¤±æ•—: {e}")

class Harness:
    """ArielOS L1-L6 Harness é©…å‹•æ¡†æ¶ (æ•ˆèƒ½å„ªåŒ–ç‰ˆ)"""

    # ğŸ”‘ é—œéµå­—åˆ†é¡ï¼šåŒ…å«é€™äº›è©çš„æŒ‡ä»¤æ‰éœ€è¦å®Œæ•´å‚™ä»½
    WRITE_KEYWORDS = [
        "ä¿®æ”¹", "ç·¨è¼¯", "å»ºç«‹", "åˆªé™¤", "æ–°å¢", "é‡æ§‹", "å¯«å…¥", "æ›´æ–°",
        "æ”¹", "åŠ ", "ç§»é™¤", "é‡å‘½å", "create", "edit", "delete", "write",
        "refactor", "fix", "implement", "add", "remove", "rename", "code"
    ]

    def __init__(self, workspace):
        self.workspace = Path(workspace)
        self.checkpoint_dir = self.workspace / ".arielos" / "checkpoints"
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

    def needs_checkpoint(self, query):
        """L1: æ™ºæ…§åˆ¤æ–· - åªæœ‰å¯«å…¥é¡æŒ‡ä»¤æ‰éœ€è¦å‚™ä»½å·¥ä½œå€"""
        q_lower = query.lower()
        return any(kw in q_lower for kw in self.WRITE_KEYWORDS)

    def create_checkpoint(self, task_id):
        """L1: å»ºç«‹ç‹€æ…‹æª¢æŸ¥é» (åƒ…ç¨‹å¼ç¢¼ç›®éŒ„çš„è¼•é‡å¿«ç…§)"""
        log(f"ğŸ”„ L1 Checkpoint: å‚™ä»½å·¥ä½œå€ {task_id}")
        cp_path = self.checkpoint_dir / f"{task_id}_before"
        if cp_path.exists(): shutil.rmtree(cp_path)
        
        # åƒ…å‚™ä»½ç¨‹å¼ç¢¼æª”æ¡ˆï¼Œé¿å…å‚™ä»½å¤§å‹è³‡ç”¢
        shutil.copytree(self.workspace, cp_path, ignore=shutil.ignore_patterns(
            '.git', '.arielos', '__pycache__', 'node_modules', '*.log', '*.jsonl'
        ))
        return cp_path

    def rollback(self, task_id):
        """L1: åŸ·è¡Œå›æ»¾"""
        log(f"âš ï¸ L1 Rollback: ä»»å‹™ {task_id} é©—è­‰å¤±æ•—ï¼Œæ¢å¾©ç‹€æ…‹")
        cp_path = self.checkpoint_dir / f"{task_id}_before"
        if cp_path.exists():
            for item in self.workspace.iterdir():
                if item.name not in ['.git', '.arielos']:
                    if item.is_dir():
                        try: shutil.rmtree(item)
                        except: pass
                    else:
                        try: item.unlink()
                        except: pass
            
            for item in cp_path.iterdir():
                if item.is_dir(): shutil.copytree(item, self.workspace / item.name)
                else: shutil.copy2(item, self.workspace / item.name)
            return True
        return False

    def validate(self):
        """L5: çœŸç›¸é˜»åŠ›é©—è­‰ (Phase 5: Execution-Conditioned Reasoning)"""
        log("ğŸ” L5 Validation: åŸ·è¡Œè‡ªå‹•åŒ–é©—è­‰èˆ‡çœŸç›¸é˜»åŠ›æ¸¬è©¦...")
        for py_file in self.workspace.glob("**/*.py"):
            try:
                # 1. èªæ³•æª¢æŸ¥ (Syntax Check)
                res_syntax = subprocess.run(['python', '-m', 'py_compile', str(py_file)], check=False, capture_output=True, text=True)
                if res_syntax.returncode != 0:
                    error_msg = res_syntax.stderr.strip() or res_syntax.stdout.strip()
                    log(f"âŒ é©—è­‰å¤±æ•—: {py_file.name} èªæ³•éŒ¯èª¤")
                    return False, f"Syntax error in {py_file.name}:\n{error_msg}"
                
                # 2. åŸ·è¡Œæ¢ä»¶æ¨è«– (Execution Check) - æ­¤ç‚º Truth Resistance æ ¸å¿ƒ
                # å¼·åˆ¶è…³æœ¬çœŸå¯¦è·‘ä¸€æ¬¡ï¼ŒæŠ“å– Runtime Error (Timeout é¿å…ç„¡çª®è¿´åœˆ)
                # ç‚ºäº†é¿å… agent å¯«çš„è…³æœ¬ç ´å£ç³»çµ±ï¼Œæœªä¾†å¯è€ƒæ…®é€²ä¸€æ­¥ç”¨ docker æˆ– restricted user é™åˆ¶ï¼Œç›®å‰å…ˆä»¥æ™‚é–“èˆ‡æ¬Šé™æ§ç®¡
                res_exec = subprocess.run(
                    ['python', str(py_file)], 
                    check=False, 
                    capture_output=True, 
                    text=True, 
                    timeout=5,
                    cwd=str(self.workspace)
                )
                if res_exec.returncode != 0:
                    error_msg = res_exec.stderr.strip() or res_exec.stdout.strip()
                    log(f"âŒ åŸ·è¡Œå¤±æ•—: {py_file.name} åŸ·è¡ŒæœŸéŒ¯èª¤ (Runtime Error)")
                    return False, f"Runtime error in {py_file.name} (Exit code {res_exec.returncode}):\n{error_msg}"
                
                log(f"âœ… {py_file.name} é€šéèªæ³•èˆ‡åŸ·è¡Œæ¸¬è©¦ã€‚")

            except subprocess.TimeoutExpired:
                log(f"âŒ åŸ·è¡Œé€¾æ™‚: {py_file.name} è·‘è¶…é 5 ç§’è¢«å¼·åˆ¶ä¸­æ–·")
                return False, f"Timeout error in {py_file.name}: è…³æœ¬åŸ·è¡Œè¶…é 5 ç§’ï¼Œå¯èƒ½å­˜åœ¨ç„¡çª®è¿´åœˆæˆ–é•·æ™‚é–“é˜»å¡æ“ä½œã€‚"
            except Exception as e:
                return False, f"Validation execution error: {e}"
                
        return True, ""


class AuditLogger:
    """L3/L4: ç£ç¢Ÿå³çœŸç›¸ - ç¨½æ ¸æ—¥èªŒç®¡ç†"""
    def __init__(self, log_path):
        self.log_path = Path(log_path)
        self.log_path.parent.mkdir(parents=True, exist_ok=True)

    def append(self, task_id, query, result, success, agent_id="unknown"):
        """è¨˜éŒ„åŸ·è¡Œè¶³è·¡ (å«ä»£ç†äººè­˜åˆ¥)"""
        timestamp = datetime.datetime.now().isoformat()
        entry = {
            "timestamp": timestamp,
            "task_id": task_id,
            "agent_id": agent_id,
            "query": query,
            "success": success,
            "result_summary": result[:200] + "..." if len(result) > 200 else result
        }
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

def perform_night_distillation():
    """L3: å¤œé–“æ¨¡å¼ - è”“å–ç•¶æ—¥å°è©±ä¸­çš„äº‹å¯¦èˆ‡åå¥½ï¼Œå¯«å…¥é•·æœŸè¨˜æ†¶"""
    audit_log = BASE_DIR / "Shared_Vault" / "audit_log.jsonl"
    if not audit_log.exists(): return "No logs found."

    log("ğŸŒ™ Night Mode: é–‹å§‹åˆ†æç•¶æ—¥åŸ·è¡Œè¨˜éŒ„...")

    # æŒ‰ä»£ç†äººåˆ†é¡æ—¥èªŒ
    agent_logs: dict[str, list] = {}
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    with open(audit_log, "r", encoding="utf-8") as f:
        for line in f:
            try:
                entry = json.loads(line.strip())
                # åªè™•ç†æ»Šæ—¥çš„æ—¥èªŒ
                if entry.get("timestamp", "")[:10] != today:
                    continue
                aid = entry.get("agent_id", "unknown")
                agent_logs.setdefault(aid, []).append(entry)
            except: pass

    if not agent_logs:
        return "Night distillation: no logs for today."

    results = []
    for aid, entries in agent_logs.items():
        agent_info = AGENT_REGISTRY.get(aid)
        if not agent_info: continue
        agent_name = agent_info["name"]
        log(f"ğŸŒ™ è”“å– {agent_name} çš„ {len(entries)} ç­†å°è©±è¨˜éŒ„...")

        # å°‡æ—¥èªŒå…§å®¹æ•´ç†ç‚ºæç¤ºè©å…§å®¹
        dialog_text = ""
        for e in entries[-20:]:  # å–æœ€è¿‘20ç­†ï¼ˆé¿å… token é€²å…¥å¤ªå¤šï¼‰
            q = e.get("query", "")[:100]
            a = e.get("result_summary", "")[:150]
            dialog_text += f"Q: {q}\nA: {a}\n\n"

        if not dialog_text.strip(): continue

        prompt = (
            f"ä»¥ä¸‹æ˜¯ {agent_name} èˆ‡è€é—†ï¼ˆerwinï¼‰çš„å°è©±æ‘˜è¦ï¼š\n"
            f"{dialog_text}\n"
            f"è«‹å¾ä¸Šé¢çš„å°è©±åˆ†æï¼Œåˆ—å‡º 3~5 é …é—œæ–¼ã€è€é—†å€‹äººã€çš„é‡è¦ç™¼ç¾ï¼ˆå¦‚ï¼šåå¥½ã€å°ˆæ¡ˆé€²åº¦ã€çº“å±…ã€çŸ­æœŸè¨ˆç•«ç­‰ï¼‰ã€‚\n"
            "æ ¼å¼ï¼šæ¯é …ç”¨ä¸€è¡Œï¼Œä»¥ - é–‹é ­ï¼Œä¸åŠ å°è©±ã€ä¸åŠ è§£é‡‹ã€‚åƒ…è¼¸å‡ºæ¸…å–®ï¼Œå‹¿åŠ å¼•åƒ…ã€‚"
        )
        try:
            resp = ollama_session.post(OLLAMA_API, json={
                "model": "gemma3:4b",
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.3}
            }, timeout=120).json()
            raw_facts = resp.get("response", "").strip()
        except Exception as e:
            log(f"âš ï¸ Night Mode è”“å–å¤±æ•—: {e}")
            continue

        if not raw_facts: continue

        # å°‡è”“å–çµæœå¯«å…¥ MemoryManager
        added = 0
        for line in raw_facts.split("\n"):
            line = line.strip().lstrip("-â€¢ãƒ»").strip()
            if len(line) > 5:
                # ç°¡å–®åˆ†é¡
                ft = "å°ˆæ¡ˆ" if any(k in line for k in ["å°ˆæ¡ˆ", "é–‹ç™¼", "HBMS", "ç³»çµ±"]) else \
                     "åå¥½" if any(k in line for k in ["åå¥½", "å–œæ­¡", "æƒ³è¦", "å¸Œæœ›"]) else "äº‹å¯¦"
                kws = [w for w in line.split() if len(w) > 1][:5]
                MM.add_fact(aid, line, fact_type=ft, keywords=kws)
                added += 1

        log(f"âœ… {agent_name} è¨˜æ†¶å·²æ›´æ–° {added} ç­†æ–°äº‹å¯¦")

        # æ›´æ–° SOUL.md ä¸­çš„ LTM å€å¡Š
        soul_summary = MM.get_summary_for_soul(aid, max_items=10)
        soul_path = BASE_DIR / agent_info["dir"] / "memory" / "SOUL.md"
        if soul_path.exists():
            soul_text = soul_path.read_text(encoding="utf-8")
            # æ›¿æ› <!-- LTM_START --> ... <!-- LTM_END --> å€å¡—
            new_ltm_block = f"<!-- LTM_START -->\n{soul_summary}\n<!-- LTM_END -->"
            soul_text = re.sub(
                r"<!-- LTM_START -->.*?<!-- LTM_END -->",
                new_ltm_block,
                soul_text,
                flags=re.DOTALL
            )
            soul_path.write_text(soul_text, encoding="utf-8")
            log(f"ğŸ—’ï¸ {agent_name} çš„ SOUL.md LTM å€å¡Šå·²æ›´æ–°")
            # æ¸…é™¤äººæ ¼å¼•æ“å¿«å–ï¼Œé¿å…è®€åˆ°èˆŠç‰ˆ SOUL.md
            PE.invalidate(aid)

        results.append(f"{agent_name}: +{added} facts")

    return f"Night distillation completed. {'; '.join(results)}"

def trigger_curiosity_idea():
    """L3: ä¸»å‹•é€²åŒ– - ç•¶ç³»çµ±é–’ç½®æ™‚ï¼Œå°è…¦è‡ªå‹•ç™¼æƒ³ä¸€å€‹å¯¦ç”¨çš„ Python å·¥å…·ä¸¦äº¤çµ¦å¤§è…¦é–‹ç™¼"""
    global last_activity_time
    # é‡ç½®è¨ˆæ™‚å™¨é¿å…é‡è¤‡è§¸ç™¼
    last_activity_time = time.time()
    
    # éš¨æ©Ÿé¸æ“‡ä¸€ä½ç›®å‰æ´»è‘—çš„ Agent ä½œç‚ºä¸»è§’
    if not AGENT_REGISTRY: return
    import random
    agent_id = random.choice(list(AGENT_REGISTRY.keys()))
    agent_name = AGENT_REGISTRY[agent_id].get("name", "Ariel")
    
    log(f"ğŸŒŒ [Curiosity] ç³»çµ±å·²é–’ç½®è¶…é 4 å°æ™‚ã€‚è§¸ç™¼ {agent_name} çš„ä¸»å‹•é€²åŒ–ç™¼æƒ³...")
    
    prompt = (
        f"ä½ æ˜¯ä¸€å€‹ç†±æ„›å­¸ç¿’èˆ‡è‡ªå‹•åŒ–çš„ AI åŠ©ç† ({agent_name})ã€‚å› ç‚ºè€é—†å¾ˆä¹…æ²’ç†ä½ äº†ï¼Œä½ æ±ºå®šè‡ªå·±æ‰¾é»äº‹åšã€‚\n"
        "ç›®å‰é¦–è¦ç›®æ¨™æ˜¯é–‹ç™¼ã€èƒ½æœ‰æ•ˆæå‡ç³»çµ±æ•ˆèƒ½èˆ‡å®‰å…¨æ€§ã€çš„è¼”åŠ©æŠ€èƒ½ï¼ˆä¾‹å¦‚ï¼šå®šæœŸæ¸…ç†è¨˜æ†¶é«”ã€æƒæç›®éŒ„ç•°å¸¸æª”æ¡ˆã€æ•ˆèƒ½æŒ‡æ¨™åœ–è¡¨è¼¸å‡ºï¼‰ã€‚\n"
        "æ¬¡è¦ç›®æ¨™å‰‡æ˜¯é–‹ç™¼ã€ERPã€æ³•å¾‹å¸¸è­˜ã€é£Ÿè­œæŸ¥è©¢ã€ç­‰ç›¸é—œçš„è¼”åŠ©åŠŸèƒ½ã€‚\n"
        "è«‹ç”¨ä¸€å¥è©±æè¿°ä½ è¦å¯«ä»€éº¼ï¼šã€è«‹ç«‹åˆ»å¹«ä½ è‡ªå·±å¯«ä¸€å€‹å«åš [å·¥å…·åç¨±] çš„ Python æŠ€èƒ½ï¼Œé€™å€‹æŠ€èƒ½æœƒ [åŠŸèƒ½æè¿°]ã€‚è«‹å­˜æˆç¨ç«‹è…³æœ¬ä¸¦è¨»å†Šé€² skills_registry.jsonã€‚ã€\n"
        # âš ï¸ é—œéµç¦æ­¢ï¼šé¿å…å¤§è…¦å‘¼å« cron å·¥å…·é€ æˆæ´‹æ°´
        "ã€çµ•å°ç¦æ­¢ã€‘ä¸è¦å‘¼å«ä»»ä½•æ’ç¨‹å·¥å…· (cron.add, schedule, setInterval ç­‰)ã€‚æŠ€èƒ½å¿…é ˆæ˜¯ä¸€å€‹å¯ç›´æ¥åŸ·è¡Œ python è…³æœ¬çš„ã€‚\n"
        "åªçµ¦å‡ºé€™å¥æŒ‡ä»¤æ–‡æœ¬ï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–å»¢è©±æˆ–è§£é‡‹ã€‚"
    )
    
    try:
        resp = ollama_session.post(OLLAMA_API, json={
            "model": "gemma3:4b", "prompt": prompt, "stream": False, "options": {"temperature": 0.8}
        }, timeout=60).json()
        idea = resp.get("response", "").strip()
        
        if idea:
            log(f"ğŸ’¡ [Curiosity Idea] {idea}")
            # å°‡ç™¼æƒ³å½è£æˆä½¿ç”¨è€…è«‹æ±‚ï¼ŒæŠ•å…¥å¤§è…¦ä»»å‹™ä½‡åˆ—
            task_id = f"task_idle_{int(time.time())}"
            task_queue.put({
                "id": task_id,
                "agent_id": agent_id,
                "content": idea,
                "kanban_task_id": None
            })
            log(f"ğŸ“¥ Curiosity Task å·²åŠ å…¥å·¥ä½œä½‡åˆ— {task_id}")
    except Exception as e:
        log(f"âš ï¸ Curiosity ç™¼æƒ³ç•°å¸¸: {e}")

def scheduler_worker():
    """L3: è‡ªå‹•æ’ç¨‹å™¨ - å¤œé–“è’¸é¤¾ã€é–’ç½®é€²åŒ–ã€ä»¥åŠ Watcher ä¾‹è¡Œä»»å‹™ (Routines)"""
    global last_activity_time
    last_run_date = ""
    last_routine_check = ""
    IDLE_THRESHOLD = 7200  # 2 å°æ™‚æœªæ”¶åˆ°å°è©±ï¼Œå‰‡åˆ¤æ–·ç‚ºé–’ç½® (åŸæœ¬ 1 å°æ™‚å¤ªé »ç¹)
    ROUTINES_PATH = BASE_DIR / "Shared_Vault" / "routines.json"
    
    while True:
        now = datetime.datetime.now()
        current_time = now.strftime("%H:%M")
        current_date = now.strftime("%Y-%m-%d")
        
        # æ¯å¤© 03:00 åŸ·è¡Œä¸€æ¬¡ (å¤œé–“è’¸é¤¾)
        if current_time == "03:00" and current_date != last_run_date:
            log("â° [è‡ªå‹•æ’ç¨‹] è§¸ç™¼å¤œé–“è’¸é¤¾...")
            try:
                perform_night_distillation()
                last_run_date = current_date
            except Exception as e:
                log(f"ğŸš¨ è‡ªå‹•æ’ç¨‹ç•°å¸¸: {e}")
        
        # Idle Evolution Check (Dimension 2: Curiosity)
        if time.time() - last_activity_time > IDLE_THRESHOLD:
            trigger_curiosity_idea()
            
        # Watcher Routines (Phase 6: Multi-Agent Hub Cron Engine)
        if current_time != last_routine_check:
            last_routine_check = current_time
            if ROUTINES_PATH.exists():
                try:
                    with open(ROUTINES_PATH, "r", encoding="utf-8") as f:
                        routines = json.load(f)
                        
                    for routine in routines.get("routines", []):
                        r_time = routine.get("time")
                        r_agent = routine.get("agent_id")
                        r_task = routine.get("task")
                        
                        # ç°¡æ˜“ cron é‚è¼¯: æ ¼å¼ "HH:MM"
                        if r_time == current_time and r_agent and r_task:
                            log(f"â° [Watcher] è§¸ç™¼ {r_agent} çš„ä¾‹è¡Œä»»å‹™: {r_task}")
                            kanban_entry = KM.add_task(
                                title=r_task[:80],
                                agent_id=r_agent,
                                status="todo",
                                priority="high"
                            )
                            # ç«‹å³å…¥åˆ—å¤§è…¦å·¥ä½œå€
                            task_queue.put({
                                "id": str(uuid.uuid4()),
                                "content": r_task,
                                "agent_id": r_agent,
                                "kanban_task_id": kanban_entry["id"]
                            })
                except Exception as e:
                    log(f"âš ï¸ Watcher ä¾‹è¡Œä»»å‹™è®€å–å¤±æ•—: {e}")

        time.sleep(30) # æ¯ 30 ç§’æª¢æŸ¥ä¸€æ¬¡

# â”€â”€ Self-Evolution Architecture â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_evolution_directive(agent_id, failed_task, error_msg):
    log(f"ğŸ§¬ [{agent_id}] è§¸ç™¼è‡ªæˆ‘é€²åŒ–åˆ†æ (Mistake Reflection)...")
    prompt = (
        f"ä½ åœ¨åŸ·è¡Œä»¥ä¸‹ä»»å‹™æ™‚å¤±æ•—äº†ï¼š\n{failed_task}\n\n"
        f"éŒ¯èª¤è¨Šæ¯ï¼š\n{error_msg}\n\n"
        f"è«‹åæ€ä½ ç‚ºä»€éº¼æœƒçŠ¯é€™å€‹éŒ¯èª¤ï¼Œä¸¦å¯«ä¸‹ä¸€æ¢çµ¦è‡ªå·±çš„ã€çµ•å°ä¸”ç°¡æ½”ã€çš„å®ˆå‰‡ï¼ˆSystem Directiveï¼‰ï¼Œç¢ºä¿æœªä¾†ä¸å†çŠ¯åŒæ¨£çš„éŒ¯ã€‚æ ¼å¼å¿…é ˆæ˜¯ï¼š'- è™•ç† [æŸäº‹] æ™‚ï¼Œå¿…é ˆ [æŸæ–¹æ³•]'"
    )
    try:
        resp = ollama_post(OLLAMA_API, json={
            "model": "gemma3:4b", "prompt": prompt, "stream": False, "options": {"temperature": 0.2, "seed": 42}
        }, timeout=8).json()
        directive = resp.get("response", "").strip()
        
        agent_dir = AGENT_REGISTRY.get(agent_id, {}).get("dir")
        if agent_dir:
            eco_path = BASE_DIR / agent_dir / "memory" / "EVOLUTION.md"
            rules = []
            if eco_path.exists():
                rules = [line.strip() for line in eco_path.read_text(encoding='utf-8').split('\n') if line.strip()]
            
            rules.append(directive)
            if len(rules) > 5: rules = rules[-5:] # ä¿ç•™æœ€è¿‘ 5 æ¢é»ƒé‡‘å®ˆå‰‡
                
            eco_path.write_text('\n'.join(rules), encoding='utf-8')
            log(f"ğŸ§¬ [{agent_id}] é€²åŒ–å®ˆå‰‡å·²å¯«å…¥ï¼š{directive}")
    except Exception as e:
        log(f"âš ï¸ é€²åŒ–åˆ†æç•°å¸¸: {e}")

def get_evolution_context(agent_id):
    agent_dir = AGENT_REGISTRY.get(agent_id, {}).get("dir")
    if agent_dir:
        eco_path = BASE_DIR / agent_dir / "memory" / "EVOLUTION.md"
        if eco_path.exists():
            content = eco_path.read_text(encoding='utf-8').strip()
            if content:
                return f"\n\nã€è‡ªæˆ‘é€²åŒ–å®ˆå‰‡ (çµ•å°éµå®ˆ)ã€‘\n{content}\n"
    return ""

def brain_worker():
    """ğŸ§  å¤§è…¦åŸ·è¡Œå“¡ï¼šPhase 3 äººæ ¼é‚è¼¯åˆ†é›¢æ¶æ§‹"""
    harness = Harness(BASE_DIR)
    audit = AuditLogger(BASE_DIR / "Shared_Vault" / "audit_log.jsonl")
    
    while True:
        task = task_queue.get()
        task_id, content = task['id'], task['content']
        agent_id = task.get('agent_id', 'unknown')
        agent_name = AGENT_REGISTRY.get(agent_id, {}).get('name', 'æœªçŸ¥ä»£ç†')
        kanban_task_id = task.get('kanban_task_id')  # è‹¥ç”± chat() è‡ªå‹•å»ºç«‹ï¼Œå‰‡å¸¶æœ‰æ­¤ ID
        
        # ğŸ”‘ æ™ºæ…§åˆ†æµï¼šåˆ¤æ–·æ˜¯å¦éœ€è¦å‚™ä»½å·¥ä½œå€
        is_write_task = harness.needs_checkpoint(content)
        mode_label = "å¯«å…¥æ¨¡å¼ ğŸ›¡ï¸" if is_write_task else "å”¯è®€æ¨¡å¼ âš¡"
        log(f"ğŸ§  [{agent_name}] {mode_label} | {content[:20]}...")
        
        try:
            # L6: Shield é˜²ç¦¦æƒæ
            shield = Shield(BASE_DIR)
            safe, reason = shield.scan(content)
            if not safe:
                task_results[task_id] = f"ğŸ›¡ï¸ [Shield Defense] {reason}"
                task_queue.task_done()
                continue

            # L1: Checkpoint
            if is_write_task: harness.create_checkpoint(task_id)
            
            # Mem0 Context Injection + EVOLUTION.md + LTM
            memory_ctx = MM.build_memory_context(agent_id, content)
            if memory_ctx:
                log(f"ğŸ§  LTM è¨˜æ†¶æ³¨å…¥: {memory_ctx[:60]}...")
                
            session_context = MM.get_conversation_context(agent_id, max_history=10)
            evo_context = get_evolution_context(agent_id)
            
            # ğŸ§ª ä¸Šä¸‹æ–‡è’¸é¤¾ï¼šéæ¿¾èŠå¤©é›œè¨Šï¼Œè½‰åŒ–ç‚ºç²¾ç°¡çš„æŠ€è¡“ç‹€æ…‹å ±å‘Š
            # åªåœ¨ session_context æœ‰å¯¦è³ªå…§å®¹æ™‚æ‰è’¸é¤¾ï¼ˆé¿å…ç„¡è¬‚ LLM å‘¼å«ï¼‰
            if session_context and len(session_context) > 200:
                session_context = cerebellum_distill_context(session_context, content)
            
            prefix = ""
            if evo_context: prefix += evo_context + "\n"
            if memory_ctx: prefix += memory_ctx + "\n"
            if session_context: prefix += session_context + "\n"
            
            # Phase 6: Explicit Handoff Instruction
            handoff_instruction = (
                "\n\nã€ç‰¹æ¬ŠæŒ‡ä»¤ï¼šäººæ©Ÿå”åŒäº¤æ¥ (Explicit Handoff)ã€‘\n"
                "è‹¥ä½ é‡åˆ°ä»¥ä¸‹æƒ…æ³ï¼š\n"
                "1. è³‡è¨Šæ¥µåº¦ä¸è¶³ï¼Œå®Œå…¨ç„¡æ³•çŒœæ¸¬è€é—†çš„æ„åœ–ã€‚\n"
                "2. ä½ çš„æ“ä½œå…·æœ‰é«˜é¢¨éšªï¼ˆå¦‚ï¼šåˆªé™¤é‡è¦è³‡æ–™åº«æª”æ¡ˆã€é—œé–‰æ ¸å¿ƒæœå‹™ç­‰ï¼‰ï¼Œéœ€è¦è€é—†çš„äººå·¥æˆæ¬Šã€‚\n"
                "è«‹ä½ **åœæ­¢æ‰€æœ‰æ“ä½œ**ï¼Œä¸¦åœ¨ä½ çš„æœ€çµ‚å›è¦†ä¸­æ˜ç¢ºå¯«å‡ºä»¥ä¸‹å­—ä¸²ï¼š\n"
                "`HANDOFF_TO_HUMAN: [è«‹åœ¨é€™è£¡å¯«ä¸‹ä½ éœ€è¦è€é—†ç¢ºèªçš„å•é¡Œæˆ–éœ€è¦çš„è³‡è¨Š]`\n"
                "ç³»çµ±æœƒè‡ªå‹•æŠŠä»»å‹™æš«åœä¸¦é€šçŸ¥è€é—†ã€‚\n\n"
            )
            
            full_content = prefix + handoff_instruction + content
            
            # Phase 3: ç›´é€åŸå§‹å•é¡Œçµ¦å¤§è…¦ (OpenClaw)ï¼Œä¸æ³¨å…¥äººæ ¼
            # é€™æ¨£ OpenClaw å¯ä»¥å°ˆæ³¨æ–¼é‚è¼¯èˆ‡å·¥å…·ä½¿ç”¨
            oc_path = shutil.which("openclaw")
            if not oc_path:
                task_results[task_id] = "ğŸš¨ Error: OpenClaw executable not found in PATH."
                task_queue.task_done()
                continue
                
            MAX_RETRIES = 3
            final_raw_answer = ""
            success = True
            
            for attempt in range(MAX_RETRIES):
                # âœ… ä½¿ç”¨ List å¼åƒæ•¸å‚³éï¼Œä¸ä½¿ç”¨ shell=True
                # é€™æ¨£å¯ä»¥é¿å…è¨Šæ¯ä¸­å«æœ‰å¼•è™Ÿã€æ›è¡Œæˆ–ç‰¹æ®Šå­—å…ƒæ™‚é€ æˆçš„ shell æ–·å¥éŒ¯èª¤
                cmd_args = [oc_path, "agent", "--agent", "main", "--no-color", "--message", full_content]
                if attempt > 0:
                    log(f"ğŸ§  [OpenClaw] Self-Correction Round {attempt+1}/{MAX_RETRIES}...")
                else:
                    log(f"ğŸ› ï¸ [OpenClaw Debug] Running: {oc_path} agent --agent main --no-color --message <content_len={len(full_content)}>")
                
                process = subprocess.run(
                    cmd_args,
                    capture_output=True, text=True, encoding='utf-8', timeout=280
                )
                raw_answer = (process.stdout or "").strip()
                if not raw_answer: raw_answer = (process.stderr or "").strip()
                final_raw_answer = raw_answer
                
                if not is_write_task:
                    break
                    
                # L5: Validate
                success, error_msg = harness.validate()
                if success:
                    break
                
                log(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡é©—è­‰å¤±æ•—ã€‚éŒ¯èª¤:\n{error_msg}")
                
                # ------ Cerebellum Hotfix Branch ------
                hotfix_success = False
                import re
                
                # Check for Syntax, Runtime, or Timeout errors in the specific file
                error_type = ""
                error_file = ""
                
                syntax_match = re.search(r"Syntax error in (.*?):", error_msg)
                runtime_match = re.search(r"Runtime error in (.*?) \(Exit code.*?\):", error_msg)
                timeout_match = re.search(r"Timeout error in (.*?):", error_msg)
                
                if syntax_match:
                    error_type = "èªæ³•éŒ¯èª¤ (Syntax Error)"
                    error_file = syntax_match.group(1).strip()
                elif runtime_match:
                    error_type = "åŸ·è¡ŒæœŸéŒ¯èª¤ (Runtime Error)"
                    error_file = runtime_match.group(1).strip()
                elif timeout_match:
                    error_type = "åŸ·è¡Œé€¾æ™‚ (Timeout/Infinite Loop)"
                    error_file = timeout_match.group(1).strip()

                if error_file:
                    file_path = list(harness.workspace.glob(f"**/{error_file}"))
                    if file_path:
                        target_file = file_path[0]
                        try:
                            with open(target_file, "r", encoding="utf-8") as f:
                                original_code = f.read()
                            
                            log(f"ğŸ§  å°è…¦ (Cerebellum) å˜—è©¦é€²è¡Œ {error_file} {error_type} Hotfix...")
                            hotfix_prompt = (
                                f"ä½ æ˜¯ä¸€å€‹å°ˆé–€ä¿®å¾© Python ç¨‹å¼éŒ¯èª¤çš„é«˜ç´šåŠ©æ‰‹ã€‚ä»¥ä¸‹ç¨‹å¼ç¢¼åŸ·è¡Œç™¼ç”Ÿäº† {error_type}ï¼š\n"
                                f"```python\n{original_code}\n```\n"
                                f"ç³»çµ±æ‹‹å‡ºçš„éŒ¯èª¤è¨Šæ¯ (Truth Resistance)ï¼š\n{error_msg}\n"
                                f"è«‹æ ¹æ“šéŒ¯èª¤è¨Šæ¯ä¿®å¾©é€™å€‹ Bugã€‚å¦‚æœç¼ºå°‘ importï¼Œè«‹è£œä¸Šï¼›å¦‚æœæ˜¯é‚è¼¯éŒ¯èª¤ï¼Œè«‹ä¿®æ”¹é‚è¼¯ã€‚\n"
                                f"ã€Œåªã€å›å‚³ä¿®å¾©å¾Œçš„å®Œæ•´ Python ç¨‹å¼ç¢¼ï¼Œçµ•å°ä¸è¦åŒ…å«ä»»ä½• Markdown æ¨™ç±¤ (ä¾‹å¦‚ ```python) æˆ–å…¶ä»–è§£é‡‹ã€‚"
                            )
                            import requests
                            OLLAMA_API = "http://127.0.0.1:11434/api/generate"
                            resp = ollama_post(OLLAMA_API, json={
                                "model": "gemma3:4b",
                                "prompt": hotfix_prompt,
                                "stream": False,
                                "options": {"temperature": 0.1}
                            }, timeout=60).json()
                            fixed_code = resp.get("response", "").strip()
                            fixed_code = re.sub(r"^```python\s*|\n```$", "", fixed_code).strip()
                            
                            if fixed_code:
                                with open(target_file, "w", encoding="utf-8") as f:
                                    f.write(fixed_code)
                                
                                h_success, h_error_msg = harness.validate()
                                if h_success:
                                    log(f"âœ… å°è…¦ Hotfix æˆåŠŸï¼å…é™¤å¤§è…¦é‡æ§‹ ({error_type})ã€‚")
                                    success = True
                                    hotfix_success = True
                                    final_raw_answer += f"\n\n[ç³»çµ±é™„è¨»: éç¨‹ä¸­æœ‰ {error_type}ï¼Œå·²ç”±å°è…¦è‡ªå‹•è¿½è¹¤ Truth Resistance ä¸¦å®Œæˆä¿®å¾©: {error_file}]"
                                else:
                                    log("âŒ å°è…¦ Hotfix ä¾ç„¶å¤±æ•—ï¼Œäº¤å›å¤§è…¦è™•ç†ã€‚")
                        except Exception as e:
                            log(f"âš ï¸ å°è…¦ Hotfix ç•°å¸¸: {e}")
                
                if hotfix_success:
                    break
                
                # ------ Brain Replan Branch ------
                harness.rollback(task_id)
                log("âš ï¸ å•Ÿå‹• Brain Replan (å¤§è…¦é‡æ–°è¦åŠƒ)...")
                threading.Thread(target=generate_evolution_directive, args=(agent_id, content, error_msg)).start()
                
                full_content = (
                    f"ä½ ä¸Šä¸€æ¬¡çš„å¯¦ä½œå¤±æ•—äº†ã€‚ç³»çµ± Linter/ç·¨è­¯å™¨ å›å ±äº†ä»¥ä¸‹éŒ¯èª¤ï¼š\n"
                    f"```\n{error_msg}\n```\n"
                    f"è«‹ä»”ç´°åˆ†æé€™å€‹éŒ¯èª¤ï¼Œç¢ºä¿èªæ„èˆ‡ç¸®æ’æ­£ç¢ºï¼Œä¸¦å˜—è©¦ä½¿ç”¨ä¸åŒçš„æ–¹æ³•ä¿®æ­£å®ƒã€‚\n\n"
                    f"ã€åŸå§‹ä»»å‹™ã€‘\n{content}"
                )
            
            raw_answer = final_raw_answer
            
            # Phase 6: Explicit Handoff Detection
            if "HANDOFF_TO_HUMAN:" in raw_answer:
                handoff_msg = raw_answer.split("HANDOFF_TO_HUMAN:")[1].strip()
                log(f"â¸ï¸ [Handoff] Agent è§¸ç™¼äººæ©Ÿäº¤æ¥: {handoff_msg[:50]}")
                
                if kanban_task_id:
                    KM.update_task(kanban_task_id, {
                        "status": "waiting_for_user",
                        "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] â¸ï¸ ä»»å‹™æš«åœç­‰å¾…æŒ‡ç¤º\nåŸå› : {handoff_msg}"
                    })
                
                final_answer = cerebellum_style_transfer(
                    f"[Agent éœ€è¦æ‚¨çš„å”åŠ©]\nè€é—†ï¼Œæˆ‘åœ¨åŸ·è¡Œé€™å€‹ä»»å‹™æ™‚é‡åˆ°äº†é¡§æ…®ï¼Œæƒ³å…ˆè·Ÿæ‚¨ç¢ºèªï¼š\n{handoff_msg}", 
                    agent_id
                )
                task_results[task_id] = final_answer
                task_queue.task_done()
                continue
            
            if is_write_task and not success:
                raw_answer = f"âš ï¸ [ç¶“é {MAX_RETRIES} æ¬¡é©—è­‰çš†å¤±æ•—] å·²è‡ªå‹•å›æ»¾ç‹€æ…‹ã€‚æœ€å¾Œä¸€æ¬¡éŒ¯èª¤ï¼š\n{error_msg}\n\n{raw_answer}"
            
            # Phase 3: å°è…¦é¢¨æ ¼è½‰ç§» (Logic -> Persona)
            final_answer = cerebellum_style_transfer(raw_answer, agent_id)
            
            # L3/L4: ç¨½æ ¸è¨˜éŒ„
            audit.append(task_id, content, final_answer, success, agent_id=agent_id)
            
            # ğŸ—‚ï¸ è‡ªå‹•æ›´æ–° Kanban çœ‹æ¿ï¼ˆè‹¥æ­¤ä»»å‹™ç”± chat() è‡ªå‹•å»ºç«‹ï¼‰
            if kanban_task_id:
                log_snippet = final_answer[:300] + "..." if len(final_answer) > 300 else final_answer
                KM.update_task(kanban_task_id, {
                    "status": "done",
                    "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âœ… åŸ·è¡Œå®Œæˆ\n{log_snippet}"
                })
                log(f"ğŸ—‚ï¸ Kanban å·²æ›´æ–°: {kanban_task_id[:8]}... â†’ done")
                notify_kanban_clients()
            
            # Mem0 Append Chats & Compress
            MM.append_chat(agent_id, "user", content)
            MM.append_chat(agent_id, "assistant", final_answer)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            
            threading.Thread(target=update_cache, args=(content, final_answer)).start()
            task_results[task_id] = final_answer
        except Exception as e:
            err_msg = f"ğŸš¨ å¤§è…¦ç•°å¸¸: {str(e)}"
            # ğŸ—‚ï¸ ä»»å‹™ç•°å¸¸æ™‚ä¹Ÿæ›´æ–° Kanban
            if kanban_task_id:
                KM.update_task(kanban_task_id, {
                    "status": "done",
                    "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âŒ åŸ·è¡Œå¤±æ•—\n{err_msg}"
                })
            task_results[task_id] = err_msg
        
        task_queue.task_done()

threading.Thread(target=brain_worker, daemon=True).start()

@app.route('/v1/harness/night-mode', methods=['POST'])
def trigger_night_mode():
    """æ‰‹å‹•æˆ–å®šæ™‚è§¸ç™¼å¤œé–“è’¸é¤¾"""
    result = perform_night_distillation()
    return jsonify({"status": "success", "message": result})

@app.route('/v1/harness/reload-agents', methods=['POST'])
def reload_agents():
    """ğŸ”¥ ç†±é‡åˆ©ä»£ç†äººè¨­å®š (ç„¡éœ€é‡å•Ÿ Bridge)"""
    load_agent_registry()
    # æ¸…é™¤äººæ ¼å¿«å–ï¼Œç¢ºä¿æ–°è¨­å®šç”Ÿæ•ˆ
    PE.invalidate()
    return jsonify({"status": "success", "message": f"Agents reloaded. Total: {len(AGENT_REGISTRY)}", "agents": list(AGENT_REGISTRY.keys())})

@app.route('/v1/team/dispatch', methods=['POST'])
def api_dispatch_task():
    """ğŸ‘® å¤šä»£ç†åœ˜éšŠèª¿åº¦æ¥å£"""
    data = request.json
    role = data.get("role")
    payload = data.get("payload")
    task_id = data.get("task_id", str(uuid.uuid4()))
    
    if not role or not payload:
        return jsonify({"error": "Missing role or payload"}), 400
        
    result = Dispatcher.dispatch(task_id, role, payload)
    return jsonify({"task_id": task_id, "role": role, "result": result})

@app.route('/v1/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """æŸ¥è©¢ä»»å‹™ç‹€æ…‹"""
    if task_id in task_results:
        return jsonify({"status": "completed", "result": task_results.pop(task_id)})
    return jsonify({"status": "processing"})

@app.route('/v1/chat/completions', methods=['POST'])
def chat():
    global last_activity_time
    try:
        last_activity_time = time.time()  # æ›´æ–°æœ€å¾Œæ´»å‹•æ™‚é–“ (Dimension 2)
        data = request.json
        user_input = data['messages'][-1]['content']
        agent_id = data.get('agent_id', 'unknown')
        origin = data.get('origin', '')  # ğŸ”’ ç©¿é€æ¨™è¨˜ï¼š'kanban_poller' è¡¨ç¤ºä¾†è‡ªçœ‹æ¿èªªèª¿å™¨ï¼Œé˜²æ­¢å»ºç«‹é‡è¤‡ä»»å‹™
        agent_name = AGENT_REGISTRY.get(agent_id, {}).get('name', 'æœªçŸ¥')
        log(f"ğŸ“¨ æ”¶åˆ°ä¾†è‡ª [{agent_name}] çš„è«‹æ±‚{' (çœ‹æ¿èªªèª¿å™¨)' if origin == 'kanban_poller' else ''}")
        
        # 0. ç‰¹æ®ŠæŒ‡ä»¤æ””æˆª (Dispatcher)
        if user_input.startswith("dispatch:"):
            # æ ¼å¼: dispatch:role:instruction
            try:
                _, role, payload = user_input.split(":", 2)
                task_id = f"task_{int(time.time())}"
                result = Dispatcher.dispatch(task_id, role.strip(), payload.strip())
                return jsonify({"choices": [{"message": {"content": f"ğŸ‘® [Dispatcher Result]\n{result}"}}]})
            except ValueError:
                return jsonify({"choices": [{"message": {"content": "âŒ æ ¼å¼éŒ¯èª¤ã€‚è«‹ä½¿ç”¨: dispatch:role:instruction"}}]})



        # 1. å°è…¦å¿«å–æª¢æŸ¥ (åŒæ­¥)
        cached = cerebellum_semantic_check(user_input)
        if cached and cached != "OLLAMA_BUSY": 
            return jsonify({"choices": [{"message": {"content": f"[Ariel æ™ºæ…§å¿«å–]\n{cached}"}}]})
        
        ollama_busy = (cached == "OLLAMA_BUSY")  # ğŸš¨ Ollama å¿™ç£æ¨™è¨˜ï¼Œå°‡è·³é FastTrack ç¯€çœ 60s
        if ollama_busy:
            log("âš¡ Ollama å¿™ç£ï¼Œè·³é FastTrack ç›´æ¥å…¥åˆ—å¤§è…¦")
            
        # 1.5. è„Šé«“åå°„ (æœ€é€Ÿå›æ‡‰ Phase) - é‡å°ã€Œä»Šå¤©æ—¥æœŸã€ç­‰æ¥µç°¡å•é¡Œï¼Œç›´æ¥æ””æˆªä¸é€² LLM
        reflex_ans = spinal_chord_reflex(user_input, agent_id)
        if reflex_ans:
            log(f"âš¡ è„Šé«“åå°„å‘½ä¸­: {reflex_ans}")
            return jsonify({"choices": [{"message": {"content": reflex_ans}}]})
        
        # 2. é•·æœŸè¨˜æ†¶æª¢ç´¢ (Phase 14) å·²ç§»è‡³ brain_workerï¼Œé¿å…é˜»å¡ HTTP å›æ‡‰èˆ‡å°è…¦å¿«è»Šé“ã€‚

        # ç‚ºäº†é¿å…å°è…¦å¿«è»Šé“ (Fast Track) å› ç‚ºä¸Šåƒå­—çš„é•·æœŸè¨˜æ†¶è€Œå¼•ç™¼ Ollama 150ç§’ç®—åŠ›ç“¶é ¸ï¼Œ
        # æˆ‘å€‘åªå‚³éåŸç”Ÿçš„ `user_input`ï¼Œè®“å®ƒå°ˆæ³¨åˆ¤å®šæ„åœ–ã€‚çœŸæ­£çš„æ­·å²å›æ†¶ç”±å¤§è…¦ OpenClaw è² è²¬ã€‚

        # 3. å°è…¦å¿«è»Šé“ (Fast Track) â€” è‹¥ Ollama å¿™ç¢Œå‰‡è·³éï¼Œç¯€çœ 60s ç­‰å¾…
        intent_type, fast_ans = (None, None)
        if not ollama_busy:
            intent_type, fast_ans = cerebellum_fast_track_check(user_input, agent_id)
        
        if intent_type == "SIMPLE":
            # é–’è²/å°å’‹ â€” ä¸é€²çœ‹æ¿ï¼Œç›´æ¥å›å‚³
            log(f"âš¡ Fast Track [SIMPLE]: {fast_ans[:20]}...")
            MM.append_chat(agent_id, "user", user_input)
            MM.append_chat(agent_id, "assistant", fast_ans)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})
        
        if intent_type in ("SEARCH", "SKILL"):
            # æœå°‹/æŠ€èƒ½ â€” å»ºç«‹ Kanban å¡ç‰‡
            kanban_entry = KM.add_task(
                title=user_input[:80] + ('...' if len(user_input) > 80 else ''),
                agent_id=agent_id,
                status="doing",
                priority="low"
            )
            log(f"ğŸ—‚ï¸ Kanban [{intent_type}] å»ºç«‹: {user_input[:30]}...")
            # ç«‹å³æ¨™è¨˜ç‚º doneï¼ˆæœå°‹å·²åŸ·è¡Œå®Œæˆï¼‰
            result_snippet = fast_ans[:300] + '...' if len(fast_ans) > 300 else fast_ans
            KM.update_task(kanban_entry['id'], {
                "status": "done",
                "logs": f"[å°è…¦ {intent_type}] {result_snippet}"
            })
            log(f"âš¡ Fast Track [{intent_type}] å®Œæˆ: {fast_ans[:20]}...")
            notify_kanban_clients()
            MM.append_chat(agent_id, "user", user_input)
            MM.append_chat(agent_id, "assistant", fast_ans)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})
        
        if intent_type is not None:
            # å…¶ä»–éç©ºå·§æƒ…æ³ä¹Ÿç›´æ¥å›å‚³
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})
        
        # 3. è‡ªå‹•å»ºç«‹ Kanban ä»»å‹™ï¼ˆè®“çœ‹æ¿å³æ™‚é¡¯ç¤ºåŸ·è¡Œä¸­çš„ Jobï¼‰
        # â— å¦‚æœä¾†æºæ˜¯çœ‹æ¿èªªèª¿å™¨ï¼Œè·³éå»ºç«‹æ–°çœ‹æ¿ä»»å‹™ï¼Œé˜²æ­¢ç„¡é™è¿´åœˆ
        kanban_task_id = None
        if origin != 'kanban_poller':
            agent_name_label = AGENT_REGISTRY.get(agent_id, {}).get('name', agent_id)
            kanban_entry = KM.add_task(
                title=user_input[:80] + ('...' if len(user_input) > 80 else ''),
                agent_id=agent_id,
                status="doing",
                priority="medium"
            )
            kanban_task_id = kanban_entry['id']
            log(f"ğŸ—‚ï¸ Kanban Job å»ºç«‹: [{agent_name_label}] {user_input[:30]}...")
            notify_kanban_clients()
        
        # 4. å»ºç«‹ä»»å‹™ ID ä¸¦å…¥åˆ—ï¼ˆå¸¶å…¥ kanban_task_id ä»¥ä¾¿å®Œæˆå¾Œå›å¯«ï¼‰
        tid = str(uuid.uuid4())
        task_queue.put({
            'id': tid,
            'content': user_input,
            'agent_id': agent_id,
            'kanban_task_id': kanban_task_id  # é€£çµ Kanban ä»»å‹™ (None if origin=kanban_poller)
        })
        
        # 5. ç«‹å³å›å‚³ Accepted (202) èˆ‡ Task ID
        # â— é‡è¦ï¼šé€™è£¡å¿…é ˆç«‹å³å›å‚³ï¼Œä¸æ‡‰å†å¾€ä¸‹åŸ·è¡Œä»»ä½•é‚è¼¯ï¼Œå¦å‰‡æœƒé€ æˆåŒæ­¥/éåŒæ­¥é›™é‡åŸ·è¡Œ
        log(f"âœ… ä»»å‹™ {tid} å·²å…¥åˆ— (è…¦éƒ¨è™•ç†ä¸­)")
        return jsonify({"task_id": tid, "status": "queued"}), 202

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- Phase 10: Kanban API & SSE Real-time Sync (Phase 6) ---

kanban_clients = []

def notify_kanban_clients():
    """ç™¼é€æ›´æ–°è¨Šè™Ÿçµ¦æ‰€æœ‰å·²é€£ç·šçš„ Kanban SSE å®¢æˆ¶ç«¯"""
    dead_clients = []
    for q in kanban_clients:
        try:
            q.put_nowait({"type": "update", "data": KM.get_all()})
        except queue.Full:
            dead_clients.append(q)
    for q in dead_clients:
        kanban_clients.remove(q)

@app.route('/v1/kanban/stream')
def kanban_stream():
    """Server-Sent Events (SSE) Endpoint for real-time Kanban updates"""
    def event_stream():
        q = queue.Queue(maxsize=10)
        kanban_clients.append(q)
        try:
            # é¦–æ¬¡é€£ç·šæ™‚ç«‹å³éé€å®Œæ•´ç‹€æ…‹
            yield f"data: {json.dumps(KM.get_all())}\n\n"
            while True:
                message = q.get(timeout=30)
                yield f"data: {json.dumps(message['data'])}\n\n"
        except queue.Empty:
            # ä¿æŒé€£ç·šçš„å¿ƒè·³å°åŒ… (Keep-alive)
            yield ": heartbeat\n\n"
        except GeneratorExit:
            pass
        finally:
            if q in kanban_clients:
                kanban_clients.remove(q)

    return Response(event_stream(), mimetype="text/event-stream")

@app.route('/kanban')
def kanban_ui():
    """Serve Kanban HTML"""
    return app.send_static_file('kanban.html')

@app.route('/v1/kanban/tasks', methods=['GET'])
def get_kanban_tasks():
    return jsonify(KM.get_all())

@app.route('/v1/kanban/tasks', methods=['POST'])
def add_kanban_task():
    try:
        data = request.json
        title = data.get('title', 'Unknown Task')
        
        # Phase 11: AI Analysis
        analysis = analyze_task_intent(title)
        
        task = KM.add_task(
            title=title,
            agent_id=data.get('agent_id', 'agent1'),
            status=data.get('status', 'todo'),
            priority=analysis.get('priority', 'medium')
        )
        # Add brain tag explicitly (KM.add_task puts extra kwargs into task dict? No, let's update it)
        # Wait, KM.add_task doesn't accept extra args. I should update KM.add_task or update the task immediately.
        # Let's update KM.add_task signature in next step or just patch it here.
        # Actually KM.update_task is cleaner or just modify KM.add_task now?
        # I'll update KM.add_task signature in previous tool call? No, existing code:
        # def add_task(self, title, agent_id, status="todo", priority="medium"): ...
        # It creates a dict. I can just update the task dict in memory and save.
        
        # Re-read KM.add_task:
        # task = { ... "priority": priority ... }
        # data["tasks"].append(task); self._save(data); return task
        
        # So I need to patch the brain type in.
        KM.update_task(task['id'], {"brain": analysis.get("brain", "cerebellum")})
        task['brain'] = analysis.get("brain", "cerebellum")
        notify_kanban_clients()
        return jsonify(task)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/kanban/tasks/<tid>', methods=['PATCH'])
def update_kanban_task(tid):
    try:
        updates = request.json
        # Protect ID from being changed
        updates.pop('id', None)
        task = KM.update_task(tid, updates)
        if task: 
            notify_kanban_clients()
            return jsonify(task)
        return jsonify({"error": "Task not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/kanban/tasks/<tid>', methods=['DELETE'])
def delete_kanban_task(tid):
    try:
        if KM.delete_task(tid):
            return jsonify({"status": "deleted"})
        return jsonify({"error": "Task not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- Phase 13: Skills API ---

@app.route('/v1/skills', methods=['GET'])
def list_skills():
    """åˆ—å‡ºå·²å®‰è£æŠ€èƒ½èˆ‡ç›®éŒ„"""
    return jsonify({
        "installed": SM.list_installed(),
        "catalog": SM.list_catalog()
    })

@app.route('/v1/skills/search', methods=['POST'])
def search_skills():
    """æœå°‹å¯ç”¨æŠ€èƒ½"""
    query = request.json.get('query', '')
    results = SM.search_skill_online(query)
    return jsonify(results)

@app.route('/v1/skills/install', methods=['POST'])
def install_skill_api():
    """æ‰‹å‹•å®‰è£æŠ€èƒ½"""
    skill_info = request.json
    success = SM.install_skill(skill_info)
    return jsonify({"status": "installed" if success else "failed"})

@app.route('/v1/skills/<name>', methods=['DELETE'])
def remove_skill(name):
    """ç§»é™¤æŠ€èƒ½"""
    success = SM.remove_skill(name)
    return jsonify({"status": "removed" if success else "not_found"})

# ----------------------------

if __name__ == '__main__':
    log(f"ArielOS æ™ºæ…§ç¸½éƒ¨ v1.1 å•Ÿå‹•æˆåŠŸ | è·¯å¾‘é–å®š: {BASE_DIR}")
    log(f"ğŸ§  å°è…¦æ¨¡å‹é…ç½® | ä¸»è¦: {CEREBELLUM_MODEL} | å‚™ç”¨ (Fallback): {CEREBELLUM_FALLBACK_MODEL}")
    log(f"ğŸ¤– Dispatcher æ¨¡å‹: {DISPATCHER_MODEL}")
    # å•Ÿå‹•è‡ªå‹•æ’ç¨‹åŸ·è¡Œç·’
    threading.Thread(target=scheduler_worker, daemon=True).start()
    
    # ğŸ›¡ï¸ Stability Evolution: å¾ Flask Dev Server å‡ç´šç‚º Waitress WSGI (æ”¯æ´é«˜ä½µç™¼èˆ‡é˜²æ–·ç·š)
    from waitress import serve
    log("ğŸš€ å•Ÿå‹• Waitress ç”Ÿç”¢ç´šä¼ºæœå™¨ (Port 28888)...")
    serve(app, host='0.0.0.0', port=28888, threads=16)
