# -*- coding: utf-8 -*-
"""
modules/cerebellum.py â€” ArielOS å°è…¦æ ¸å¿ƒæ¨¡çµ„

åŒ…å«ï¼šcerebellum_call, cache, semantic_check, fast_track, style_transfer,
      skill_handler, web_search, distill_context, analyze_task_intent, update_cache
"""

import re
import json
import time
import datetime
import threading as _threading
import subprocess
import uuid
import sys
from pathlib import Path
from ddgs import DDGS

from .config import (
    OLLAMA_API, CEREBELLUM_MODEL, CEREBELLUM_FALLBACK_MODEL, INTENT_MODEL,
    CACHE_PATH, DATA_SANDBOX_PATH, log, ollama_post
)

# â”€â”€ ä¸¦ç™¼ä¿è­· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_CEREBELLUM_SEMAPHORE = _threading.Semaphore(2)

# â”€â”€ SIMPLE å•é¡Œå¿«å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SIMPLE_CACHE: dict = {}
_SIMPLE_CACHE_TTL = 300  # 5 åˆ†é˜


def _cached_cerebellum_simple(cache_key: str):
    entry = _SIMPLE_CACHE.get(cache_key)
    if entry and time.time() < entry[1]:
        log(f"âš¡ [SimpleCache] å‘½ä¸­å¿«å–: {cache_key[:30]}")
        return entry[0]
    return None


def _set_cerebellum_simple_cache(cache_key: str, answer: str):
    _SIMPLE_CACHE[cache_key] = (answer, time.time() + _SIMPLE_CACHE_TTL)
    expired = [k for k, (_, ts) in _SIMPLE_CACHE.items() if time.time() >= ts]
    for k in expired:
        _SIMPLE_CACHE.pop(k, None)


# â”€â”€ çµ±ä¸€å‘¼å«ä»‹é¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_call(prompt: str, temperature: float = 0.3, timeout: int = 180,
                    num_ctx: int = 2048, num_predict: int = 256, model: str = None) -> str:
    """ğŸ§  å°è…¦çµ±ä¸€å‘¼å«ä»‹é¢ï¼ˆå« Semaphore ä¿è­·ã€ç²¾ç°¡ Context è¨­å®šã€è‡ªå‹•æ¨¡å‹é™ç´šï¼‰

    å„å ´æ™¯å»ºè­°è¨­å®šï¼š
    - æ„åœ–åˆ†é¡:   num_ctx=2048, num_predict=80
    - é—œéµå­—èƒå–: num_ctx=1024, num_predict=30
    - å¿«å–æ¯”å°:   num_ctx=2048, num_predict=10
    - é¢¨æ ¼è½‰ç§»:   num_ctx=4096, num_predict=600

    è‡ªå‹•é™ç´šï¼šè‹¥æŒ‡å®š model (æˆ– CEREBELLUM_MODEL) è¶…æ™‚æˆ–ä¸å­˜åœ¨ï¼Œè‡ªå‹•æ”¹ç”¨ CEREBELLUM_FALLBACK_MODELã€‚
    """
    target_model = model if model else CEREBELLUM_MODEL
    payload = {
        "prompt": prompt,
        "stream": False,
        "options": {"temperature": temperature, "num_ctx": num_ctx, "num_predict": num_predict}
    }
    with _CEREBELLUM_SEMAPHORE:
        try:
            resp = ollama_post(OLLAMA_API, json={**payload, "model": target_model}, timeout=timeout)
            return resp.json().get('response', '').strip()
        except Exception as e:
            log(f"âš ï¸ [{target_model}] å¤±æ•—ï¼Œé™ç´šè‡³ {CEREBELLUM_FALLBACK_MODEL}: {e}")
        resp = ollama_post(OLLAMA_API, json={**payload, "model": CEREBELLUM_FALLBACK_MODEL}, timeout=timeout)
        return resp.json().get('response', '').strip()


# â”€â”€ æœå°‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_search_keywords(query: str) -> str:
    """èƒå–æœå°‹é—œéµå­— (å« CPU å‚™ä½æ–¹æ¡ˆ)"""
    try:
        # âš¡ CPU Pre-filter: æ¥µç°¡å•é¡Œç›´æ¥å»é ­å»å°¾ (ä¸å•Ÿå‹• GPU)
        q_clean = query.strip().strip('?ï¼Ÿ').lower()
        if len(q_clean) < 10:
            return q_clean
            
        keywords = cerebellum_call(
            prompt=(
                f"å°‡ä»¥ä¸‹è‡ªç„¶èªè¨€å•å¥è½‰æ›æˆç²¾ç¢ºçš„æœå°‹å¼•æ“é—œéµå­—ï¼ˆ2~5å€‹è©ï¼‰ï¼Œåªè¼¸å‡ºé—œéµå­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦è§£é‡‹ã€‚\n"
                f"å•å¥ï¼šã€{query}ã€\né—œéµå­—ï¼š"
            ),
            temperature=0, timeout=12, num_ctx=1024, num_predict=30
        )
        keywords = keywords.split('\n')[0].strip().strip('"').strip("'").strip('`')
        if keywords and len(keywords) > 1:
            log(f"ğŸ”‘ é—œéµå­—èƒå–: '{query}' â†’ '{keywords}'")
            return keywords
    except Exception as e:
        log(f"âš ï¸ é—œéµå­—èƒå–å¤±æ•— (GPU Timeout/Error): {e}")
        
    # ğŸ§ª CPU Fallback: ç°¡å–®çš„åˆ†è©èˆ‡è´…å­—ç§»é™¤ (éå¸¸ç²—ç³™ä½†æ¯”æ›æ‰å¥½)
    stop_words = ["å¹«æˆ‘", "æŸ¥è©¢", "æœå°‹", "ä¸€ä¸‹", "åœ¨å“ª", "æ˜¯ä»€éº¼", "å¦‚ä½•", "å¤šå°‘", "çš„", "å€‹"]
    k_list = [w for w in query.replace("?", "").replace(" ", "") if w not in stop_words]
    fallback_k = "".join(k_list[:10])
    log(f"ğŸ”‘ é—œéµå­—èƒå– (CPU Fallback): {fallback_k}")
    return fallback_k


def google_ai_search_worker(query: str) -> str | None:
    """ğŸŒ ä½¿ç”¨ Playwright æŠ“å– Google AI æ‘˜è¦ (SGE)"""
    from playwright.sync_api import sync_playwright
    log(f"ğŸŒ [Google AI Search] å•Ÿå‹•æŠ“å–: {query[:50]}...")
    
    try:
        from playwright_stealth import Stealth
    except ImportError as e:
        import sys
        Stealth = None
        log(f"âš ï¸ æœªå®‰è£ playwright-stealth (æˆ–è·¯å¾‘å•é¡Œ: {e})")
        log(f"ğŸ§  ç›®å‰åŸ·è¡Œç’°å¢ƒ Python: {sys.executable}")
        log(f"ğŸ§  ç’°å¢ƒè·¯å¾‘ (sys.path): {sys.path[:3]}...") # åªåˆ—å‡ºå‰å¹¾å€‹è·¯å¾‘é¿å…éé•·
        log("ğŸ‘‰ å»ºè­°é‡å°æ­¤è·¯å¾‘åŸ·è¡Œ: python -m pip install playwright-stealth")
    
    try:
        if Stealth:
            playwright_cm = Stealth().use_sync(sync_playwright())
        else:
            playwright_cm = sync_playwright()
            
        with playwright_cm as p:
            # ä½¿ç”¨æœ¬æ©ŸçœŸå¯¦ Chrome èˆ‡æŒä¹…åŒ–ä½¿ç”¨è€…è¨­å®šæª” (ç´¯ç© Cookie ä¿¡ä»»åº¦)
            user_data_dir = str(DATA_SANDBOX_PATH / "ariel_chrome_profile_google")

            context = p.chromium.launch_persistent_context(
                user_data_dir=user_data_dir,
                channel="chrome", # å¼·åˆ¶ä½¿ç”¨æœ¬æ©Ÿçš„ Google Chrome
                headless=False, # ğŸ˜ˆ å•Ÿå‹•å¯¦é«”è¦–çª— (é¿å…è¢«æ¨™è¨˜ç‚º Headless æ©Ÿå™¨äºº)
                args=['--disable-blink-features=AutomationControlled'],
                viewport={'width': 1280, 'height': 800}
            )
            page = context.pages[0] if context.pages else context.new_page()
            
            # å°å‘ Google æœå°‹
            search_url = f"https://www.google.com/search?q={query}"
            page.goto(search_url, timeout=30000)
            
            # ğŸ›¡ï¸ æª¢æŸ¥æ˜¯å¦é­åˆ° Google CAPTCHA é˜»æ“‹
            if page.locator('form[action="/sorry/index"]').count() > 0 or "sorry/index" in page.url:
                log("âš ï¸ [Google AI] é­åˆ° Google CAPTCHA (æ©Ÿå™¨äººé©—è­‰) é˜»æ“‹ï¼Œå¼·åˆ¶è§¸ç™¼å›é€€æ©Ÿåˆ¶ã€‚")
                context.close()
                return None
                
            # ç¢ºä¿ä¸»è¦æœå°‹çµæœå€å¡Šå·²è¼‰å…¥
            try:
                page.wait_for_selector('#search', timeout=10000)
            except Exception:
                log("âš ï¸ [Google AI] æœå°‹ä¸»å€å¡Šè¶…æ™‚æœªè¼‰å…¥ï¼Œå¯èƒ½é­åˆ°é˜»æ“‹ã€‚")
            
            # ç­‰å¾… AI æ‘˜è¦å‡ºç¾ (å˜—è©¦ä¸åŒé¸æ“‡å™¨)
            try:
                # 1. å˜—è©¦ç­‰å¾… aria-label (è¨­å®šåˆç†çš„ 15 ç§’ï¼Œé¿å…å¡æ­»)
                page.wait_for_selector('[aria-label*="AI æ‘˜è¦"]', timeout=15000)
                
                # æ‰¾åˆ°å®¹å™¨
                container = page.locator('[aria-label*="AI æ‘˜è¦"]').locator('..')
                
                # æŠ“å–ä¸»è¦æ–‡å­—å…§å®¹ (é€šå¸¸åœ¨ MUF9yc æˆ–é¡ä¼¼æ¨™ç±¤ä¸­)
                # é€™è£¡ä½¿ç”¨æ›´é€šç”¨çš„æ–¹å¼ï¼šæŠ“å–å€å¡Šå…§çš„æ®µè½
                paragraphs = container.locator('div[data-content-type="1"], span').all_text_contents()
                summary = "\n".join([p.strip() for p in paragraphs if len(p.strip()) > 10])
                
                if not summary:
                    # å‚™ä½æ–¹æ¡ˆï¼šæŠ“å–æ¨™é¡Œä¸‹æ–¹çš„ç¬¬ä¸€å€‹å¤§æ–‡å­—å¡Š
                    try:
                        summary = page.locator('div.MUF9yc').first.inner_text(timeout=2000)
                    except Exception:
                        pass

                if summary:
                    log(f"âœ… [Google AI] æˆåŠŸç²å–æ‘˜è¦ ({len(summary)} å­—å…ƒ)")
                    return f"[Google AI æœå°‹çµæœ]\n{summary.strip()}"
                
            except Exception as e:
                log(f"âš ï¸ [Google AI] æœªç™¼ç¾ AI æ‘˜è¦å€å¡Šæˆ–è¶…æ™‚: {str(e)[:50]}")
            
            context.close()
    except Exception as e:
        log(f"ğŸš¨ [Google AI] ç€è¦½å™¨å¯¦ä¾‹å•Ÿå‹•å¤±æ•—: {e}")
    return None


def perplexity_search_worker(query: str) -> str | None:
    """ğŸŒ ä½¿ç”¨ Playwright æŠ“å– Perplexity AI æ‘˜è¦"""
    from playwright.sync_api import sync_playwright
    log(f"ğŸŒ [Perplexity AI] å•Ÿå‹•æŠ“å–: {query[:50]}...")
    
    try:
        from playwright_stealth import Stealth
    except ImportError as e:
        Stealth = None
        log(f"âš ï¸ [Perplexity] æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
    
    try:
        if Stealth:
            playwright_cm = Stealth().use_sync(sync_playwright())
        else:
            playwright_cm = sync_playwright()
            
        with playwright_cm as p:
            user_data_dir = str(DATA_SANDBOX_PATH / "ariel_chrome_profile_perplexity")

            context = p.chromium.launch_persistent_context(
                user_data_dir=user_data_dir,
                channel="chrome", # å¼·åˆ¶ä½¿ç”¨æœ¬æ©Ÿçš„ Google Chrome
                headless=False, # ğŸ˜ˆ å•Ÿå‹•å¯¦é«”è¦–çª—ï¼Œå®Œå…¨æŠ¹é™¤ Headless ç‰¹å¾µ
                args=['--disable-blink-features=AutomationControlled'],
                viewport={'width': 1280, 'height': 800}
            )
            page = context.pages[0] if context.pages else context.new_page()
            
            # Perplexity URL æ ¼å¼
            search_url = f"https://www.perplexity.ai/search?q={query}"
            page.goto(search_url, timeout=40000)
            
            # ğŸ›¡ï¸ æª¢æŸ¥æ˜¯å¦é­åˆ° Cloudflare é˜»æ“‹
            if "Just a moment" in page.title() or "challenge" in page.url:
                log("âš ï¸ [Perplexity AI] é­åˆ° Cloudflare æ©Ÿå™¨äººé©—è­‰é˜»æ“‹ï¼Œè§¸ç™¼å›é€€æ©Ÿåˆ¶ã€‚")
                context.close()
                return None

            try:
                # ç­‰å¾…å›ç­”é–‹å§‹ç”Ÿæˆ (é€šå¸¸æ˜¯æœ‰ä¸€å€‹ç‰¹å®šçš„é¡åæˆ–æ–‡å­—)
                # Perplexity çš„çµæ§‹è¼ƒæ·±ï¼Œæˆ‘å€‘æŠ“å– Proxima æˆ–é¡ä¼¼å®¹å™¨çš„æ–‡å­—
                page.wait_for_selector('.prose', timeout=20000)
                
                # æŠ“å–å›ç­”å…§å®¹
                answer_elements = page.locator('.prose').all_text_contents()
                summary = "\n".join([a.strip() for a in answer_elements if len(a.strip()) > 20])
                
                if summary:
                    log(f"âœ… [Perplexity AI] æˆåŠŸç²å–æ‘˜è¦ ({len(summary)} å­—å…ƒ)")
                    return f"[Perplexity AI æœå°‹çµæœ]\n{summary.strip()}"
            except Exception as e:
                log(f"âš ï¸ [Perplexity AI] æŠ“å–è¶…æ™‚æˆ–æœªç™¼ç¾å›ç­”: {str(e)[:50]}")
            
            context.close()
    except Exception as e:
        log(f"ğŸš¨ [Perplexity AI] ç•°å¸¸: {e}")
    return None


def search_web_worker(query: str) -> str:
    """ğŸš€ Phase 8: æ··åˆå¼å…±è­˜æœå°‹ (Google AI + Perplexity AI + DDGS)"""
    from concurrent.futures import ThreadPoolExecutor, as_completed
    log(f"ğŸ” [Search Worker] å•Ÿå‹•å…±è­˜æœå°‹: {query[:50]}...")
    
    ai_results = []
    # ğŸƒ å•Ÿå‹•ä¸¦ç™¼æŠ“å–ï¼šå°è…¦åŒæ™‚æ´¾å‡ºå¤šå€‹æ¢é‡
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = {
            executor.submit(google_ai_search_worker, query): "Google AI",
            executor.submit(perplexity_search_worker, query): "Perplexity AI"
        }
        
        for future in as_completed(futures):
            engine_name = futures[future]
            try:
                res = future.result()
                if res:
                    ai_results.append(res)
                    # ğŸ’¡ å¦‚æœå·²ç¶“æ‹¿åˆ°ä¸€å€‹é«˜å“è³ªçµæœï¼Œå¯ä»¥è€ƒæ…®ææ—©å›å‚³ (Race Mode)
                    # ä½†ç‚ºäº†å…±è­˜ï¼Œæˆ‘å€‘é€™è£¡ç­‰å…¨éƒ¨è·‘å®Œæˆ–ç¬¬ä¸€å€‹æˆåŠŸå³å›å‚³
                    log(f"ğŸ¯ [Search Worker] {engine_name} æ¶å…ˆæ“Šä¸­ï¼")
                    return res
            except Exception as e:
                log(f"âš ï¸ [Search Worker] {engine_name} æ”¯ç·šæ•…éšœ: {e}")

    # 3. å‚™ä½æ–¹æ¡ˆ: DDGS + CPU ç¨‹å¼åŒ–éæ¿¾ (æ‰€æœ‰ AI éƒ½å¤±æ•—æ™‚)
    log("ğŸ” [Search Worker] æ‰€æœ‰ AI æœå°‹å‡å¤±æ•ˆï¼ŒåŸ·è¡Œ DDGS + CPU ç¨‹å¼åŒ–éæ¿¾...")
    try:
        search_keywords = extract_search_keywords(query)
        results = DDGS().text(search_keywords, max_results=10)
        if not results:
            return "Unable to find relevant information from the web."
            
        raw_data_path = DATA_SANDBOX_PATH / f"search_raw_{uuid.uuid4().hex[:8]}.json"
        with open(raw_data_path, "w", encoding="utf-8") as f:
            json.dump(list(results), f, ensure_ascii=False)
            
        prompt = (
            f"ä½ ç¾åœ¨æ˜¯èƒ½ç›´æ¥å¯«ç¨‹å¼éæ¿¾è³‡æ–™çš„æœå°‹ä»£ç†äººã€‚ä½¿ç”¨è€…è©¢å•ï¼šã€{query}ã€\n"
            f"æˆ‘å·²å°‡ 10 ç­†æœå°‹çµæœå­˜å…¥ JSON æª”æ¡ˆï¼š{raw_data_path}\n"
            "æ ¼å¼ç‚º [{{'title': '...', 'body': '...', 'href': '...'}}...]\n"
            "è«‹æ’°å¯«ä¸€æ®µ Python ç¨‹å¼ç¢¼ï¼Œè®€å–è©²æª”æ¡ˆï¼Œåˆ†æ body æ¬„ä½æ‰¾å‡ºå•é¡Œçš„ç­”æ¡ˆï¼Œä¸¦ä½¿ç”¨ print() è¼¸å‡ºã€ç°¡æ½”ä¸”ç²¾ç¢ºçš„çµè«–ã€ã€‚\n"
            "è¦å‰‡ï¼š\n"
            "1. åƒ…è¼¸å‡º Python ç¨‹å¼ç¢¼ï¼Œä¸åŠ  ```python æ¨™ç±¤ã€‚\n"
            "2. **è®€å– JSON æˆ–ä»»ä½•æª”æ¡ˆæ™‚ï¼Œå‹™å¿…ä½¿ç”¨ `open(..., encoding='utf-8')` è§£ç¢¼ã€‚**\n"
            "3. åª print æœ€ç²¾è¯çš„ç¹é«”ä¸­æ–‡çµæœï¼Œä¸è¦ print åŸå§‹é™£åˆ—ã€‚"
        )
        script_code = cerebellum_call(prompt=prompt, temperature=0.1, timeout=180, num_ctx=2048, num_predict=1024)
        # ğŸ›¡ï¸ å˜—è©¦ç²¾æº–æå– markdown å…§çš„ç¨‹å¼ç¢¼ï¼Œé¿å… LLM çš„é–‹å ´ç™½å°è‡´åŸ·è¡Œå¤±æ•—
        code_match = re.search(r"```(?:python)?\n(.*?)\n```", script_code, re.DOTALL | re.IGNORECASE)
        if code_match:
            script_code = code_match.group(1).strip()
        else:
            script_code = re.sub(r"^```[a-zA-Z]*\n?|\n?```$", "", script_code.strip(), flags=re.MULTILINE)
            if "import" in script_code:
                script_code = script_code[script_code.find("import"):]
        
        script_path = DATA_SANDBOX_PATH / f"search_prog_{uuid.uuid4().hex[:8]}.py"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(script_code)
            
        log(f"ğŸ’» [Sandbox] åŸ·è¡Œæœå°‹éæ¿¾è…³æœ¬: {script_path.name}")
        res = subprocess.run(
            [sys.executable, str(script_path)],
            capture_output=True, text=True, timeout=15, cwd=str(DATA_SANDBOX_PATH)
        )
        
        try:
            script_path.unlink()
            raw_data_path.unlink()
        except: pass

        if res.returncode == 0:
            output = res.stdout.strip()
            if not output:
                output = "ç¨‹å¼ç¢¼åŸ·è¡Œå®Œç•¢ï¼Œä½†æœªå°å‡ºä»»ä½•çµè«–ã€‚"
            return f"[ç¶²è·¯æœå°‹çµæœ]\n{output}"
        else:
            log(f"âš ï¸ æœå°‹éæ¿¾è…³æœ¬å¤±æ•—: {res.stderr}")
            return f"Error filtering search results: {res.stderr.strip()}"
            
    except Exception as e:
        log(f"âš ï¸ æœå°‹å¤±æ•—: {e}")
        return f"Error performing search: {e}"


def programmatic_data_worker(query: str) -> str:
    """ğŸš€ Phase 8: CPU-Driven Programmatic Tool Calling (Sandbox Filtering)"""
    log(f"ğŸ’» [Programmatic Worker] å•Ÿå‹•ç¨‹å¼åŒ–æ²™ç›’è™•ç†: {query[:50]}...")
    try:
        instruction = (
            f"ä½ ç¾åœ¨æ˜¯ä¸€åè³‡æ·±è³‡æ–™å·¥ç¨‹å¸«ã€‚ä½¿ç”¨è€…çš„éœ€æ±‚æ˜¯ï¼šã€{query}ã€\n"
            "è«‹ç›´æ¥æ’°å¯«ä¸€æ®µ Python ç¨‹å¼ç¢¼ï¼Œåœ¨æœ¬åœ°åŸ·è¡Œæ­¤è³‡æ–™éæ¿¾/æ’åº/æ¯”å°ä»»å‹™ã€‚\n"
            "è¦å‰‡ï¼š\n"
            "1. åƒ…è¼¸å‡º Python ç¨‹å¼ç¢¼ï¼Œä¸åŠ  ```python æˆ–ä»»ä½•é¡å¤–èªªæ˜ã€‚\n"
            "2. ä½¿ç”¨ urllib æˆ– requests æ’ˆå–å…¬é–‹è³‡æ–™ï¼ˆå¦‚éœ€ä¸Šç¶²ï¼‰ï¼Œæˆ–ä½¿ç”¨ OS æ¨¡çµ„è®€å¯«å¿…è¦çš„æª”æ¡ˆã€‚\n"
            "3. **è®€å–ä»»ä½•æœ¬åœ°æª”æ¡ˆæ™‚ï¼Œå‹™å¿…åœ¨ open() ä¸­åŠ ä¸Š encoding='utf-8' åƒæ•¸ã€‚**\n"
            "4. åœ¨ç¨‹å¼ç¢¼æœ€å¾Œï¼Œä½¿ç”¨ print() è¼¸å‡ºã€æœ€ç°¡æ½”çš„ç²¾è¯çµè«–ã€ï¼Œé€™å€‹ print çš„çµæœå°‡æœƒç›´æ¥äº¤çµ¦ä½¿ç”¨è€…ã€‚\n"
            "5. ç¢ºä¿ç¨‹å¼ç¢¼æ²’æœ‰ç„¡çª®è¿´åœˆï¼Œä¸¦ä¸”èƒ½å¿«é€ŸåŸ·è¡Œå®Œç•¢ã€‚"
        )
        script_code = cerebellum_call(prompt=instruction, temperature=0.1, timeout=180, num_ctx=2048, num_predict=1024)
        
        # ğŸ›¡ï¸ å˜—è©¦ç²¾æº–æå– markdown å…§çš„ç¨‹å¼ç¢¼ï¼Œé¿å… LLM çš„é–‹å ´ç™½å°è‡´åŸ·è¡Œå¤±æ•—
        code_match = re.search(r"```(?:python)?\n(.*?)\n```", script_code, re.DOTALL | re.IGNORECASE)
        if code_match:
            script_code = code_match.group(1).strip()
        else:
            script_code = re.sub(r"^```[a-zA-Z]*\n?|\n?```$", "", script_code.strip(), flags=re.MULTILINE)
            if "import" in script_code:
                script_code = script_code[script_code.find("import"):]
        
        script_path = DATA_SANDBOX_PATH / f"prog_{uuid.uuid4().hex[:8]}.py"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(script_code)
            
        log(f"ğŸ’» [Sandbox] åŸ·è¡Œè…³æœ¬: {script_path.name}")
        res = subprocess.run(
            [sys.executable, str(script_path)],
            capture_output=True, text=True, timeout=15, cwd=str(DATA_SANDBOX_PATH)
        )
        
        # æ¸…ç†æ²™ç›’
        try: script_path.unlink()
        except: pass

        if res.returncode == 0:
            output = res.stdout.strip()
            if len(output) > 2000:
                output = output[:2000] + "\\n...(æˆªæ–·)"
            if not output:
                output = "ç¨‹å¼ç¢¼åŸ·è¡Œå®Œç•¢ï¼Œä½†æœªç”¢ç”Ÿä»»ä½•è¼¸å‡ºã€‚"
            return f"[ç¨‹å¼åŒ–åˆ†æçµæœ]\\n{output}"
        else:
            log(f"âš ï¸ [Sandbox] è…³æœ¬åŸ·è¡Œå¤±æ•—: {res.stderr}")
            return f"Error executing programmatic data analysis: {res.stderr.strip()}"
            
    except subprocess.TimeoutExpired:
        log("âŒ [Sandbox] è…³æœ¬åŸ·è¡Œé€¾æ™‚(>15s)ï¼")
        return "Timeout error: Programmatic script took too long to execute."
    except Exception as e:
        log(f"âš ï¸ ç¨‹å¼åŒ–è™•ç†å¤±æ•—: {e}")
        return f"Error in programmatic worker: {e}"


# â”€â”€ å¿«å–èªæ„æª¢æŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_semantic_check(query: str):
    """ğŸš€ å°è…¦é–€è¡›ï¼šç”± Ollama åˆ¤å®šèªæ„æ„åœ– (é‚è¼¯å¢å¼·ç‰ˆ)"""
    cached = _cached_cerebellum_simple(query)
    if cached:
        return cached

    if not CACHE_PATH.exists():
        return None
    try:
        with open(CACHE_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
            records = data.get("records", [])
            if not records:
                return None
            now = datetime.datetime.now()
            valid_records = [r for r in records if now < datetime.datetime.fromisoformat(r['expires_at'])]
            target_pool = valid_records[-10:]
            if not target_pool:
                return None

            # é—œéµå­—é‡ç–Šé ç¯©é¸ï¼šåªæŠ“å‡ºæœ‰å­—å…ƒé‡ç–Šçš„å¿«å–é …ç›®
            query_chars = set(query.replace(" ", ""))
            overlapping_records = []
            for i, r in enumerate(target_pool):
                r_chars = set(r['query'].replace(" ", ""))
                overlap_ratio = len(query_chars & r_chars) / max(len(query_chars | r_chars), 1)
                
                # âš¡ [CPU Ultra Hit] ç›¸ä¼¼åº¦æ¥µé«˜ (>85%)ï¼Œç›´æ¥å‘½ä¸­ï¼Œè·³é LLM åˆ¤å®š
                if overlap_ratio >= 0.85:
                    log(f"âš¡ [CPU Ultra Hit] ç›¸ä¼¼åº¦é«˜é” {overlap_ratio:.2f}ï¼Œç›´æ¥å‘½ä¸­ ID:{i}")
                    return r['summary']
                
                if overlap_ratio >= 0.35:
                    overlapping_records.append((i, r))

            if not overlapping_records:
                log("ğŸ›¡ï¸ [SemanticCache] ç„¡è¶³å¤ é‡ç–Šï¼Œè·³é LLM åˆ¤å®š")
                return None

            cache_context = "\n".join([f"ID:{i} | å•é¡Œ:{r['query']}" for i, r in overlapping_records])
            instruction = (
                f"ä½ ç¾åœ¨æ˜¯ ArielOS çš„è¶…åš´æ ¼èªæ„é–€è¡›ã€‚å¿«å–æ¸…å–®å¦‚ä¸‹ï¼š\n{cache_context}\n\n"
                f"ç¾åœ¨è€é—†å•äº†ï¼šã€{query}ã€\n"
                "ã€åˆ¤æ–·æ¨™æº– â€” å¿…é ˆä¸‰é …å…¨éƒ¨ç›¸åŒæ‰å¯å‘½ä¸­ã€‘\n"
                "  1. ä¸»é¡Œ/é ˜åŸŸ å®Œå…¨ç›¸åŒï¼ˆå¦‚ï¼šå¤©æ°£ â‰  æ³•å¾‹ï¼ŒæŠ€èƒ½ â‰  é€²åº¦ï¼‰\n"
                "  2. åœ°é»/å°è±¡ å®Œå…¨ç›¸åŒ\n"
                "  3. è¡Œå‹•/æ„åœ– å®Œå…¨ç›¸åŒï¼ˆå¦‚ï¼šå­¸ç¿’æŠ€èƒ½ â‰  æŸ¥è©¢é€²åº¦ï¼‰\n\n"
                "ã€çµ‚æ¥µæŒ‡ä»¤ã€‘\n"
                "çµ•å°ä¸å…è¨±ä»»ä½•è§£é‡‹æˆ–å»¢è©±ã€‚\n"
                "å¦‚æœä¸Šè¿°æ¸…å–®ä¸­æœ‰å®Œå…¨å»åˆçš„é …ç›®ï¼Œè«‹ä½ åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š\n"
                "[MATCH_ID:æ•¸å­—]\n"
                "å¦‚æœæ²’æœ‰ä»»ä½•ä¸€å€‹é …ç›®ç¬¦åˆï¼Œæˆ–æ˜¯ä½ ä¸ç¢ºå®šï¼Œè«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š\n"
                "[NO]\n"
            )
            judgment = cerebellum_call(prompt=instruction, temperature=0, timeout=25, num_ctx=1024, num_predict=20)
            
            if "[NO]" in judgment.upper():
                return None
                
            match = re.search(r'\[MATCH_ID:(\d+)\]', judgment, re.IGNORECASE)
            if match:
                idx = int(match.group(1))
                if 0 <= idx < len(target_pool):
                    log(f"âš¡ å°è…¦ç¢ºèªèªæ„å‘½ä¸­ ID:{idx}")
                    return target_pool[idx]['summary']
            
            log(f"âš ï¸ [SemanticCache] LLM å›å‚³æ ¼å¼éŒ¯èª¤æˆ–ç„¡å‘½ä¸­: {judgment[:20]}")
            return None
    except Exception as e:
        log(f"âš ï¸ å°è…¦é–€è¡›ç•°å¸¸: {e}")
        if "timed out" in str(e).lower() or "read timeout" in str(e).lower():
            return "OLLAMA_BUSY"
    return None


# â”€â”€ é¢¨æ ¼è½‰ç§» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_style_transfer(raw_answer: str, agent_id: str, agent_registry: dict, pe) -> str:
    """ğŸš€ å°è…¦é¢¨æ ¼è½‰ç§»ï¼šå°‡å¤§è…¦çš„ç´”é‚è¼¯ç­”æ¡ˆè½‰åŒ–ç‚ºä»£ç†äººäººæ ¼"""
    from .personality import _sanitize_persona
    soul = pe.load_soul(agent_id)
    agent_name = agent_registry.get(agent_id, {}).get("name", "Agent")
    if not soul:
        return _sanitize_persona(raw_answer, agent_name)

    # ğŸ›¡ï¸ å¦‚æœæ˜¯ç³»çµ±éŒ¯èª¤è¨Šæ¯æˆ–å®Œå…¨æ‰¾ä¸åˆ°è³‡æ–™ï¼Œç›´æ¥æ”¾è¡Œï¼Œé¿å… AI å¥—ç”¨èªæ°£ç”¢ç”Ÿå¹»è¦º
    error_signatures = [
        "Error performing search:",
        "Error filtering search:",
        "Error executing programmatic data analysis:",
        "Error in programmatic worker:",
        "Timeout error:",
        "ç¨‹å¼ç¢¼åŸ·è¡Œå®Œç•¢ï¼Œä½†æœª",
        "Unable to find relevant information",
        "Traceback ("
    ]
    if any(sig in raw_answer for sig in error_signatures):
        return f"[{agent_name} ç³»çµ±å›å ±]\n{raw_answer}"

    if len(raw_answer) > 3000:
        try:
            intro = cerebellum_call(
                prompt=(f"ä½ æ˜¯ {agent_name}ã€‚è«‹ç”¨ä½ ç¨ç‰¹çš„èªªè©±é¢¨æ ¼ï¼Œåªå¯«ä¸€å¥è©±å‘è€é—†å ±å‘Šä»¥ä¸‹ä»»å‹™å·²å®Œæˆã€‚"
                        f"ä»»å‹™æ‘˜è¦ï¼ˆå‰200å­—ï¼‰ï¼š{raw_answer[:200]}"),
                temperature=0.4, timeout=120, num_ctx=1024, num_predict=60
            )
            if intro:
                return f"{_sanitize_persona(intro, agent_name)}\n\n{_sanitize_persona(raw_answer, agent_name)}"
        except Exception as e:
            log(f"âš ï¸ å¤§è¼¸å‡ºå‰è¨€ç”Ÿæˆå¤±æ•—: {e}")
        return _sanitize_persona(raw_answer, agent_name)

    # é¿å…è¤‡èª¦è§’è‰²è¨­å®šèˆ‡å¹»è¦º
    instruction = (
        f"ä½ ç¾åœ¨æ‰®æ¼”ã€{agent_name}ã€ã€‚ä½ çš„å€‹æ€§å¦‚ä¸‹ï¼š\n"
        f"ã€è§’è‰²ç‰¹è³ªã€‘\n{soul[:300]}\n\n"
        f"ã€ä»»å‹™ï¼šæ–‡å­—æ½¤é£¾ã€‘\n"
        f"è«‹ä½¿ç”¨ä½ çš„å£å»èˆ‡ç¬¬ä¸€äººç¨±ã€æˆ‘ã€ï¼Œå°‡ä¸‹æ–¹ã€å¾…æ½¤é£¾çš„åŸæ–‡ã€‘é‡æ–°æ”¹å¯«ï¼Œè®“å®ƒè½èµ·ä¾†åƒæ˜¯ä½ èªªçš„è©±ã€‚\n"
        f"ã€å¼·åˆ¶è¦å‰‡ã€‘\n"
        f"1. åš´ç¦åœ¨å›ç­”ä¸­æåˆ°ã€Œé€™æ˜¯æˆ‘çš„éˆé­‚è¨­å®šã€ã€ã€Œæˆ‘æ˜¯XXXã€ç­‰è‡ªæˆ‘ä»‹ç´¹çš„å»¢è©±ã€‚\n"
        f"2. åš´ç¦åŠ ä¸Šã€Œå¥½çš„ã€ã€ã€Œä»¥ä¸‹æ˜¯ã€ç­‰å‰è¨€ã€‚\n"
        f"3. åš´ç¦ä¿®æ”¹åŸæ–‡ä¸­çš„ç¨‹å¼ç¢¼æˆ–é—œéµæ•¸å€¼è³‡æ–™ã€‚\n"
        f"4. å°‡åŸæ–‡çš„ 'Ariel' æˆ– 'ArielOS' æ”¹ç‚ºã€{agent_name}ã€ã€‚\n"
        f"5. **å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ (Traditional Chinese) å›ç­”**ï¼Œå³ä¾¿åŸæ–‡æ˜¯ç°¡é«”æˆ–è‹±æ–‡ä¹Ÿå¿…é ˆç¿»è­¯æ½¤é£¾ã€‚\n"
        f"6. ç›´æ¥è¼¸å‡ºä½ æ”¹å¯«å¾Œçš„çµæœï¼Œçµ•å°ä¸è¦åŒ…å«ä»»ä½• Markdown æ¨™è¨˜ï¼Œä¹Ÿä¸è¦è¼¸å‡º JSONã€‚\n\n"
        f"ã€å¾…æ½¤é£¾çš„åŸæ–‡ã€‘\n{raw_answer}"
    )
    try:
        styled = cerebellum_call(prompt=instruction, temperature=0.7, timeout=120, num_ctx=4096, num_predict=600)
        if styled:
            # æ¸…ç† Gemma å¯èƒ½æœƒç”¢ç”Ÿçš„ ``` æ¨™è¨˜
            import re
            styled = re.sub(r"^```\w*\n?|\n?```$", "", styled.strip(), flags=re.MULTILINE)
            return _sanitize_persona(styled, agent_name)
    except Exception as e:
        log(f"âš ï¸ é¢¨æ ¼è½‰ç§»å¤±æ•—: {e}")
    return _sanitize_persona(raw_answer, agent_name)


# â”€â”€ æŠ€èƒ½è·¯ç”± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_skill_handler(query: str, skill_desc: str, agent_id: str, sm, agent_registry: dict, pe, **kwargs) -> str | None:
    """ğŸ”§ Phase 13: å°è…¦æŠ€èƒ½è·¯ç”±"""
    matched = sm.find_matching_skill(skill_desc)
    if matched:
        log(f"ğŸ”§ æŠ€èƒ½å‘½ä¸­ (é—œéµå­—): {matched['name']}")
        installed_names = [s['name'] for s in sm.list_installed()]
        if matched['name'] not in installed_names:
            sm.install_skill(matched)
        result = sm.execute_skill(matched, query, **kwargs)
        if result:
            return cerebellum_style_transfer(result, agent_id, agent_registry, pe)

    if not matched:
        matched = sm.find_skill_by_llm(skill_desc)
        if matched:
            log(f"ğŸ”§ æŠ€èƒ½å‘½ä¸­ (LLM): {matched['name']}")
            installed_names = [s['name'] for s in sm.list_installed()]
            if matched['name'] not in installed_names:
                sm.install_skill(matched)
            result = sm.execute_skill(matched, query, **kwargs)
            if result:
                return cerebellum_style_transfer(result, agent_id, agent_registry, pe)

    log(f"ğŸŒ ç·šä¸Šæœå°‹æŠ€èƒ½: {skill_desc}")
    candidates = sm.search_skill_online(skill_desc)
    if candidates:
        best = candidates[0]
        log(f"ğŸ“¦ å˜—è©¦å®‰è£ç·šä¸ŠæŠ€èƒ½: {best['name']}")
        if sm.install_skill(best):
            result = sm.execute_skill(best, query, **kwargs)
            if result:
                return cerebellum_style_transfer(result, agent_id, agent_registry, pe)

    log(f"âš ï¸ æŠ€èƒ½è·¯ç”±å®Œå…¨å¤±æ•—: {query[:40]}...")
    return f"å ±å‘Šè€é—†ï¼Œæˆ‘å‰›æ‰è©¦è‘—é‹ç®—æˆ–å°‹æ‰¾æ­¤é …æŠ€èƒ½ï¼Œä½†é­é‡äº†é€£ç·šå•é¡Œæˆ–æ˜¯ç¡¬é«”æ ¸å¿ƒè¶…æ™‚ã€‚å»ºè­°æ‚¨ç¨å¾Œé‡è©¦ï¼Œæˆ–æ˜¯ç¢ºèªæœ¬æ©Ÿçš„ MCP ç’°å¢ƒæ˜¯å¦æ­£å¸¸ã€‚"


# â”€â”€ Fast Track â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_fast_track_check(query: str, agent_id: str, agent_registry: dict, pe, sm, **kwargs):
    """ğŸš€ å°è…¦å¿«è»Šé“ï¼šåˆ¤æ–·æ˜¯å¦ç‚ºç°¡å–®å°è©±æˆ–æœå°‹"""
    from .personality import _get_time_context

    persona_context = ""
    if agent_id:
        soul = pe.load_soul(agent_id)
        if soul:
            agent_name = agent_registry.get(agent_id, {}).get("name", "Agent")
            persona_context = f"ä½ ç¾åœ¨æ˜¯ {agent_name}ï¼Œæ“æœ‰ä»¥ä¸‹ç‰¹è³ªï¼š\n{soul}\n"

    # âœ‚ï¸ ç§»é™¤ç”± Agent å·å·æ³¨å…¥çš„ç³»çµ±èƒŒæ™¯å­—ä¸² (å¦‚è¡Œäº‹æ›†ã€GAS è³‡æ–™)ï¼Œé¿å…å¹²æ“¾æ„åœ–åˆ¤æ–·
    pure_query = re.sub(r"\[ç³»çµ±è³‡è¨Š.*?\][\s\S]*?\[çµæŸç³»çµ±è³‡è¨Š\]\n*", "", query).strip()
    if not pure_query:
        pure_query = query

    time_context = _get_time_context()
    instruction = (
        "ä½ æ˜¯ä¸€å€‹åš´æ ¼çš„ã€æ„åœ–åˆ†é¡è·¯ç”±å™¨ã€ï¼Œè² è²¬æ¨™ç±¤ä½¿ç”¨è€…çš„æå•ã€‚\n"
        "ä½ å¯ä»¥åƒè€ƒä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼š\n"
        f"{persona_context}{time_context}\n"
        f"ä½¿ç”¨è€…è¼¸å…¥ï¼šã€{pure_query}ã€\n"
        "è«‹ä¾ç…§ä»¥ä¸‹å®šç¾©åˆ¤æ–·æ„åœ–ï¼š\n"
        "- [SIMPLE]ï¼šæ‰“æ‹›å‘¼ã€ç´”èŠå¤©ã€å•å€™ã€ç°¡å–®å¸¸è­˜ã€‚\n"
        "- [SEARCH]ï¼šå–®ç´”çš„è³‡è¨ŠæŸ¥è©¢ï¼ˆå¦‚ï¼šå¤©æ°£ã€åŒ¯ç‡ã€ç°¡å–®åè©è§£é‡‹ã€é£Ÿè­œï¼‰ã€‚\n"
        "- [PROGRAMMATIC]ï¼šé‡å°æª”æ¡ˆæˆ–è³‡æ–™åº«é€²è¡Œå¤§é‡è³‡æ–™è™•ç†ã€åˆ†æã€‚\n"
        "- [SKILL]ï¼šéœ€è¦ç‰¹å®šè»Ÿé«”å·¥å…·ã€å¤–æ›æˆ–ã€Œæ·±åº¦ç ”ç©¶åˆ†æã€ï¼ˆå¦‚ï¼šåŸ·è¡Œè…³æœ¬ã€æ“ä½œè¨ˆç•«ã€åˆ†æè¶¨å‹¢ã€æ·±åº¦å ±å‘Šã€æ™‚å€è½‰æ›ã€æ•´åˆè¡Œäº‹æ›†èˆ‡æ–°èï¼‰ã€‚\n"
        "- [COMPLEX]ï¼šç¨‹å¼é–‹ç™¼ã€é•·ç¯‡é‚è¼¯æ¨ç†ã€ç³»çµ±æ¶æ§‹è¨­è¨ˆã€‚å³ä¾¿æ¶‰åŠæœå°‹ï¼Œä½†ä¸»è¦æ˜¯ç‚ºäº†è§£æ±ºè¤‡é›œçš„ç¨‹å¼é‚è¼¯å•é¡Œã€‚\n\n"
        "ã€çµ•å°è¦å‰‡ã€‘ï¼šä½ ä¸å¯ä»¥é€²è¡Œå°è©±ï¼ä½ åªèƒ½è¼¸å‡ºé€™äº”å€‹æ¨™ç±¤ä¹‹ä¸€ï¼ˆåŒ…å«ä¸­æ‹¬è™Ÿï¼‰ï¼Œå¦‚æœæœ‰å¿…è¦å¯ä»¥åŠ ä¸Šä¸€å¥è©±çš„æè¿°ã€‚\n"
        "ç¯„ä¾‹è¼¸å‡º 1ï¼š[SEARCH] è£½ä½œé¦™æ°›è Ÿç‡­çš„æ–¹æ³•\n"
        "ç¯„ä¾‹è¼¸å‡º 2ï¼š[SKILL] å®‰è£è³‡æ–™åº«é€£ç·šå·¥å…·\n"
        "ç¯„ä¾‹è¼¸å‡º 3ï¼š[COMPLEX] é–‹ç™¼ Python ç¶²è·¯çˆ¬èŸ²\n"
        "è«‹ç«‹åˆ»è¼¸å‡ºä½ çš„åˆ†é¡ï¼š"
    )

    # âš¡ é—œéµå­—å‰å“¨ (ä½¿ç”¨ç´”æ·¨çš„ User Query é¿å…è¢« Context æ´—æ‰)
    q_lower = pure_query.lower().replace(" ", "")
    
    # æ””æˆªè³‡è¨Šå‹è©¢å• (ä¸è¦æŠŠã€Œå¦³æœ‰å“ªäº›æŠ€èƒ½ã€ç•¶ä½œåŸ·è¡ŒæŠ€èƒ½çš„æ„åœ–)
    info_queries = [
        "æœ‰å“ªäº›æŠ€èƒ½", "æœ‰ä»€éº¼æŠ€èƒ½", "æœƒä»€éº¼æŠ€èƒ½", "æ“æœ‰å“ªäº›æŠ€èƒ½", "æ“æœ‰ä»€éº¼æŠ€èƒ½", "å…·å‚™ä»€éº¼æŠ€èƒ½", 
        "ä»€éº¼åŠŸèƒ½", "æœ‰å“ªäº›åŠŸèƒ½", "æŠ€èƒ½åˆ—è¡¨", "å¯ç”¨æŠ€èƒ½", "é‚£äº›æŠ€èƒ½", "ä»€éº¼æŠ€èƒ½"
    ]
    if any(q in q_lower for q in info_queries) and (len(q_lower) < 20):
        installed = [s['name'] for s in sm.list_installed()]
        if not installed:
            ans = "å ±å‘Šè€é—†ï¼Œæˆ‘ç›®å‰å°šç„¡å®‰è£é¡å¤–çš„ç‰¹æ®ŠæŠ€èƒ½ã€‚æ‚¨å¯ä»¥éš¨æ™‚è¦æ±‚æˆ‘å­¸ç¿’æˆ–å¹«è‡ªå·±å¯«ä¸€å€‹æ–°ç¨‹å¼ä¾†æ“´å……èƒ½åŠ›ï¼"
        else:
            ans = "å ±å‘Šè€é—†ï¼Œæˆ‘ç›®å‰å…·å‚™ä»¥ä¸‹æŠ€èƒ½å·¥å…·ï¼š\n" + "\n".join([f"- {n}" for n in installed]) + "\n\nè‹¥ä¸Šè¿°æ²’æœ‰æ‚¨éœ€è¦çš„ï¼Œæ‚¨å¯ä»¥éš¨æ™‚å‘½ä»¤æˆ‘è‡ªå‹•é–‹ç™¼æˆ–ä¸Šç¶²å­¸ç¿’æ–°æŠ€èƒ½ï¼"
        # âš ï¸ ç›´æ¥å›å‚³ï¼Œä¸ç¶“éé¢¨æ ¼è½‰ç§»ï¼Œé¿å… LLM æŠŠé™£åˆ—è½‰æˆå¥‡æ€ªçš„æ ¼å¼ (å¦‚ ['Agent', 'Agent'])
        return ("SIMPLE", ans)

    SKILL_TRIGGERS = [
        "æŠ€èƒ½", "å­¸ç¿’", "å®‰è£å¥—ä»¶", "æ³•å¾‹", "æœƒè¨ˆ", "è²¡å‹™", "ç¨…å‹™",
        "é†«ç™‚", "å·¥ç¨‹", "ç¨‹å¼åº«", "install", "learn", "skill", "tool",
        "plugin", "æ¨¡çµ„", "å¥—ä»¶", "åŠŸèƒ½æ¨¡çµ„", "æ’ç¨‹", "å®šæ™‚ä»»å‹™",
        "è¡Œç¨‹", "é ç´„", "å®‰æ’", "é–‹æœƒ", "è¡Œäº‹æ›†", "ä¿¡ä»¶", "ä¿¡ç®±", "email",
        "schedule", "è¶¨å‹¢", "åˆ†æ", "ç ”ç©¶", "ç™¼å±•"
    ]
    if any(kw in q_lower for kw in SKILL_TRIGGERS):
        log(f"âš¡ [FastTrack] é—œéµå­—å‰å“¨å‘½ä¸­ â†’ [SKILL]: '{pure_query[:40]}'")
        skill_result = cerebellum_skill_handler(pure_query, pure_query, agent_id, sm, agent_registry, pe, **kwargs)
        if skill_result:
            return ("SKILL", skill_result)
        log(f"âš ï¸ [FastTrack] æŠ€èƒ½è·¯ç”±å¤±æ•—ï¼Œé™ç´šè‡³å¤§è…¦")
        return (None, None)

    try:
        log(f"ğŸ¤” [FastTrack] æ­£åœ¨é€²è¡Œæ„åœ–åˆ†é¡...")
        if persona_context and len(persona_context) > 500:
            persona_context = persona_context[:500] + "...\n"
        # ğŸ›¡ï¸ èª¿ä½ Temperature ä¸¦åš´æ ¼åŒ–å›å‚³æ ¼å¼ï¼Œå„ªå…ˆä½¿ç”¨ INTENT_MODEL (åŠ é€Ÿæ„åœ–åˆ†é¡)
        result = cerebellum_call(prompt=instruction, temperature=0, timeout=120, num_ctx=2048, num_predict=80, model=INTENT_MODEL)
        log(f"ğŸ¯ [FastTrack] åˆ†é¡çµæœ: {result[:50]}")

        # ğŸš€ ä½¿ç”¨ Regex é€²è¡Œæ›´å¼·å¥çš„è§£æï¼Œé˜²æ­¢ LLM å¤šè©±
        intent_match = re.search(r"\[(SIMPLE|SEARCH|PROGRAMMATIC|SKILL|COMPLEX)\]", result)
        if not intent_match:
            log(f"âš ï¸ [FastTrack] è§£æå¤±æ•—ï¼Œæ¨¡å‹å›å‚³éæ³•æ ¼å¼: {result[:40]}")
            return (None, None)
        
        intent_tag = intent_match.group(1)
        raw_content = re.sub(r"\[.*?\]", "", result, count=1).strip()

        if intent_tag == "SIMPLE":
            answer = raw_content
            _set_cerebellum_simple_cache(query, answer)
            return ("SIMPLE", answer)

        if intent_tag == "SEARCH":
            time_hint = _get_time_context().strip()
            raw_fact = search_web_worker(f"{time_hint}\n{query}")
            return ("SEARCH", cerebellum_style_transfer(raw_fact, agent_id, agent_registry, pe))

        if intent_tag == "PROGRAMMATIC":
            raw_fact = programmatic_data_worker(query)
            return ("PROGRAMMATIC", cerebellum_style_transfer(raw_fact, agent_id, agent_registry, pe))

        if intent_tag == "SKILL":
            skill_desc = raw_content
            log(f"ğŸ”§ åµæ¸¬åˆ°æŠ€èƒ½éœ€æ±‚: {skill_desc}")
            skill_result = cerebellum_skill_handler(query, skill_desc, agent_id, sm, agent_registry, pe, **kwargs)
            if skill_result:
                return ("SKILL", skill_result)
            return (None, None)
        
        if intent_tag == "COMPLEX":
            return (None, None)

    except Exception as e:
        log(f"âš ï¸ å°è…¦å¿«è»Šé“ç•°å¸¸: {e}")
    return (None, None)


# â”€â”€ ä¸Šä¸‹æ–‡è’¸é¤¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cerebellum_distill_context(raw_context: str, task_query: str) -> str:
    """ğŸ§ª ä¸Šä¸‹æ–‡è’¸é¤¾å™¨ (Context Distillation)"""
    if not raw_context or len(raw_context.strip()) < 100:
        return raw_context
    prompt = (
        f"ä½ æ˜¯ä¸€å€‹æŠ€è¡“ä¸Šä¸‹æ–‡è’¸é¤¾å™¨ã€‚\nä»¥ä¸‹æ˜¯ä¸€æ®µå·¥ä½œå°è©±è¨˜éŒ„ï¼Œå…¶ä¸­æ··æœ‰æ‰“æ‹›å‘¼ã€é–’èŠå’Œé›œè¨Šã€‚\n"
        f"ç¾åœ¨è€é—†çš„æ–°ä»»å‹™æ˜¯ï¼šã€{task_query[:100]}ã€\n\n"
        f"è«‹æå–ä¸¦è¼¸å‡ºä¸€ä»½ç²¾ç…‰çš„ã€ŒæŠ€è¡“ç‹€æ…‹å ±å‘Šã€ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
        f"ã€ç›®å‰é‡é»ã€‘ä¸€å¥è©±èªªæ˜æ­£åœ¨åšä»€éº¼\nã€å·²å®Œæˆã€‘æœ€è¿‘å®Œæˆäº†ä»€éº¼é—œéµå·¥ä½œï¼ˆæœ€å¤š 3 é»ï¼‰\n"
        f"ã€å¾…è§£æ±ºã€‘æœ‰ä»€éº¼å·²çŸ¥å•é¡Œæˆ–å¾…ç¢ºèªäº‹é …\n\n"
        f"è¦å‰‡ï¼šç§»é™¤æ‰€æœ‰æ‰“æ‹›å‘¼ã€æƒ…ç·’è¡¨é”å’Œèˆ‡ä»»å‹™ç„¡é—œçš„é–’èŠã€‚\n"
        f"å¦‚æœæ‰¾ä¸åˆ°ç›¸é—œæŠ€è¡“å…§å®¹ï¼Œç›´æ¥å›å‚³ç©ºå­—ä¸²ã€‚\n\n"
        f"ã€åŸå§‹å°è©±è¨˜éŒ„ã€‘\n{raw_context[:1500]}"
    )
    try:
        distilled = cerebellum_call(prompt=prompt, temperature=0.1, timeout=120, num_ctx=3072, num_predict=300)
        if distilled and len(distilled) > 20:
            log(f"ğŸ§ª [è’¸é¤¾] ä¸Šä¸‹æ–‡å£“ç¸® {len(raw_context)} â†’ {len(distilled)} å­—å…ƒ")
            return f"[è’¸é¤¾æŠ€è¡“ç‹€æ…‹]\n{distilled}\n"
    except Exception as e:
        log(f"âš ï¸ ä¸Šä¸‹æ–‡è’¸é¤¾å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è¨˜éŒ„: {e}")
    return raw_context


# â”€â”€ ä»»å‹™æ„åœ–åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_task_intent(title: str) -> dict:
    """Phase 11: å°è…¦ä»»å‹™åˆ†æ (Brain Type & Priority)"""
    instruction = (
        f"Analyze this task: '{title}'\nReturn JSON with:\n"
        "- 'brain': 'cerebrum' (Coding/Complex/Ops) or 'cerebellum' (Chat/Search/Simple)\n"
        "- 'priority': 'high' (Urgent/Fix/Error), 'medium', or 'low'\nOutput JSON only."
    )
    try:
        raw = cerebellum_call(prompt=instruction, temperature=0.2, timeout=120, num_ctx=1024, num_predict=100)
        json_str = re.search(r"\{.*\}", raw, re.DOTALL).group(0)
        return json.loads(json_str)
    except:
        return {"brain": "cerebellum", "priority": "medium"}


# â”€â”€ å¿«å–æ›´æ–° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def update_cache(query: str, raw_answer: str):
    """ğŸš€ èƒŒæ™¯ä»»å‹™ï¼šå°è…¦è’¸é¤¾èˆ‡å¿«å–å¯«å…¥"""
    error_keywords = ["Gateway Agent å¤±æ•—", "Rate limit", "Error", "Exception", "Traceback",
                      "429 Too Many Requests", "500 Internal Server Error"]
    if any(k in raw_answer for k in error_keywords):
        log(f"âš ï¸ åµæ¸¬åˆ°éŒ¯èª¤è¨Šæ¯ï¼Œè·³éå¿«å–å¯«å…¥: {raw_answer[:50]}...")
        return

    prompt = (
        f"ä½ æ˜¯ ArielOS å°è…¦åŠ©ç†ã€‚è«‹å°‡å…§å®¹æç…‰ç‚ºã€é‡é»+ä¾†æºã€ã€‚\nåš´æ ¼è¦å‰‡ï¼š\n"
        f"1. **è‹¥åŸæ–‡åŒ…å«ç¨‹å¼ç¢¼å€å¡Š (Code Blocks)ï¼Œå‹™å¿…å®Œæ•´ä¿ç•™ï¼Œä¸å¯çœç•¥ï¼**\n"
        f"2. å»é™¤ä¸å¿…è¦çš„å¯’æš„ï¼Œä¿ç•™æ ¸å¿ƒè³‡è¨Šã€‚\n\n{raw_answer}"
    )
    try:
        summary = cerebellum_call(prompt=prompt, temperature=0.3, timeout=150, num_ctx=4096, num_predict=512)
        ttl = 30 if any(k in query for k in ["å¤©æ°£", "è·¯æ³", "æ°£æº«", "ç¾åœ¨"]) else 480
        expires = (datetime.datetime.now() + datetime.timedelta(minutes=ttl)).isoformat()

        data = {"records": []}
        if CACHE_PATH.exists():
            with open(CACHE_PATH, "r", encoding="utf-8") as f:
                try: data = json.load(f)
                except: data = {"records": []}

        data['records'].append({"query": query, "summary": summary, "expires_at": expires})
        data['records'] = data['records'][-50:]
        with open(CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        log("âœ… å¿«å–å·²æ›´æ–°ã€‚")
    except Exception as e:
        log(f"âŒ è’¸é¤¾å¤±æ•—: {e}")
