# -*- coding: utf-8 -*-
"""
ariel_bridge.py â€” ArielOS ä¸­å¤®æ©‹æ¥å™¨ (æ¨¡çµ„åŒ–é‡æ§‹ç‰ˆ)

æ¶æ§‹èªªæ˜ï¼š
  modules/config.py        â†’ å¸¸æ•¸ã€è·¯å¾‘ã€æ¨¡å‹åç¨±
  modules/cerebellum.py    â†’ å°è…¦é‚è¼¯ (call, cache, search, skill, distill)
  modules/personality.py   â†’ PersonalityEngine, AgentDispatcher, spinal_chord_reflex
  modules/harness.py       â†’ Shield, Harness, AuditLogger
  modules/evolution.py     â†’ å¤œé–“è’¸é¤¾, å¥½å¥‡å¿ƒæ’ç¨‹, é€²åŒ–å®ˆå‰‡
"""

# â”€â”€ æ¨™æº–åº« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import json, datetime, shutil, subprocess, queue, threading, uuid, re, time, logging
from pathlib import Path

# â”€â”€ Flask â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from flask import Flask, request, jsonify, Response

# â”€â”€ ArielOS æ¨¡çµ„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from modules.config import (
    BASE_DIR, CACHE_PATH, KANBAN_DB_PATH,
    OLLAMA_API, CEREBELLUM_MODEL, INTENT_MODEL, CEREBELLUM_FALLBACK_MODEL, DISPATCHER_MODEL,
    log, ollama_post, IDLE_THRESHOLD, ROUTINES_PATH
)
from modules.harness import Shield, Harness, AuditLogger
from modules.personality import (
    AGENT_REGISTRY, PersonalityEngine, AgentDispatcher,
    load_agent_registry, spinal_chord_reflex, _sanitize_persona, _get_time_context
)
from modules.cerebellum import (
    cerebellum_call, _cached_cerebellum_simple, _set_cerebellum_simple_cache,
    cerebellum_semantic_check, cerebellum_style_transfer, cerebellum_skill_handler,
    cerebellum_fast_track_check, cerebellum_distill_context,
    analyze_task_intent, update_cache, search_web_worker
)
from modules.evolution import (
    generate_evolution_directive, get_evolution_context,
    perform_night_distillation, trigger_curiosity_idea, scheduler_worker
)
from modules.vector_memory import VM  # å‘é‡è¨˜æ†¶å±¤ (ChromaDB + sentence-transformers)
from skill_manager import SkillManager
from memory_manager import MemoryManager

# â”€â”€ æŠ‘åˆ¶è­¦å‘Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.getLogger("primp").setLevel(logging.ERROR)

# â”€â”€ Flask App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)
logging.getLogger('werkzeug').setLevel(logging.ERROR)
task_queue: queue.Queue = queue.Queue()
task_results: dict = {}

# â”€â”€ åˆå§‹åŒ–å…¨åŸŸå¯¦ä¾‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_agent_registry()
PE = PersonalityEngine(BASE_DIR)
SM = SkillManager(BASE_DIR)
MM = MemoryManager(BASE_DIR)
Dispatcher = AgentDispatcher(BASE_DIR)
KM_PATH = KANBAN_DB_PATH

# â”€â”€ çœ‹æ¿ç®¡ç†å™¨ (Inline, ä¾è³´ KM_PATH) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class KanbanManager:
    """Phase 10: çœ‹æ¿ä»»å‹™ç®¡ç†å™¨"""
    def __init__(self, db_path):
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            self._save({"tasks": []})

    def _load(self):
        try:
            with open(self.db_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {"tasks": []}

    def _save(self, data):
        with open(self.db_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def get_all(self):
        return self._load().get("tasks", [])

    def add_task(self, title, agent_id, status="todo", priority="medium"):
        data = self._load()
        task = {
            "id": str(uuid.uuid4()),
            "title": title,
            "agent_id": agent_id,
            "status": status,
            "priority": priority,
            "created_at": datetime.datetime.now().isoformat()
        }
        data["tasks"].append(task)
        self._save(data)
        return task

    def update_task(self, tid, updates):
        data = self._load()
        for task in data["tasks"]:
            if task["id"] == tid:
                task.update(updates)
                self._save(data)
                return task
        return None

    def delete_task(self, tid):
        data = self._load()
        initial_len = len(data["tasks"])
        data["tasks"] = [t for t in data["tasks"] if t["id"] != tid]
        if len(data["tasks"]) < initial_len:
            self._save(data)
            return True
        return False

KM = KanbanManager(KANBAN_DB_PATH)

# â”€â”€ é–’ç½®æ™‚é–“è¿½è¹¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
last_activity_time_ref = [time.time()]  # ä½¿ç”¨ list ä»¥ä¾¿è·¨å‡½å¼ä¿®æ”¹

# â”€â”€ åŒ…è£å‡½å¼ï¼šæ³¨å…¥å…¨åŸŸå¯¦ä¾‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _spinal_chord_reflex(query: str, agent_id: str):
    return spinal_chord_reflex(query, agent_id, AGENT_REGISTRY, PE, SM)

def _cerebellum_style_transfer(raw_answer: str, agent_id: str):
    return cerebellum_style_transfer(raw_answer, agent_id, AGENT_REGISTRY, PE)

def _cerebellum_fast_track_check(query: str, agent_id: str = None, **kwargs):
    return cerebellum_fast_track_check(query, agent_id or "unknown", AGENT_REGISTRY, PE, SM, **kwargs)

def _cerebellum_skill_handler(query: str, skill_desc: str, agent_id: str):
    return cerebellum_skill_handler(query, skill_desc, agent_id, SM, AGENT_REGISTRY, PE)

def _perform_night_distillation():
    return perform_night_distillation(AGENT_REGISTRY, MM, PE)

def _trigger_curiosity_idea():
    return trigger_curiosity_idea(AGENT_REGISTRY, task_queue, last_activity_time_ref)

def _scheduler_worker():
    return scheduler_worker(_perform_night_distillation, _trigger_curiosity_idea, KM, task_queue, last_activity_time_ref)

# â”€â”€ å¤§è…¦åŸ·è¡Œå“¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def brain_worker():
    """ğŸ§  å¤§è…¦åŸ·è¡Œå“¡ï¼šPhase 3 äººæ ¼é‚è¼¯åˆ†é›¢æ¶æ§‹"""
    harness = Harness(BASE_DIR)
    audit = AuditLogger(BASE_DIR / "Shared_Vault" / "audit_log.jsonl")

    while True:
        task = task_queue.get()
        task_id, content = task['id'], task['content']
        agent_id = task.get('agent_id', 'unknown')
        agent_name = AGENT_REGISTRY.get(agent_id, {}).get('name', 'æœªçŸ¥ä»£ç†')
        kanban_task_id = task.get('kanban_task_id')

        is_write_task = harness.needs_checkpoint(content)
        mode_label = "å¯«å…¥æ¨¡å¼ ğŸ›¡ï¸" if is_write_task else "å”¯è®€æ¨¡å¼ âš¡"
        log(f"ğŸ§  [{agent_name}] {mode_label} | {content[:20]}...")

        try:
            shield = Shield(BASE_DIR)
            safe, reason = shield.scan(content)
            if not safe:
                task_results[task_id] = f"ğŸ›¡ï¸ [Shield Defense] {reason}"
                task_queue.task_done()
                continue

            if is_write_task:
                harness.create_checkpoint(task_id)

            memory_ctx = MM.build_memory_context(agent_id, content)
            # ğŸ“¡ èªæ„å¢å¼·ï¼šå¾ ChromaDB èªæ„æŸ¥è©¢è£œè¶³é—œéµå­—æ’ˆå–ä¸åˆ°çš„è¨˜æ†¶
            if VM.is_ready:
                semantic_hits = VM.query_semantic(agent_id, content, top_k=3)
                if semantic_hits:
                    semantic_lines = "\n".join(
                        [f"- [{h['metadata'].get('type','?')}] {h['text']} (ç›¸ä¼¼åº¦:{h['score']})"
                         for h in semantic_hits]
                    )
                    semantic_block = f"[èªæ„è¨˜æ†¶]\n{semantic_lines}\n"
                    memory_ctx = (memory_ctx + "\n" + semantic_block) if memory_ctx else semantic_block
            if memory_ctx:
                log(f"ğŸ§  LTM è¨˜æ†¶æ³¨å…¥ (é—œéµå­—+èªæ„): {memory_ctx[:60]}...")

            session_context = MM.get_conversation_context(agent_id, max_history=10)
            evo_context = get_evolution_context(agent_id)

            # ğŸ§ª ä¸Šä¸‹æ–‡è’¸é¤¾
            if session_context and len(session_context) > 200:
                session_context = cerebellum_distill_context(session_context, content)

            prefix = ""
            if evo_context: prefix += evo_context + "\n"
            if memory_ctx: prefix += memory_ctx + "\n"
            if session_context: prefix += session_context + "\n"

            handoff_instruction = (
                "\n\nã€ç‰¹æ¬ŠæŒ‡ä»¤ï¼šäººæ©Ÿå”åŒäº¤æ¥ (Explicit Handoff)ã€‘\n"
                "è‹¥ä½ é‡åˆ°ä»¥ä¸‹æƒ…æ³ï¼š\n"
                "1. è³‡è¨Šæ¥µåº¦ä¸è¶³ï¼Œå®Œå…¨ç„¡æ³•çŒœæ¸¬è€é—†çš„æ„åœ–ã€‚\n"
                "2. ä½ çš„æ“ä½œå…·æœ‰é«˜é¢¨éšªï¼ˆå¦‚ï¼šåˆªé™¤é‡è¦è³‡æ–™åº«æª”æ¡ˆã€é—œé–‰æ ¸å¿ƒæœå‹™ç­‰ï¼‰ï¼Œéœ€è¦è€é—†çš„äººå·¥æˆæ¬Šã€‚\n"
                "è«‹ä½ **åœæ­¢æ‰€æœ‰æ“ä½œ**ï¼Œä¸¦åœ¨ä½ çš„æœ€çµ‚å›è¦†ä¸­æ˜ç¢ºå¯«å‡ºä»¥ä¸‹å­—ä¸²ï¼š\n"
                "`HANDOFF_TO_HUMAN: [è«‹åœ¨é€™è£¡å¯«ä¸‹ä½ éœ€è¦è€é—†ç¢ºèªçš„å•é¡Œæˆ–éœ€è¦çš„è³‡è¨Š]`\n"
                "ç³»çµ±æœƒè‡ªå‹•æŠŠä»»å‹™æš«åœä¸¦é€šçŸ¥è€é—†ã€‚\n\n"
            )

            full_content = prefix + handoff_instruction + content

            oc_path = shutil.which("openclaw")
            if not oc_path:
                task_results[task_id] = "ğŸš¨ Error: OpenClaw executable not found in PATH."
                task_queue.task_done()
                continue

            MAX_RETRIES = 3
            final_raw_answer = ""
            success = True

            for attempt in range(MAX_RETRIES):
                cmd_args = [oc_path, "agent", "--agent", "main", "--no-color", "--message", full_content]
                if attempt > 0:
                    log(f"ğŸ§  [OpenClaw] Self-Correction Round {attempt+1}/{MAX_RETRIES}...")
                else:
                    log(f"ğŸ› ï¸ [OpenClaw Debug] Running: {oc_path} agent --agent main --no-color --message <content_len={len(full_content)}>")

                process = subprocess.run(cmd_args, capture_output=True, text=True, encoding='utf-8', errors='replace', timeout=280)
                raw_answer = (process.stdout or "").strip()
                if not raw_answer:
                    raw_answer = (process.stderr or "").strip()
                final_raw_answer = raw_answer

                if not is_write_task:
                    break

                success, error_msg = harness.validate()
                if success:
                    break

                log(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡é©—è­‰å¤±æ•—ã€‚éŒ¯èª¤:\n{error_msg}")

                # Cerebellum Hotfix Branch
                hotfix_success = False
                error_type = ""
                error_file = ""

                syntax_match = re.search(r"Syntax error in (.*?):", error_msg)
                runtime_match = re.search(r"Runtime error in (.*?) \(Exit code.*?\):", error_msg)
                timeout_match = re.search(r"Timeout error in (.*?):", error_msg)

                if syntax_match:
                    error_type = "èªæ³•éŒ¯èª¤ (Syntax Error)"
                    error_file = syntax_match.group(1).strip()
                elif runtime_match:
                    error_type = "åŸ·è¡ŒæœŸéŒ¯èª¤ (Runtime Error)"
                    error_file = runtime_match.group(1).strip()
                elif timeout_match:
                    error_type = "åŸ·è¡Œé€¾æ™‚ (Timeout/Infinite Loop)"
                    error_file = timeout_match.group(1).strip()

                if error_file:
                    file_path = list(harness.workspace.glob(f"**/{error_file}"))
                    if file_path:
                        target_file = file_path[0]
                        try:
                            with open(target_file, "r", encoding="utf-8") as f:
                                original_code = f.read()
                            log(f"ğŸ§  å°è…¦ (Cerebellum) å˜—è©¦é€²è¡Œ {error_file} {error_type} Hotfix...")
                            hotfix_prompt = (
                                f"ä½ æ˜¯ä¸€å€‹å°ˆé–€ä¿®å¾© Python ç¨‹å¼éŒ¯èª¤çš„é«˜ç´šåŠ©æ‰‹ã€‚ä»¥ä¸‹ç¨‹å¼ç¢¼åŸ·è¡Œç™¼ç”Ÿäº† {error_type}ï¼š\n"
                                f"```python\n{original_code}\n```\n"
                                f"ç³»çµ±æ‹‹å‡ºçš„éŒ¯èª¤è¨Šæ¯ï¼š\n{error_msg}\n"
                                f"è«‹æ ¹æ“šéŒ¯èª¤è¨Šæ¯ä¿®å¾©é€™å€‹ Bugã€‚è‹¥ç¼ºå°‘ import è«‹è£œä¸Šã€‚\n"
                                f"ã€Œåªã€å›å‚³ä¿®å¾©å¾Œçš„å®Œæ•´ Python ç¨‹å¼ç¢¼ï¼Œçµ•å°ä¸è¦åŒ…å«ä»»ä½• Markdown æ¨™ç±¤ã€‚"
                            )
                            fixed_code = cerebellum_call(prompt=hotfix_prompt, temperature=0.1, timeout=180, num_ctx=2048, num_predict=512)
                            fixed_code = re.sub(r"^```\w*\n?|\n?```$", "", fixed_code).strip()
                            if fixed_code:
                                with open(target_file, "w", encoding="utf-8") as f:
                                    f.write(fixed_code)
                                h_success, h_error_msg = harness.validate()
                                if h_success:
                                    log(f"âœ… å°è…¦ Hotfix æˆåŠŸï¼å…é™¤å¤§è…¦é‡æ§‹ ({error_type})ã€‚")
                                    success = True
                                    hotfix_success = True
                                    final_raw_answer += f"\n\n[ç³»çµ±é™„è¨»: éç¨‹ä¸­æœ‰ {error_type}ï¼Œå·²ç”±å°è…¦è‡ªå‹•è¿½è¹¤ä¸¦å®Œæˆä¿®å¾©: {error_file}]"
                                else:
                                    log("âŒ å°è…¦ Hotfix ä¾ç„¶å¤±æ•—ï¼Œäº¤å›å¤§è…¦è™•ç†ã€‚")
                        except Exception as e:
                            log(f"âš ï¸ å°è…¦ Hotfix ç•°å¸¸: {e}")

                if hotfix_success:
                    break

                harness.rollback(task_id)
                log("âš ï¸ å•Ÿå‹• Brain Replan (å¤§è…¦é‡æ–°è¦åŠƒ)...")
                threading.Thread(target=generate_evolution_directive, args=(agent_id, content, error_msg, MM)).start()

                full_content = (
                    f"ä½ ä¸Šä¸€æ¬¡çš„å¯¦ä½œå¤±æ•—äº†ã€‚ç³»çµ± Linter/ç·¨è­¯å™¨ å›å ±äº†ä»¥ä¸‹éŒ¯èª¤ï¼š\n"
                    f"```\n{error_msg}\n```\n"
                    f"è«‹ä»”ç´°åˆ†æé€™å€‹éŒ¯èª¤ï¼Œç¢ºä¿èªæ„èˆ‡ç¸®æ’æ­£ç¢ºï¼Œä¸¦å˜—è©¦ä½¿ç”¨ä¸åŒçš„æ–¹æ³•ä¿®æ­£å®ƒã€‚\n\n"
                    f"ã€åŸå§‹ä»»å‹™ã€‘\n{content}"
                )

            raw_answer = final_raw_answer

            # Explicit Handoff Detection
            if "HANDOFF_TO_HUMAN:" in raw_answer:
                handoff_msg = raw_answer.split("HANDOFF_TO_HUMAN:")[1].strip()
                log(f"â¸ï¸ [Handoff] Agent è§¸ç™¼äººæ©Ÿäº¤æ¥: {handoff_msg[:50]}")
                if kanban_task_id:
                    KM.update_task(kanban_task_id, {
                        "status": "waiting_for_user",
                        "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] â¸ï¸ ä»»å‹™æš«åœç­‰å¾…æŒ‡ç¤º\nåŸå› : {handoff_msg}"
                    })
                final_answer = _cerebellum_style_transfer(
                    f"[Agent éœ€è¦æ‚¨çš„å”åŠ©]\nè€é—†ï¼Œæˆ‘åœ¨åŸ·è¡Œé€™å€‹ä»»å‹™æ™‚é‡åˆ°äº†é¡§æ…®ï¼Œæƒ³å…ˆè·Ÿæ‚¨ç¢ºèªï¼š\n{handoff_msg}",
                    agent_id
                )
                task_results[task_id] = final_answer
                task_queue.task_done()
                continue

            if is_write_task and not success:
                raw_answer = f"âš ï¸ [ç¶“é {MAX_RETRIES} æ¬¡é©—è­‰çš†å¤±æ•—] å·²è‡ªå‹•å›æ»¾ç‹€æ…‹ã€‚æœ€å¾Œä¸€æ¬¡éŒ¯èª¤ï¼š\n{error_msg}\n\n{raw_answer}"

            # ğŸ­ å¤šä»£ç†åšå¼ˆï¼šReviewer å¯©æŸ¥å¾ªç’°ï¼ˆåƒ… high-priority ä»»å‹™ï¼‰
            task_priority = task.get('priority', 'medium')
            if task_priority == 'high' and raw_answer and success:
                log("ğŸ­ [Reviewer] é«˜å„ªå…ˆä»»å‹™è§¸ç™¼å¯©æŸ¥å¾ªç’°...")
                reviewer_soul_path = BASE_DIR / "Shared_Vault" / "roles" / "reviewer.soul.md"
                reviewer_soul = reviewer_soul_path.read_text(encoding="utf-8") if reviewer_soul_path.exists() else ""
                review_prompt = (
                    f"{reviewer_soul}\n\n"
                    f"é‡å°ä»¥ä¸‹ Worker çš„ç”¢å‡ºé€²è¡Œå¯©æŸ¥ã€‚\n"
                    f"ã€ä»»å‹™è«‹æ±‚ã€‘\n{content[:500]}\n\n"
                    f"ã€Worker çš„ç”¢å‡ºã€‘\n{raw_answer[:2000]}\n\n"
                    f"è«‹ä¾ç…§ä½ çš„è¼¸å‡ºæ ¼å¼å›å‚³å¯©æŸ¥çµæœã€‚"
                )
                try:
                    review_result = cerebellum_call(
                        prompt=review_prompt, temperature=0.1, timeout=120,
                        num_ctx=4096, num_predict=400
                    )
                    log(f"ğŸ­ [Reviewer] å¯©æŸ¥: {review_result[:80]}...")

                    if "[VERDICT]: REJECT" in review_result:
                        log("ğŸš¨ [Reviewer] REJECTï¼Œè§¸ç™¼ Self-Correction...")
                        correction_prompt = (
                            f"ä½ ä¹‹å‰çš„ç”¢å‡ºè¢« Reviewer æ‹’çµ•äº†ã€‚\n"
                            f"å¯©æŸ¥æ„è¦‹ï¼š\n{review_result}\n\n"
                            f"è«‹ä¿®æ­£æ‰€æœ‰å•é¡Œï¼Œé‡æ–°è¼¸å‡ºå®Œæ•´çµæœã€‚åŸå§‹ä»»å‹™ï¼š{content[:300]}"
                        )
                        corrected = cerebellum_call(
                            prompt=correction_prompt, temperature=0.1, timeout=120,
                            num_ctx=4096, num_predict=800
                        )
                        if corrected:
                            raw_answer = corrected
                            log("âœ… [Reviewer] Self-Correction å®Œæˆï¼Œæ›´æ–°ç”¢å‡ºã€‚")
                            if kanban_task_id:
                                KM.update_task(kanban_task_id, {
                                    "logs": f"[Reviewer REJECT+ä¿®æ­£] {review_result[:200]}"
                                })
                    else:
                        log("âœ… [Reviewer] PASSï¼Œå¯©æŸ¥é€šéã€‚")
                except Exception as e:
                    log(f"âš ï¸ [Reviewer] å¯©æŸ¥å›è·¯ç•°å¸¸: {e}")

            final_answer = _cerebellum_style_transfer(raw_answer, agent_id)
            audit.append(task_id, content, final_answer, success, agent_id=agent_id)

            if kanban_task_id:
                log_snippet = final_answer[:300] + "..." if len(final_answer) > 300 else final_answer
                KM.update_task(kanban_task_id, {
                    "status": "done",
                    "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âœ… åŸ·è¡Œå®Œæˆ\n{log_snippet}"
                })
                log(f"ğŸ—‚ï¸ Kanban å·²æ›´æ–°: {kanban_task_id[:8]}... â†’ done")
                notify_kanban_clients()

            MM.append_chat(agent_id, "user", content)
            MM.append_chat(agent_id, "assistant", final_answer)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            threading.Thread(target=update_cache, args=(content, final_answer)).start()
            task_results[task_id] = final_answer

        except Exception as e:
            err_msg = f"ğŸš¨ å¤§è…¦ç•°å¸¸: {str(e)}"
            if kanban_task_id:
                KM.update_task(kanban_task_id, {
                    "status": "done",
                    "logs": f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âŒ åŸ·è¡Œå¤±æ•—\n{err_msg}"
                })
            task_results[task_id] = err_msg

        task_queue.task_done()


threading.Thread(target=brain_worker, daemon=True).start()

# â”€â”€ Kanban SSE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

kanban_clients = []

def notify_kanban_clients():
    dead_clients = []
    for q in kanban_clients:
        try: q.put_nowait({"type": "update", "data": KM.get_all()})
        except queue.Full: dead_clients.append(q)
    for q in dead_clients:
        kanban_clients.remove(q)

# â”€â”€ Flask API Routes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route('/v1/harness/night-mode', methods=['POST'])
def trigger_night_mode():
    result = _perform_night_distillation()
    return jsonify({"status": "success", "message": result})

@app.route('/v1/harness/snapshot', methods=['POST'])
def trigger_snapshot():
    try:
        import tarfile
        from datetime import datetime
        backups_dir = BASE_DIR / "backups"
        backups_dir.mkdir(exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        snap_path = backups_dir / f"snapshot_{ts}.tar.gz"
        
        excludes = {"Shared_Vault/Memory", "Shared_Vault/chroma_db", "backups", "__pycache__", ".git", ".env"}
        def _exclude(tarinfo):
            for exc in excludes:
                if exc in tarinfo.name.replace("\\", "/"):
                    return None
            return tarinfo
            
        with tarfile.open(snap_path, "w:gz") as tar:
            tar.add(BASE_DIR, arcname="ArielOS", filter=_exclude)
            
        return jsonify({"status": "success", "message": f"å¿«ç…§å»ºç«‹æˆåŠŸ: {snap_path.name}"})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/v1/harness/reload-agents', methods=['POST'])
def reload_agents():
    load_agent_registry()
    PE.invalidate()
    return jsonify({"status": "success", "message": f"Agents reloaded. Total: {len(AGENT_REGISTRY)}", "agents": list(AGENT_REGISTRY.keys())})

@app.route('/v1/team/dispatch', methods=['POST'])
def api_dispatch_task():
    data = request.json
    role = data.get("role")
    payload = data.get("payload")
    task_id = data.get("task_id", str(uuid.uuid4()))
    if not role or not payload:
        return jsonify({"error": "Missing role or payload"}), 400
    result = Dispatcher.dispatch(task_id, role, payload)
    return jsonify({"task_id": task_id, "role": role, "result": result})

@app.route('/v1/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    if task_id in task_results:
        return jsonify({"status": "completed", "result": task_results.pop(task_id)})
    return jsonify({"status": "processing"})

@app.route('/v1/chat/completions', methods=['POST'])
def chat():
    global last_activity_time_ref
    try:
        last_activity_time_ref[0] = time.time()
        data = request.json
        user_input = data['messages'][-1]['content']
        agent_id = data.get('agent_id', 'unknown')
        origin = data.get('origin', '')
        gas_url = data.get('gas_url') or ''
        agent_name = AGENT_REGISTRY.get(agent_id, {}).get('name', 'æœªçŸ¥')
        log(f"ğŸ“¨ æ”¶åˆ°ä¾†è‡ª [{agent_name}] çš„è«‹æ±‚{' (çœ‹æ¿åŸ·è¡Œå™¨)' if origin == 'kanban_poller' else ''}")

        if user_input.startswith("dispatch:"):
            try:
                _, role, payload = user_input.split(":", 2)
                task_id = f"task_{int(time.time())}"
                result = Dispatcher.dispatch(task_id, role.strip(), payload.strip())
                return jsonify({"choices": [{"message": {"content": f"ğŸ‘® [Dispatcher Result]\n{result}"}}]})
            except ValueError:
                return jsonify({"choices": [{"message": {"content": "âŒ æ ¼å¼éŒ¯èª¤ã€‚è«‹ä½¿ç”¨: dispatch:role:instruction"}}]})

        cached = cerebellum_semantic_check(user_input)
        if cached and cached != "OLLAMA_BUSY":
            return jsonify({"choices": [{"message": {"content": f"[Ariel æ™ºæ…§å¿«å–]\n{cached}"}}]})

        ollama_busy = (cached == "OLLAMA_BUSY")
        if ollama_busy:
            log("âš¡ Ollama å¿™ç¢Œï¼Œè·³é FastTrack ç›´æ¥å…¥åˆ—å¤§è…¦")

        reflex_ans = _spinal_chord_reflex(user_input, agent_id)
        if reflex_ans:
            log(f"âš¡ è„Šé«“åå°„å‘½ä¸­: {reflex_ans}")
            return jsonify({"choices": [{"message": {"content": reflex_ans}}]})

        intent_type, fast_ans = (None, None)
        if not ollama_busy:
            intent_type, fast_ans = _cerebellum_fast_track_check(user_input, agent_id, gas_url=gas_url)

        if intent_type == "SIMPLE":
            log(f"âš¡ Fast Track [SIMPLE]: {fast_ans[:20]}...")
            MM.append_chat(agent_id, "user", user_input)
            MM.append_chat(agent_id, "assistant", fast_ans)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})

        if intent_type in ("SEARCH", "SKILL"):
            kanban_entry = KM.add_task(
                title=user_input[:80] + ('...' if len(user_input) > 80 else ''),
                agent_id=agent_id, status="doing", priority="low"
            )
            result_snippet = fast_ans[:300] + '...' if len(fast_ans) > 300 else fast_ans
            KM.update_task(kanban_entry['id'], {"status": "done", "logs": f"[å°è…¦ {intent_type}] {result_snippet}"})
            log(f"âš¡ Fast Track [{intent_type}] å®Œæˆ: {fast_ans[:20]}...")
            notify_kanban_clients()
            MM.append_chat(agent_id, "user", user_input)
            MM.append_chat(agent_id, "assistant", fast_ans)
            threading.Thread(target=MM._compress_old_chats, args=(agent_id,)).start()
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})

        if intent_type is not None:
            return jsonify({"choices": [{"message": {"content": fast_ans}}]})

        kanban_task_id = None
        if origin != 'kanban_poller':
            kanban_entry = KM.add_task(
                title=user_input[:80] + ('...' if len(user_input) > 80 else ''),
                agent_id=agent_id, status="doing", priority="medium"
            )
            kanban_task_id = kanban_entry['id']
            log(f"ğŸ—‚ï¸ Kanban Job å»ºç«‹: [{agent_name}] {user_input[:30]}...")
            notify_kanban_clients()

        tid = str(uuid.uuid4())
        task_queue.put({'id': tid, 'content': user_input, 'agent_id': agent_id, 'kanban_task_id': kanban_task_id})
        log(f"âœ… ä»»å‹™ {tid} å·²å…¥åˆ— (è…¦éƒ¨è™•ç†ä¸­)")
        return jsonify({"task_id": tid, "status": "queued"}), 202

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/v1/kanban/stream')
def kanban_stream():
    def event_stream():
        q = queue.Queue(maxsize=10)
        kanban_clients.append(q)
        try:
            yield f"data: {json.dumps(KM.get_all())}\n\n"
            while True:
                message = q.get(timeout=30)
                yield f"data: {json.dumps(message['data'])}\n\n"
        except queue.Empty:
            yield ": heartbeat\n\n"
        except GeneratorExit:
            pass
        finally:
            if q in kanban_clients:
                kanban_clients.remove(q)
    return Response(event_stream(), mimetype="text/event-stream")

@app.route('/kanban')
def kanban_ui():
    return app.send_static_file('kanban.html')

@app.route('/v1/kanban/tasks', methods=['GET'])
def get_kanban_tasks():
    return jsonify(KM.get_all())

@app.route('/v1/kanban/tasks', methods=['POST'])
def add_kanban_task():
    try:
        data = request.json
        title = data.get('title', 'Unknown Task')
        analysis = analyze_task_intent(title)
        task = KM.add_task(title=title, agent_id=data.get('agent_id', 'agent1'), status=data.get('status', 'todo'), priority=analysis.get('priority', 'medium'))
        KM.update_task(task['id'], {"brain": analysis.get("brain", "cerebellum")})
        task['brain'] = analysis.get("brain", "cerebellum")
        notify_kanban_clients()
        return jsonify(task)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/kanban/tasks/<tid>', methods=['PATCH'])
def update_kanban_task(tid):
    try:
        updates = request.json
        updates.pop('id', None)
        task = KM.update_task(tid, updates)
        if task:
            notify_kanban_clients()
            return jsonify(task)
        return jsonify({"error": "Task not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/kanban/tasks/<tid>', methods=['DELETE'])
def delete_kanban_task(tid):
    try:
        if KM.delete_task(tid):
            return jsonify({"status": "deleted"})
        return jsonify({"error": "Task not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/v1/skills', methods=['GET'])
def list_skills():
    return jsonify({"installed": SM.list_installed(), "catalog": SM.list_catalog()})

@app.route('/v1/skills/search', methods=['POST'])
def search_skills():
    query = request.json.get('query', '')
    return jsonify(SM.search_skill_online(query))

@app.route('/v1/skills/install', methods=['POST'])
def install_skill_api():
    skill_info = request.json
    success = SM.install_skill(skill_info)
    return jsonify({"status": "installed" if success else "failed"})

@app.route('/v1/skills/<name>', methods=['DELETE'])
def remove_skill(name):
    success = SM.remove_skill(name)
    return jsonify({"status": "removed" if success else "not_found"})

# â”€â”€ å•Ÿå‹• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == '__main__':
    log(f"ArielOS æ™ºæ…§ç¸½éƒ¨ v2.0 (æ¨¡çµ„åŒ–ç‰ˆ) å•Ÿå‹•æˆåŠŸ | è·¯å¾‘é–å®š: {BASE_DIR}")
    log(f"ğŸ§  å°è…¦æ¨¡å‹é…ç½® | ä¸»è¦: {CEREBELLUM_MODEL} | å¿«å–åˆ†é¡: {INTENT_MODEL} | å‚™ç”¨: {CEREBELLUM_FALLBACK_MODEL}")
    log(f"ğŸ¤– Dispatcher æ¨¡å‹: {DISPATCHER_MODEL}")
    log(f"ğŸ“¦ å·²è¼‰å…¥æ¨¡çµ„: config, harness, personality, cerebellum, evolution")
    threading.Thread(target=_scheduler_worker, daemon=True).start()
    from waitress import serve
    log("ğŸš€ å•Ÿå‹• Waitress ç”Ÿç”¢ç´šä¼ºæœå™¨ (Port 28888)...")
    serve(app, host='0.0.0.0', port=28888, threads=16)
