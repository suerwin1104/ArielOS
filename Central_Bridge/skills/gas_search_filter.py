import sys
if sys.stdout.encoding.lower() != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

import os
import json
import urllib.request
import re

def main():
    if len(sys.argv) < 2:
        print("âŒ ç¼ºå°‘éœ€æ±‚åƒæ•¸ã€‚")
        sys.exit(1)

    demand = sys.argv[1]
    gas_url = os.environ.get("GAS_URL")

    if not gas_url:
        print("âš ï¸ ç„¡æ³•åŸ·è¡Œæ­¤æŠ€èƒ½ï¼šæ‚¨çš„å€‹äººè¨­å®šæª” (SOUL.md) ä¸­å°šæœªè¨­å®š GAS_URLã€‚")
        sys.exit(1)

    # 1. LLM-based Complex Demand Detection
    # Using the local Cerebellum model to intelligently parse the demand into JSON
    import requests
    OLLAMA_API = "http://127.0.0.1:11434/api/generate"
    CEREBELLUM_MODEL = "gemma3:4b-it-q4_K_M"

    instruction = f"""
    åˆ†æä½¿ç”¨è€…éœ€æ±‚ï¼Œé¸æ“‡æœ€åˆé©çš„ã€Œæ„Ÿå®˜å¼•æ“ (Sensory Engine)ã€ï¼š
    
    ã€æ„Ÿå®˜è·¯ç”±è¦å‰‡ã€‘
    1. ğŸ¯ [ç²¾ç¢ºèª¿æ ¡] - é‡å°ï¼šç¡¬é«”è¦æ ¼ã€ç‰¹å®šç‰ˆæœ¬è™Ÿã€Bug ä¿®è£œã€GitHub/Reddit è¨è«–ã€å®˜æ–¹æ–‡ä»¶ã€‚
       â®• è¼¸å‡ºï¼š{{"action": "search", "params": {{"query": "ç²¾ç°¡é—œéµå­—", "searchType": "google", "filterCode": "data = data"}}}}
    
    2. ğŸ§  [é–‹æ”¾ç ”ç©¶] - é‡å°ï¼šè¶¨å‹¢åˆ†æã€æœªä¾†é æ¸¬ã€é•·ç¯‡å ±å‘Šã€æ–°èæ‡¶äººåŒ…ã€å¤šæ–¹è§€é»ã€‚
       â®• è¼¸å‡ºï¼š{{"action": "search", "params": {{"query": "ç²¾ç°¡æ ¸å¿ƒè©", "searchType": "exa", "filterCode": "data = data"}}}}
    
    3. âš¡ [ç°¡å–®äº‹å¯¦] - é‡å°ï¼šä»Šæ—¥æ—¥æœŸã€å¤©æ°£ã€ç°¡å–®å®šç¾©ã€åŒ¯ç‡ã€‚
       â®• è¼¸å‡ºï¼š{{"action": "local_search", "query": "é—œéµå­—"}}
    
    4. ğŸ” [æ·±åº¦æ¢é‡] - é‡å°ï¼šæ˜ç¢ºè¦æ±‚ã€Œæ·±åº¦æœå°‹ã€ã€ã€Œæˆªåœ–åˆ†æã€ã€ã€ŒPDFå…¨æ–‡ã€æˆ–ç¶²é è¢«å°é–ã€‚
       â®• è¼¸å‡ºï¼š{{"action": "search_deep", "query": "å®Œæ•´éœ€æ±‚"}}
       
    ã€èªè¨€èˆ‡å€åŸŸè¦å‰‡ã€‘
    - æ‰€æœ‰æœå°‹çµæœå¿…é ˆä»¥ã€Œç¹é«”ä¸­æ–‡ã€ç‚ºä¸»ã€‚
    - å„ªå…ˆè€ƒæ…®ã€Œå°ç£ã€æˆ–ã€Œå…¨çƒã€è§€é»ï¼Œé™¤éä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚ã€Œä¸­åœ‹å¤§é™¸ã€ã€‚
    - åœ¨æœå°‹é—œéµå­— (query) ä¸­ï¼Œè‹¥ç„¡æ˜ç¢ºå€åŸŸï¼Œå¯é©åº¦åŠ å…¥ã€Œå°ç£ã€æˆ–ã€Œç¹é«”ã€ç­‰è©å½™ä»¥å„ªåŒ–çµæœã€‚
    
    å¯ç”¨ä»»å‹™ï¼šcalendar(å¤©æ•¸), emails(æ•¸é‡), search(GA-å¼•æ“), local_search(ç°¡å–®), search_deep(æ¢é‡)ã€‚
    
    ä½¿ç”¨è€…éœ€æ±‚ï¼šã€{demand}ã€
    
    è«‹å›å‚³ JSON é™£åˆ—ã€‚æ³¨æ„ï¼šsearch çš„ query å¿…é ˆç²¾ç°¡ã€‚åƒ…å›å‚³ JSONï¼Œä¸è¦ markdownã€‚
    """

    tasks = []
    _log(f"ğŸ§  æ­£åœ¨è«‹æ±‚èª¿åº¦å“¡ (Dispatcher) åˆ†ææ„Ÿå®˜å±¤ç´š...")
    try:
        resp = requests.post(OLLAMA_API, json={
            "prompt": instruction,
            "model": CEREBELLUM_MODEL,
            "stream": False,
            "options": {"temperature": 0.1, "num_ctx": 1024}
        }, timeout=120)
        llm_output = resp.json().get('response', '').strip()
        
        json_match = re.search(r'\[.*\]', llm_output, re.DOTALL)
        if json_match:
            tasks = json.loads(json_match.group(0))
            _log(f"âš–ï¸ èª¿åº¦å“¡æ±ºç­–: {json.dumps(tasks, ensure_ascii=False)}")
        else:
            _log(f"âš ï¸ èª¿åº¦è§£æå¤±æ•—ï¼Œé€€å›é è¨­æœå°‹æ¨¡å¼ã€‚")
    except Exception as e:
        _log(f"âš ï¸ å°è…¦é€£ç·šå¤±æ•— ({e})ã€‚")

    # è™•ç†ä»»å‹™åˆ†æµèˆ‡åŸ·è¡Œ
    if not tasks:
        tasks = [{"action": "search", "params": {"query": demand, "searchType": "exa"}}]

    print(f"**[ArielOS æ„Ÿå®˜è·¯ç”±æ±ºç­–å ±å‘Š]**\n")
    
    batch_gas_tasks = []
    for t in tasks:
        action = t.get("action")
        if action in ["calendar", "emails", "search"]:
            batch_gas_tasks.append(t)
        elif action == "local_search":
            _log(f"âš¡ åŸ·è¡Œæœ¬åœ°å¿«é€Ÿæª¢ç´¢: {t.get('query')}")
            # Here we just print instructions as it's a bridge between skills
            print(f"> [æœ¬åœ°æœå°‹] è«‹åƒè€ƒæœ¬åœ°è³‡è¨Šä¾†æºè™•ç†: {t.get('query')}\n")
        elif action == "search_deep":
            _log(f"ğŸ” å•Ÿå‹•æ·±åº¦æ¢é‡ (Playwright)...")
            print(f"> [æ·±åº¦æ¢é‡] æ­£åœ¨å–šé†’æœ¬åœ°ç€è¦½å™¨é€²è¡Œç²¾æº–æƒæ...\n")

    if batch_gas_tasks:
        payload = {"action": "batch_execute", "tasks": batch_gas_tasks}
        _log(f"ğŸ“¡ å‚³é€ {len(batch_gas_tasks)} å€‹é›²ç«¯è’¸é¤¾ä»»å‹™è‡³ GAS...")
        
        try:
            req = urllib.request.Request(gas_url, data=json.dumps(payload).encode('utf-8'),
                                        headers={'Content-Type': 'application/json'}, method='POST')
            with urllib.request.urlopen(req, timeout=45) as response:
                result = json.loads(response.read().decode('utf-8'))
                if result.get("status") == "success":
                    data = result.get("data", {})
                    # ... (Display outputs for calendar, emails, search)
                    display_gas_results(data)
                else:
                    print(f"âŒ GAS åŸ·è¡Œå¤±æ•—: {result.get('error')}")
        except Exception as e:
            print(f"âŒ é€šè¨Šç•°å¸¸: {e}")

def display_gas_results(data):
    if "calendar" in data:
        print(f"ğŸ“… **è¿‘æœŸè¡Œç¨‹:**")
        for s in data["calendar"]: print(f"- {s['time']} {s['title']}")
        print()
    if "emails" in data:
        print(f"ğŸ“§ **æ–°é€²ä¿¡ä»¶ (å·²è’¸é¤¾):**")
        for e in data["emails"]: print(f"- From: {e['from']}\n  Subject: {e['subject']}\n  Snippet: {e['snippet']}...")
        print()
    if "search" in data:
        res = data["search"]
        engine = "Exa èªç¾©" if res.get("params", {}).get("searchType") == "exa" else "Google ç²¾ç¢º"
        print(f"ğŸ” **{engine} å¼•æ“çµæœ ({res.get('query')}):**")
        for item in res.get("result", []):
            if isinstance(item, dict):
                print(f"- **{item.get('title')}**\n  {item.get('content', '')[:200]}...\n  Link: {item.get('url')}\n")
            else: print(f"- {item}")

def _log(msg):
    print(f"ğŸ”§ [Sensory-Router] {msg}")

if __name__ == "__main__":
    main()
